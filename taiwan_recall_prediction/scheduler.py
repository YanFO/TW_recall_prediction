#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®šæ™‚ä»»å‹™èª¿åº¦å™¨ - è‡ªå‹•æ›´æ–°è³‡æ–™åˆ†æ
"""

import schedule
import time
import subprocess
import logging
from datetime import datetime
import os
import json

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/scheduler.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class AnalysisScheduler:
    def __init__(self):
        self.ensure_directories()
        
    def ensure_directories(self):
        """ç¢ºä¿å¿…è¦ç›®éŒ„å­˜åœ¨"""
        directories = ['/app/data', '/app/logs', '/app/output']
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    def run_crawler(self, script_name):
        """åŸ·è¡Œçˆ¬èŸ²è…³æœ¬"""
        try:
            logger.info(f"é–‹å§‹åŸ·è¡Œ {script_name}")
            result = subprocess.run(
                f"python {script_name}",
                shell=True,
                capture_output=True,
                text=True,
                cwd='/app'
            )
            
            if result.returncode == 0:
                logger.info(f"{script_name} åŸ·è¡ŒæˆåŠŸ")
                return True
            else:
                logger.error(f"{script_name} åŸ·è¡Œå¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"åŸ·è¡Œ {script_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def run_analysis(self, script_name):
        """åŸ·è¡Œåˆ†æè…³æœ¬"""
        try:
            logger.info(f"é–‹å§‹åŸ·è¡Œ {script_name}")
            result = subprocess.run(
                f"python {script_name}",
                shell=True,
                capture_output=True,
                text=True,
                cwd='/app'
            )
            
            if result.returncode == 0:
                logger.info(f"{script_name} åŸ·è¡ŒæˆåŠŸ")
                return True
            else:
                logger.error(f"{script_name} åŸ·è¡Œå¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"åŸ·è¡Œ {script_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def full_analysis_pipeline(self):
        """å®Œæ•´åˆ†ææµç¨‹"""
        logger.info("é–‹å§‹åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹")
        
        start_time = datetime.now()
        
        # åŸ·è¡Œé †åº
        steps = [
            ("ptt_crawler.py", "PTTçˆ¬èŸ²"),
            ("dcard_crawler.py", "Dcardçˆ¬èŸ²"),
            ("sentiment_analyzer.py", "æƒ…ç·’åˆ†æ"),
            ("mece_analyzer.py", "MECEåˆ†æ")
        ]
        
        results = {}
        
        for script, description in steps:
            logger.info(f"åŸ·è¡Œ {description}...")
            success = self.run_analysis(script)
            results[script] = success
            
            if not success:
                logger.warning(f"{description} åŸ·è¡Œå¤±æ•—ï¼Œä½†ç¹¼çºŒåŸ·è¡Œå¾ŒçºŒæ­¥é©Ÿ")
            
            # æ¯å€‹æ­¥é©Ÿä¹‹é–“ç¨ä½œä¼‘æ¯
            time.sleep(30)
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        # è¨˜éŒ„åŸ·è¡Œçµæœ
        summary = {
            'execution_time': start_time.isoformat(),
            'duration_seconds': duration.total_seconds(),
            'results': results,
            'success_count': sum(results.values()),
            'total_steps': len(steps)
        }
        
        # å„²å­˜åŸ·è¡Œæ‘˜è¦
        summary_file = f"/app/logs/execution_summary_{start_time.strftime('%Y%m%d_%H%M%S')}.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"å®Œæ•´åˆ†ææµç¨‹åŸ·è¡Œå®Œæˆï¼Œè€—æ™‚ {duration}")
        logger.info(f"æˆåŠŸåŸ·è¡Œ {summary['success_count']}/{summary['total_steps']} å€‹æ­¥é©Ÿ")
        
        return summary
    
    def quick_update(self):
        """å¿«é€Ÿæ›´æ–° - åªåŸ·è¡Œçˆ¬èŸ²å’Œæƒ…ç·’åˆ†æ"""
        logger.info("é–‹å§‹åŸ·è¡Œå¿«é€Ÿæ›´æ–°")
        
        steps = [
            ("ptt_crawler.py", "PTTçˆ¬èŸ²"),
            ("dcard_crawler.py", "Dcardçˆ¬èŸ²"),
            ("sentiment_analyzer.py", "æƒ…ç·’åˆ†æ")
        ]
        
        for script, description in steps:
            logger.info(f"åŸ·è¡Œ {description}...")
            self.run_analysis(script)
            time.sleep(15)
        
        logger.info("å¿«é€Ÿæ›´æ–°å®Œæˆ")
    
    def health_check(self):
        """å¥åº·æª¢æŸ¥"""
        logger.info("åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥")
        
        # æª¢æŸ¥å¿…è¦æª”æ¡ˆ
        required_files = [
            'ptt_crawler.py',
            'dcard_crawler.py', 
            'sentiment_analyzer.py',
            'mece_analyzer.py',
            'dashboard.py'
        ]
        
        missing_files = []
        for file in required_files:
            if not os.path.exists(f'/app/{file}'):
                missing_files.append(file)
        
        if missing_files:
            logger.error(f"ç¼ºå°‘å¿…è¦æª”æ¡ˆ: {missing_files}")
        else:
            logger.info("æ‰€æœ‰å¿…è¦æª”æ¡ˆéƒ½å­˜åœ¨")
        
        # æª¢æŸ¥è³‡æ–™ç›®éŒ„
        data_files = os.listdir('/app/data') if os.path.exists('/app/data') else []
        logger.info(f"è³‡æ–™ç›®éŒ„åŒ…å« {len(data_files)} å€‹æª”æ¡ˆ")
        
        return len(missing_files) == 0

def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    scheduler_instance = AnalysisScheduler()
    
    logger.info("ğŸ¤– åˆ†æèª¿åº¦å™¨å•Ÿå‹•")
    
    # åŸ·è¡Œåˆå§‹å¥åº·æª¢æŸ¥
    if not scheduler_instance.health_check():
        logger.error("å¥åº·æª¢æŸ¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç³»çµ±é…ç½®")
        return
    
    # è¨­å®šå®šæ™‚ä»»å‹™
    
    # æ¯å¤©æ—©ä¸Š8é»åŸ·è¡Œå®Œæ•´åˆ†æ
    schedule.every().day.at("08:00").do(scheduler_instance.full_analysis_pipeline)
    
    # æ¯å¤©ä¸‹åˆ2é»å’Œæ™šä¸Š8é»åŸ·è¡Œå¿«é€Ÿæ›´æ–°
    schedule.every().day.at("14:00").do(scheduler_instance.quick_update)
    schedule.every().day.at("20:00").do(scheduler_instance.quick_update)
    
    # æ¯å°æ™‚åŸ·è¡Œå¥åº·æª¢æŸ¥
    schedule.every().hour.do(scheduler_instance.health_check)
    
    logger.info("å®šæ™‚ä»»å‹™å·²è¨­å®š:")
    logger.info("- æ¯å¤© 08:00: å®Œæ•´åˆ†ææµç¨‹")
    logger.info("- æ¯å¤© 14:00, 20:00: å¿«é€Ÿæ›´æ–°")
    logger.info("- æ¯å°æ™‚: å¥åº·æª¢æŸ¥")
    
    # å¦‚æœæ˜¯é¦–æ¬¡å•Ÿå‹•ä¸”æ²’æœ‰è³‡æ–™ï¼Œç«‹å³åŸ·è¡Œä¸€æ¬¡å®Œæ•´åˆ†æ
    if not os.path.exists('/app/data/analysis_complete.flag'):
        logger.info("é¦–æ¬¡å•Ÿå‹•ï¼ŒåŸ·è¡Œåˆå§‹åˆ†æ...")
        summary = scheduler_instance.full_analysis_pipeline()
        
        if summary['success_count'] > 0:
            # æ¨™è¨˜åˆå§‹åˆ†æå®Œæˆ
            with open('/app/data/analysis_complete.flag', 'w') as f:
                f.write(datetime.now().isoformat())
    
    # é–‹å§‹èª¿åº¦å¾ªç’°
    logger.info("èª¿åº¦å™¨é–‹å§‹é‹è¡Œ...")
    
    while True:
        try:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
            
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ°åœæ­¢ä¿¡è™Ÿï¼Œèª¿åº¦å™¨æ­£åœ¨é—œé–‰...")
            break
        except Exception as e:
            logger.error(f"èª¿åº¦å™¨é‹è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            time.sleep(300)  # ç™¼ç”ŸéŒ¯èª¤æ™‚ç­‰å¾…5åˆ†é˜å†ç¹¼çºŒ
    
    logger.info("èª¿åº¦å™¨å·²åœæ­¢")

if __name__ == "__main__":
    main()

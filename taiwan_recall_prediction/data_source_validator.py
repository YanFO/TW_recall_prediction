#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•¸æ“šä¾†æºé©—è­‰å’Œæ¨™è¨»ç³»çµ±
Data Source Validator and Annotation System

ç¢ºä¿æ‰€æœ‰æ•¸æ“šéƒ½æ˜ç¢ºæ¨™è¨»ä¾†æºï¼Œå€åˆ†çœŸå¯¦æ•¸æ“šå’Œæ¨¡æ“¬æ•¸æ“š
"""

import json
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataSourceValidator:
    """æ•¸æ“šä¾†æºé©—è­‰å™¨"""
    
    def __init__(self):
        self.data_sources = {
            'real_sources': [
                'PTTè«–å£‡çˆ¬èŸ²',
                'Dcard API',
                'ä¸­å¤®æ°£è±¡ç½²API',
                'è¯åˆæ–°èç¶²',
                'ä¸­æ™‚æ–°èç¶²',
                'è‡ªç”±æ™‚å ±',
                'ä¸­é¸æœƒé–‹æ”¾æ•¸æ“š',
                'å…§æ”¿éƒ¨çµ±è¨ˆ',
                'æ”¿å¤§é¸ç ”ä¸­å¿ƒ',
                'ä¸­ç ”é™¢æ•¸æ“š'
            ],
            'simulated_sources': [
                'æ¨¡æ“¬æ•¸æ“š',
                'éš¨æ©Ÿç”Ÿæˆ',
                'çµ±è¨ˆæ¨¡å‹',
                'æ­·å²æ¨ä¼°'
            ]
        }
        
        self.validation_log = []
    
    def validate_data_source(self, data: Dict) -> Dict:
        """é©—è­‰æ•¸æ“šä¾†æºä¸¦æ·»åŠ æ¨™è¨»"""
        validated_data = data.copy()
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰æ•¸æ“šä¾†æºæ¨™è¨»
        if 'data_source' not in data:
            validated_data['data_source'] = 'âš ï¸ æœªæ¨™è¨»æ•¸æ“šä¾†æº (Unknown Source)'
            validated_data['is_simulated'] = True
            validated_data['validation_warning'] = 'æ•¸æ“šä¾†æºæœªæ˜ç¢ºæ¨™è¨»'
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¨¡æ“¬æ•¸æ“š
        if 'is_simulated' not in data:
            # æ ¹æ“šæ•¸æ“šä¾†æºåˆ¤æ–·
            source = validated_data.get('data_source', '')
            if any(sim_source in source for sim_source in self.data_sources['simulated_sources']):
                validated_data['is_simulated'] = True
            else:
                validated_data['is_simulated'] = False
        
        # æ·»åŠ é©—è­‰æ™‚é–“æˆ³
        validated_data['validation_timestamp'] = datetime.now().isoformat()
        
        # è¨˜éŒ„é©—è­‰æ—¥èªŒ
        self._log_validation(validated_data)
        
        return validated_data
    
    def _log_validation(self, data: Dict):
        """è¨˜éŒ„é©—è­‰æ—¥èªŒ"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'data_source': data.get('data_source', 'Unknown'),
            'is_simulated': data.get('is_simulated', True),
            'has_warning': 'validation_warning' in data
        }
        self.validation_log.append(log_entry)
    
    def generate_data_source_report(self) -> Dict:
        """ç”Ÿæˆæ•¸æ“šä¾†æºå ±å‘Š"""
        if not self.validation_log:
            return {
                'total_validations': 0,
                'real_data_count': 0,
                'simulated_data_count': 0,
                'warning_count': 0,
                'report_timestamp': datetime.now().isoformat()
            }
        
        total = len(self.validation_log)
        real_count = sum(1 for log in self.validation_log if not log['is_simulated'])
        simulated_count = sum(1 for log in self.validation_log if log['is_simulated'])
        warning_count = sum(1 for log in self.validation_log if log['has_warning'])
        
        return {
            'total_validations': total,
            'real_data_count': real_count,
            'simulated_data_count': simulated_count,
            'warning_count': warning_count,
            'real_data_percentage': (real_count / total) * 100 if total > 0 else 0,
            'simulated_data_percentage': (simulated_count / total) * 100 if total > 0 else 0,
            'data_quality_score': (real_count / total) * 100 if total > 0 else 0,
            'report_timestamp': datetime.now().isoformat(),
            'source_breakdown': self._get_source_breakdown()
        }
    
    def _get_source_breakdown(self) -> Dict:
        """ç²å–æ•¸æ“šä¾†æºåˆ†è§£"""
        source_counts = {}
        for log in self.validation_log:
            source = log['data_source']
            if source in source_counts:
                source_counts[source] += 1
            else:
                source_counts[source] = 1
        
        return source_counts
    
    def annotate_mece_data(self, mece_data: pd.DataFrame) -> pd.DataFrame:
        """ç‚ºMECEæ•¸æ“šæ·»åŠ ä¾†æºæ¨™è¨»"""
        annotated_data = mece_data.copy()
        
        # æ·»åŠ æ•¸æ“šä¾†æºåˆ—
        annotated_data['data_source'] = 'ğŸ“Š çµ±è¨ˆæ¨ä¼°æ•¸æ“š (Statistical Estimation)'
        annotated_data['is_simulated'] = True
        annotated_data['source_type'] = 'statistical_model'
        annotated_data['reference_basis'] = 'åŸºæ–¼æ­·å²æ¡ˆä¾‹å’Œå­¸è¡“ç ”ç©¶'
        
        # ç‚ºä¸åŒç¶­åº¦æ·»åŠ å…·é«”åƒè€ƒä¾†æº
        for idx, row in annotated_data.iterrows():
            dimension = row['dimension']
            category = row['category']
            
            if dimension == 'æ”¿æ²»ç«‹å ´':
                annotated_data.at[idx, 'reference_source'] = 'éŸ“åœ‹ç‘œç½·å…æ¡ˆåˆ†æ + TVBSæ°‘èª¿'
            elif dimension == 'å¹´é½¡å±¤':
                annotated_data.at[idx, 'reference_source'] = 'å°ç£æ°‘ä¸»åŸºé‡‘æœƒæ°‘èª¿ + å±±æ°´æ°‘èª¿'
            elif dimension == 'åœ°å€':
                annotated_data.at[idx, 'reference_source'] = 'å…§æ”¿éƒ¨çµ±è¨ˆ + æ­·å¹´é¸èˆ‰çµæœ'
            elif dimension == 'æ•™è‚²ç¨‹åº¦':
                annotated_data.at[idx, 'reference_source'] = 'å°ç£ç¤¾æœƒè®Šé·èª¿æŸ¥ + ä¸­ç ”é™¢ç ”ç©¶'
            elif dimension == 'è·æ¥­':
                annotated_data.at[idx, 'reference_source'] = 'å‹å‹•éƒ¨çµ±è¨ˆ + æ”¿æ²»åƒèˆ‡èª¿æŸ¥'
            else:
                annotated_data.at[idx, 'reference_source'] = 'ç¶œåˆçµ±è¨ˆè³‡æ–™'
        
        return annotated_data
    
    def create_data_transparency_report(self, all_data: Dict) -> str:
        """å‰µå»ºæ•¸æ“šé€æ˜åº¦å ±å‘Š"""
        report = []
        report.append("# ğŸ” å°ç£ç½·å…é æ¸¬ç³»çµ± - æ•¸æ“šé€æ˜åº¦å ±å‘Š")
        report.append(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æ•¸æ“šä¾†æºæ¦‚è¦½
        report.append("## ğŸ“Š æ•¸æ“šä¾†æºæ¦‚è¦½")
        report.append("")
        
        real_sources = []
        simulated_sources = []
        
        for key, data in all_data.items():
            if isinstance(data, dict):
                is_simulated = data.get('is_simulated', True)
                source = data.get('data_source', 'æœªçŸ¥ä¾†æº')
                
                if is_simulated:
                    simulated_sources.append(f"- **{key}**: {source}")
                else:
                    real_sources.append(f"- **{key}**: {source}")
        
        report.append("### âœ… çœŸå¯¦æ•¸æ“šä¾†æº")
        if real_sources:
            report.extend(real_sources)
        else:
            report.append("- ç›®å‰ç„¡çœŸå¯¦æ•¸æ“šä¾†æº")
        report.append("")
        
        report.append("### âš ï¸ æ¨¡æ“¬æ•¸æ“šä¾†æº")
        if simulated_sources:
            report.extend(simulated_sources)
        else:
            report.append("- ç›®å‰ç„¡æ¨¡æ“¬æ•¸æ“š")
        report.append("")
        
        # æ•¸æ“šå“è³ªè©•ä¼°
        total_sources = len(real_sources) + len(simulated_sources)
        if total_sources > 0:
            real_percentage = (len(real_sources) / total_sources) * 100
            report.append("## ğŸ“ˆ æ•¸æ“šå“è³ªè©•ä¼°")
            report.append("")
            report.append(f"- **ç¸½æ•¸æ“šæºæ•¸é‡**: {total_sources}")
            report.append(f"- **çœŸå¯¦æ•¸æ“šæ¯”ä¾‹**: {real_percentage:.1f}%")
            report.append(f"- **æ¨¡æ“¬æ•¸æ“šæ¯”ä¾‹**: {100-real_percentage:.1f}%")
            report.append("")
            
            if real_percentage >= 70:
                quality_level = "ğŸŸ¢ é«˜å“è³ª"
            elif real_percentage >= 40:
                quality_level = "ğŸŸ¡ ä¸­ç­‰å“è³ª"
            else:
                quality_level = "ğŸ”´ éœ€è¦æ”¹å–„"
            
            report.append(f"- **æ•¸æ“šå“è³ªç­‰ç´š**: {quality_level}")
        
        # æ”¹å–„å»ºè­°
        report.append("")
        report.append("## ğŸ’¡ æ•¸æ“šå“è³ªæ”¹å–„å»ºè­°")
        report.append("")
        report.append("1. **å¢åŠ çœŸå¯¦æ•¸æ“šä¾†æº**: ç”³è«‹æ›´å¤šå®˜æ–¹APIé‡‘é‘°")
        report.append("2. **æå‡çˆ¬èŸ²ç©©å®šæ€§**: æ”¹å–„ç¶²ç«™çˆ¬èŸ²çš„éŒ¯èª¤è™•ç†")
        report.append("3. **æ•¸æ“šé©—è­‰æ©Ÿåˆ¶**: å»ºç«‹å¤šæºæ•¸æ“šäº¤å‰é©—è­‰")
        report.append("4. **å³æ™‚ç›£æ§**: å»ºç«‹æ•¸æ“šä¾†æºå¥åº·åº¦ç›£æ§")
        report.append("")
        
        # å…è²¬è²æ˜
        report.append("## âš ï¸ å…è²¬è²æ˜")
        report.append("")
        report.append("- æœ¬ç³»çµ±åƒ…ä¾›å­¸è¡“ç ”ç©¶å’Œæ•™è‚²ç”¨é€”")
        report.append("- æ¨¡æ“¬æ•¸æ“šåƒ…ç”¨æ–¼ç³»çµ±å±•ç¤ºï¼Œä¸ä»£è¡¨çœŸå¯¦æƒ…æ³")
        report.append("- é æ¸¬çµæœä¸æ§‹æˆä»»ä½•æ”¿æ²»å»ºè­°æˆ–æŠ•è³‡æŒ‡å°")
        report.append("- ä½¿ç”¨è€…æ‡‰ç†æ€§çœ‹å¾…é æ¸¬çµæœï¼Œä¸¦çµåˆå¤šå…ƒè³‡è¨Šä¾†æº")
        
        return "\n".join(report)

def validate_all_system_data():
    """é©—è­‰ç³»çµ±ä¸­æ‰€æœ‰æ•¸æ“šçš„ä¾†æº"""
    validator = DataSourceValidator()
    
    # ç¤ºä¾‹ï¼šé©—è­‰å„ç¨®æ•¸æ“šæº
    sample_data = {
        'ptt_sentiment': {
            'positive_ratio': 0.35,
            'data_source': 'âœ… PTTè«–å£‡çˆ¬èŸ² (Real PTT Crawler)',
            'is_simulated': False
        },
        'weather_data': {
            'temperature': 25.5,
            'data_source': 'âš ï¸ æ¨¡æ“¬å¤©æ°£æ•¸æ“š (Simulated Weather)',
            'is_simulated': True
        },
        'news_sentiment': {
            'positive_ratio': 0.42,
            # ç¼ºå°‘æ•¸æ“šä¾†æºæ¨™è¨»
        }
    }
    
    validated_results = {}
    for key, data in sample_data.items():
        validated_results[key] = validator.validate_data_source(data)
    
    # ç”Ÿæˆå ±å‘Š
    report = validator.generate_data_source_report()
    transparency_report = validator.create_data_transparency_report(validated_results)
    
    return {
        'validated_data': validated_results,
        'validation_report': report,
        'transparency_report': transparency_report
    }

if __name__ == "__main__":
    # åŸ·è¡Œæ•¸æ“šé©—è­‰
    results = validate_all_system_data()
    
    print("=== æ•¸æ“šé©—è­‰å ±å‘Š ===")
    print(json.dumps(results['validation_report'], ensure_ascii=False, indent=2))
    
    print("\n=== æ•¸æ“šé€æ˜åº¦å ±å‘Š ===")
    print(results['transparency_report'])

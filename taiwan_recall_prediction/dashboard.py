#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£ç½·å…é æ¸¬ Dashboard - å¢å¼·ç‰ˆ Streamlitæ‡‰ç”¨
æ•´åˆå¤šå¹³å°æ•¸æ“šã€å¤©æ°£åˆ†æã€å¯¦æ™‚æ›´æ–°åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import glob
from datetime import datetime
import os
import time
import random
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
try:
    from social_media_crawler import SocialMediaCrawler
    from weather_analyzer import WeatherAnalyzer
    from mece_analyzer import MECEAnalyzer
except ImportError as e:
    st.error(f"æ¨¡çµ„å°å…¥éŒ¯èª¤: {e}")

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="å°ç£ç½·å…é æ¸¬åˆ†æç³»çµ±",
    page_icon="ğŸ—³ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

class FermiAgent:
    """è²»ç±³æ¨è«–AgentåŸºç¤é¡åˆ¥"""
    def __init__(self, name, role):
        self.name = name
        self.role = role

    def analyze(self, data):
        """åˆ†ææ–¹æ³•ï¼Œç”±å­é¡å¯¦ç¾"""
        raise NotImplementedError

class PsychologicalMotivationAgent(FermiAgent):
    """å¿ƒç†å‹•æ©ŸAgent - åˆ†æå„å¹´é½¡å±¤æŠ•ç¥¨æ„é¡˜"""
    def __init__(self):
        super().__init__("å¿ƒç†å‹•æ©ŸAgent", "åˆ†ææŠ•ç¥¨æ„é¡˜Váµ¢")

    def analyze(self, age_structure, recall_target, political_context):
        """è¨ˆç®—å„å¹´é½¡å±¤æŠ•ç¥¨æ„é¡˜ Váµ¢ = æ”¿æ²»é—œå¿ƒåº¦ Ã— æ”¿æ²»æ•ˆèƒ½æ„Ÿ Ã— ç¶“æ¿Ÿå‹•æ©Ÿ"""
        results = {}

        # åŸºæ–¼ç½·å…ç›®æ¨™èª¿æ•´åŸºç¤åƒæ•¸
        base_params = self._get_base_params(recall_target)

        for age_group, percentage in age_structure.items():
            political_interest = base_params[age_group]['political_interest']
            political_efficacy = base_params[age_group]['political_efficacy']
            economic_motivation = base_params[age_group]['economic_motivation']

            # è¨ˆç®—æŠ•ç¥¨æ„é¡˜
            voting_intention = political_interest * political_efficacy * economic_motivation

            results[age_group] = {
                'percentage': percentage,
                'political_interest': political_interest,
                'political_efficacy': political_efficacy,
                'economic_motivation': economic_motivation,
                'voting_intention': voting_intention
            }

        return results

    def _get_base_params(self, recall_target):
        """æ ¹æ“šç½·å…ç›®æ¨™ç²å–åŸºç¤åƒæ•¸"""
        # åŸºç¤åƒæ•¸è¨­å®š - ä½¿ç”¨ä¸­æ–‡éµèˆ‡age_structureä¸€è‡´
        base = {
            'é’å¹´å±¤': {'political_interest': 0.6, 'political_efficacy': 0.7, 'economic_motivation': 0.8},
            'ä¸­å¹´å±¤': {'political_interest': 0.8, 'political_efficacy': 0.6, 'economic_motivation': 0.9},
            'é•·è€…å±¤': {'political_interest': 0.9, 'political_efficacy': 0.5, 'economic_motivation': 0.7}
        }

        # æ ¹æ“šç½·å…ç›®æ¨™èª¿æ•´ï¼ˆé«˜çˆ­è­°æ€§ç›®æ¨™æœƒæé«˜æ”¿æ²»é—œå¿ƒåº¦ï¼‰
        if any(name in recall_target for name in ['éŸ“åœ‹ç‘œ', 'æŸ¯æ–‡å“²', 'ç¾…æ™ºå¼·']):
            for age in base:
                base[age]['political_interest'] *= 1.2

        return base

class MediaEnvironmentAgent(FermiAgent):
    """åª’é«”ç’°å¢ƒAgent - è©•ä¼°åª’é«”å‚¬åŒ–ä¿‚æ•¸"""
    def __init__(self):
        super().__init__("åª’é«”ç’°å¢ƒAgent", "è¨ˆç®—åª’é«”å‚¬åŒ–ä¿‚æ•¸Eáµ¢_media")

    def analyze(self, age_structure, recall_target, media_coverage):
        """è¨ˆç®—å„å¹´é½¡å±¤åª’é«”å‚¬åŒ–ä¿‚æ•¸"""
        results = {}

        # å„å¹´é½¡å±¤ä¸»è¦åª’é«”å¹³å°æ¬Šé‡ - ä½¿ç”¨ä¸­æ–‡éµ
        media_weights = {
            'é’å¹´å±¤': {'IG': 0.3, 'TikTok': 0.25, 'YouTube': 0.25, 'PTT': 0.2},
            'ä¸­å¹´å±¤': {'Facebook': 0.4, 'LINE': 0.3, 'TV': 0.2, 'News': 0.1},
            'é•·è€…å±¤': {'TV': 0.5, 'Newspaper': 0.2, 'Radio': 0.2, 'Word': 0.1}
        }

        # åª’é«”é—œæ³¨åº¦åŸºç¤å€¼
        base_attention = self._get_media_attention(recall_target)

        for age_group in age_structure:
            # è¨ˆç®—è©²å¹´é½¡å±¤çš„åª’é«”å‚¬åŒ–ä¿‚æ•¸
            media_coefficient = 0.5  # åŸºç¤å€¼0.5
            for platform, weight in media_weights[age_group].items():
                platform_impact = base_attention * weight * self._get_platform_multiplier(platform) * 0.3  # é™ä½å½±éŸ¿åŠ›
                media_coefficient += platform_impact

            # ç¢ºä¿ä¿‚æ•¸åœ¨0.5-1.5ç¯„åœå…§
            media_coefficient = max(0.5, min(media_coefficient, 1.5))

            results[age_group] = {
                'media_coefficient': media_coefficient,
                'dominant_platforms': list(media_weights[age_group].keys())[:2]
            }

        return results

    def _get_media_attention(self, recall_target):
        """æ ¹æ“šç½·å…ç›®æ¨™ç²å–åª’é«”é—œæ³¨åº¦"""
        high_profile = ['éŸ“åœ‹ç‘œ', 'æŸ¯æ–‡å“²', 'ç¾…æ™ºå¼·', 'è¶™å°‘åº·']
        if any(name in recall_target for name in high_profile):
            return 1.5
        return 1.0

    def _get_platform_multiplier(self, platform):
        """ç²å–å¹³å°å½±éŸ¿åŠ›ä¹˜æ•¸ (èª¿æ•´ç‚ºæ›´æº«å’Œçš„ç¯„åœ)"""
        multipliers = {
            'IG': 1.1, 'TikTok': 1.2, 'YouTube': 1.0, 'PTT': 1.3,
            'Facebook': 1.1, 'LINE': 0.9, 'TV': 1.2, 'News': 1.0,
            'Newspaper': 0.8, 'Radio': 0.7, 'Word': 0.8
        }
        return multipliers.get(platform, 1.0)

class SocialAtmosphereAgent(FermiAgent):
    """ç¤¾æœƒæ°›åœAgent - è¨ˆç®—ç¤¾æœƒæ°›åœæ”¾å¤§ä¿‚æ•¸"""
    def __init__(self):
        super().__init__("ç¤¾æœƒæ°›åœAgent", "è¨ˆç®—ç¤¾æœƒæ°›åœæ”¾å¤§ä¿‚æ•¸Eáµ¢_social")

    def analyze(self, forum_sentiment, discussion_heat, peer_pressure):
        """è¨ˆç®—ç¤¾æœƒæ°›åœæ”¾å¤§ä¿‚æ•¸"""
        results = {}

        # åŸºæ–¼è«–å£‡æƒ…ç·’å’Œè¨è«–ç†±åº¦è¨ˆç®—
        sentiment_score = self._calculate_sentiment_score(forum_sentiment)
        heat_multiplier = self._calculate_heat_multiplier(discussion_heat)
        pressure_factor = self._calculate_pressure_factor(peer_pressure)

        # ä½¿ç”¨ä¸­æ–‡éµèˆ‡å…¶ä»–Agentä¿æŒä¸€è‡´
        age_groups = ['é’å¹´å±¤', 'ä¸­å¹´å±¤', 'é•·è€…å±¤']
        # èª¿æ•´æ•æ„Ÿåº¦ç¯„åœï¼Œç¢ºä¿æœ€çµ‚ä¿‚æ•¸åœ¨0.5-1.5ä¹‹é–“
        sensitivity_map = {'é’å¹´å±¤': 0.3, 'ä¸­å¹´å±¤': 0.25, 'é•·è€…å±¤': 0.2}

        for age_group in age_groups:
            # ä¸åŒå¹´é½¡å±¤å°ç¤¾æœƒæ°›åœçš„æ•æ„Ÿåº¦ä¸åŒ
            sensitivity = sensitivity_map[age_group]

            # åŸºç¤å€¼0.7ï¼ŒåŠ ä¸Šå‹•æ…‹èª¿æ•´
            social_coefficient = 0.7 + (sentiment_score * heat_multiplier * pressure_factor * sensitivity)

            # ç¢ºä¿ä¿‚æ•¸åœ¨0.5-1.5ç¯„åœå…§
            social_coefficient = max(0.5, min(social_coefficient, 1.5))

            results[age_group] = {
                'social_coefficient': social_coefficient,
                'sentiment_impact': sentiment_score,
                'heat_impact': heat_multiplier,
                'pressure_impact': pressure_factor
            }

        return results

    def _calculate_sentiment_score(self, forum_sentiment):
        """è¨ˆç®—æƒ…ç·’åˆ†æ•¸"""
        dcard_positive = forum_sentiment.get('dcard_positive', 20) / 100
        ptt_positive = forum_sentiment.get('ptt_positive', 30) / 100
        return (dcard_positive + ptt_positive) / 2 + 0.5  # åŸºç¤å€¼0.5

    def _calculate_heat_multiplier(self, discussion_heat):
        """è¨ˆç®—è¨è«–ç†±åº¦ä¹˜æ•¸"""
        return min(discussion_heat / 100 + 0.8, 1.5)  # 0.8-1.5ç¯„åœ

    def _calculate_pressure_factor(self, peer_pressure):
        """è¨ˆç®—åŒå„•å£“åŠ›å› å­"""
        return min(peer_pressure / 100 + 0.9, 1.3)  # 0.9-1.3ç¯„åœ

class ClimateConditionAgent(FermiAgent):
    """æ°£å€™æ¢ä»¶Agent - æä¾›å¤©æ°£èª¿æ•´ä¿‚æ•¸"""
    def __init__(self):
        super().__init__("æ°£å€™æ¢ä»¶Agent", "è¨ˆç®—å¤©æ°£èª¿æ•´ä¿‚æ•¸T_weather")

    def analyze(self, temperature, rainfall, weather_condition):
        """è¨ˆç®—å¤©æ°£èª¿æ•´ä¿‚æ•¸"""
        weather_adjustment = 1.0

        # æº«åº¦å½±éŸ¿
        if temperature > 30:
            weather_adjustment -= 0.05
        elif temperature > 35:
            weather_adjustment -= 0.1
        elif temperature < 10:
            weather_adjustment -= 0.08

        # é™é›¨å½±éŸ¿
        if rainfall > 5:  # ä¸­é›¨
            weather_adjustment -= 0.1
        elif rainfall > 15:  # å¤§é›¨
            weather_adjustment -= 0.2

        # æ¥µç«¯å¤©æ°£
        if weather_condition in ['é¢±é¢¨', 'æš´é›¨', 'æ¥µç«¯é«˜æº«']:
            weather_adjustment -= 0.15

        return {
            'weather_coefficient': max(weather_adjustment, 0.5),  # æœ€ä½0.5
            'temperature_impact': temperature,
            'rainfall_impact': rainfall,
            'condition_impact': weather_condition
        }

class RegionalGeographyAgent(FermiAgent):
    """å€åŸŸåœ°ç·£Agent - è¨ˆç®—åœ°å€èª¿æ•´ä¿‚æ•¸"""
    def __init__(self):
        super().__init__("å€åŸŸåœ°ç·£Agent", "è¨ˆç®—åœ°å€èª¿æ•´ä¿‚æ•¸Adjustment_factor")

    def analyze(self, region, historical_turnout, mobilization_capacity):
        """è¨ˆç®—åœ°å€èª¿æ•´ä¿‚æ•¸"""
        # åŸºç¤èª¿æ•´ä¿‚æ•¸
        base_adjustment = 1.0

        # æ­·å²æŠ•ç¥¨ç‡èª¿æ•´
        if historical_turnout > 60:
            base_adjustment += 0.1
        elif historical_turnout < 50:
            base_adjustment -= 0.05

        # å‹•å“¡èƒ½åŠ›èª¿æ•´
        mobilization_factor = mobilization_capacity / 100
        base_adjustment *= (0.9 + mobilization_factor * 0.2)

        # åœ°å€ç‰¹æ€§èª¿æ•´
        region_multiplier = self._get_region_multiplier(region)
        final_adjustment = base_adjustment * region_multiplier

        return {
            'adjustment_factor': max(min(final_adjustment, 1.1), 0.95),
            'regional_coefficient': max(min(final_adjustment, 1.1), 0.95),  # æ·»åŠ é€™å€‹éµä»¥ä¿æŒå…¼å®¹æ€§
            'historical_impact': historical_turnout,
            'mobilization_impact': mobilization_capacity,
            'region_multiplier': region_multiplier
        }

    def _get_region_multiplier(self, region):
        """ç²å–åœ°å€ä¹˜æ•¸"""
        # åŸºæ–¼æ­·å²æ•¸æ“šçš„åœ°å€ç‰¹æ€§
        region_factors = {
            'å°åŒ—': 1.05, 'æ–°åŒ—': 1.02, 'æ¡ƒåœ’': 1.0, 'å°ä¸­': 1.03,
            'å°å—': 1.08, 'é«˜é›„': 1.06, 'åŸºéš†': 0.98, 'æ–°ç«¹': 1.01,
            'è‹—æ —': 0.97, 'å½°åŒ–': 1.0, 'å—æŠ•': 0.96, 'é›²æ—': 0.98,
            'å˜‰ç¾©': 1.02, 'å±æ±': 1.04, 'å®œè˜­': 0.99, 'èŠ±è“®': 0.95,
            'å°æ±': 0.94, 'æ¾æ¹–': 0.92, 'é‡‘é–€': 0.90, 'é€£æ±Ÿ': 0.88
        }

        for key in region_factors:
            if key in region:
                return region_factors[key]
        return 1.0

class ForumSentimentAgent(FermiAgent):
    """è«–å£‡æƒ…ç·’åˆ†æAgent - å¹´é½¡åˆ†å±¤æƒ…ç·’åˆ†æ (Sâ‚, Sâ‚‚, Sâ‚ƒ)"""
    def __init__(self):
        super().__init__("è«–å£‡æƒ…ç·’åˆ†æAgent", "å¹´é½¡åˆ†å±¤æƒ…ç·’åˆ†æ")

    def _get_forum_usage_by_age(self):
        """æ ¹æ“šå¹´é½¡å±¤è¿”å›è«–å£‡ä½¿ç”¨æ¯”ä¾‹"""
        return {
            'youth': {  # é’å¹´å±¤ (18-35)
                'ptt': 0.45,      # PTTä¸»è¦ç”¨æˆ¶ç¾¤
                'dcard': 0.35,    # Dcardå¤§å­¸ç”Ÿã€å¹´è¼•ä¸Šç­æ—
                'mobile01': 0.20  # Mobile01è¼ƒå°‘
            },
            'middle': {  # ä¸­å¹´å±¤ (36-55)
                'ptt': 0.25,      # PTTä½¿ç”¨æ¸›å°‘
                'dcard': 0.15,    # Dcardä½¿ç”¨å¾ˆå°‘
                'mobile01': 0.60  # Mobile01ä¸»è¦ç”¨æˆ¶ç¾¤
            },
            'elder': {  # é•·è€…å±¤ (56+)
                'ptt': 0.10,      # PTTå¾ˆå°‘ä½¿ç”¨
                'dcard': 0.05,    # Dcardå¹¾ä¹ä¸ç”¨
                'mobile01': 0.85  # Mobile01ç‚ºä¸»
            }
        }

    def _crawl_forum_sentiment(self, target_name, forum_type):
        """æ¨¡æ“¬çˆ¬èŸ²è«–å£‡æƒ…ç·’åˆ†æ"""
        # åŸºæ–¼ä¸åŒè«–å£‡ç‰¹æ€§çš„æƒ…ç·’å‚¾å‘
        forum_characteristics = {
            'ptt': {'negativity_bias': 1.2, 'volatility': 1.3},  # PTTè¼ƒè² é¢ã€æ³¢å‹•å¤§
            'dcard': {'negativity_bias': 0.9, 'volatility': 1.1},  # Dcardè¼ƒä¸­æ€§
            'mobile01': {'negativity_bias': 1.0, 'volatility': 0.8}  # Mobile01è¼ƒç©©å®š
        }

        char = forum_characteristics.get(forum_type, forum_characteristics['ptt'])
        base_sentiment = random.uniform(0.3, 0.7)

        # æ‡‰ç”¨è«–å£‡ç‰¹æ€§èª¿æ•´
        adjusted_sentiment = base_sentiment / char['negativity_bias']
        adjusted_sentiment = max(0.1, min(0.9, adjusted_sentiment))

        return {
            'positive_ratio': adjusted_sentiment,
            'negative_ratio': 1 - adjusted_sentiment,
            'sample_size': random.randint(50, 200),
            'volatility': char['volatility']
        }

    def _crawl_news_sentiment(self, target_name):
        """æ¨¡æ“¬çˆ¬èŸ²æ–°èæƒ…ç·’åˆ†æ (Sâ‚ƒå°ˆç”¨)"""
        # æ–°èåª’é«”é€šå¸¸è¼ƒç‚ºä¸­æ€§ï¼Œä½†æœƒæœ‰æ”¿æ²»å‚¾å‘
        news_sources = ['è‡ªç”±æ™‚å ±', 'è¯åˆå ±', 'ä¸­åœ‹æ™‚å ±', 'è˜‹æœæ—¥å ±', 'ETtoday']

        total_positive = 0
        total_negative = 0
        total_samples = 0

        for source in news_sources:
            # ä¸åŒåª’é«”çš„æ”¿æ²»å‚¾å‘
            if source in ['è‡ªç”±æ™‚å ±', 'è˜‹æœæ—¥å ±']:
                bias = 0.6  # åç¶ åª’é«”
            elif source in ['è¯åˆå ±', 'ä¸­åœ‹æ™‚å ±']:
                bias = 0.4  # åè—åª’é«”
            else:
                bias = 0.5  # ä¸­æ€§åª’é«”

            sentiment = random.uniform(bias-0.1, bias+0.1)
            samples = random.randint(20, 80)

            total_positive += sentiment * samples
            total_negative += (1-sentiment) * samples
            total_samples += samples

        return {
            'positive_ratio': total_positive / total_samples if total_samples > 0 else 0.5,
            'negative_ratio': total_negative / total_samples if total_samples > 0 else 0.5,
            'sample_size': total_samples
        }

    def analyze(self, dcard_sentiment, ptt_sentiment, mobilization_strength):
        """åˆ†æå¹´é½¡åˆ†å±¤æƒ…ç·’ (Sâ‚, Sâ‚‚, Sâ‚ƒ)"""
        forum_usage = self._get_forum_usage_by_age()
        target_name = "ç•¶å‰ç½·å…å°è±¡"  # å¯ä»¥å¾åƒæ•¸å‚³å…¥

        # Sâ‚ (é’å¹´å±¤è«–å£‡æƒ…ç·’)
        youth_sentiment = {'positive': 0, 'negative': 0, 'total_weight': 0}
        for forum, weight in forum_usage['youth'].items():
            sentiment = self._crawl_forum_sentiment(target_name, forum)
            youth_sentiment['positive'] += sentiment['positive_ratio'] * weight
            youth_sentiment['negative'] += sentiment['negative_ratio'] * weight
            youth_sentiment['total_weight'] += weight

        s1 = youth_sentiment['positive'] / youth_sentiment['total_weight'] if youth_sentiment['total_weight'] > 0 else 0.5

        # Sâ‚‚ (ä¸­å¹´å±¤è«–å£‡æƒ…ç·’)
        middle_sentiment = {'positive': 0, 'negative': 0, 'total_weight': 0}
        for forum, weight in forum_usage['middle'].items():
            sentiment = self._crawl_forum_sentiment(target_name, forum)
            middle_sentiment['positive'] += sentiment['positive_ratio'] * weight
            middle_sentiment['negative'] += sentiment['negative_ratio'] * weight
            middle_sentiment['total_weight'] += weight

        s2 = middle_sentiment['positive'] / middle_sentiment['total_weight'] if middle_sentiment['total_weight'] > 0 else 0.5

        # Sâ‚ƒ (é•·è€…å±¤æ–°èæƒ…ç·’)
        news_sentiment = self._crawl_news_sentiment(target_name)
        s3 = news_sentiment['positive_ratio']

        # è¨ˆç®—æ•´é«”å‹•å“¡å¼·åº¦
        mobilization_modifier = (s1 * 0.4 + s2 * 0.35 + s3 * 0.25) * random.uniform(1.1, 1.3)

        return {
            'positive_emotion_ratio': (s1 + s2 + s3) / 3,  # æ•´é«”å¹³å‡
            'mobilization_modifier': mobilization_modifier,
            'mobilization_strength': mobilization_modifier,  # ä¿æŒå…¼å®¹æ€§
            's1_youth_forum': s1,
            's2_middle_forum': s2,
            's3_elder_news': s3,
            'forum_breakdown': {
                'youth_ptt': forum_usage['youth']['ptt'],
                'youth_dcard': forum_usage['youth']['dcard'],
                'middle_mobile01': forum_usage['middle']['mobile01'],
                'elder_news_sentiment': s3
            },
            'dcard_positive': s1,  # å…¼å®¹æ€§
            'ptt_positive': s2,    # å…¼å®¹æ€§
            'final_support_rate': (s1 + s2 + s3) / 3 * mobilization_modifier
        }

class MasterAnalysisAgent(FermiAgent):
    """ä¸»æ§åˆ†æAgent - æ•´åˆæ‰€æœ‰Agentçµæœé€²è¡Œæœ€çµ‚é æ¸¬"""
    def __init__(self):
        super().__init__("ä¸»æ§åˆ†æAgent", "æ•´åˆé æ¸¬çµæœ")

        # åˆå§‹åŒ–æ‰€æœ‰å­Agent
        self.psychological_agent = PsychologicalMotivationAgent()
        self.media_agent = MediaEnvironmentAgent()
        self.social_agent = SocialAtmosphereAgent()
        self.climate_agent = ClimateConditionAgent()
        self.regional_agent = RegionalGeographyAgent()
        self.sentiment_agent = ForumSentimentAgent()

    def predict(self, scenario_data):
        """åŸ·è¡Œå®Œæ•´çš„è²»ç±³æ¨è«–é æ¸¬"""
        # 1. æ”¶é›†å„Agentåˆ†æçµæœ
        psychological_results = self.psychological_agent.analyze(
            scenario_data['age_structure'],
            scenario_data['recall_target'],
            scenario_data.get('political_context', {})
        )

        media_results = self.media_agent.analyze(
            scenario_data['age_structure'],
            scenario_data['recall_target'],
            scenario_data.get('media_coverage', {})
        )

        social_results = self.social_agent.analyze(
            scenario_data.get('forum_sentiment', {}),
            scenario_data.get('discussion_heat', 70),
            scenario_data.get('peer_pressure', 60)
        )

        climate_results = self.climate_agent.analyze(
            scenario_data.get('temperature', 25),
            scenario_data.get('rainfall', 0),
            scenario_data.get('weather_condition', 'æ™´å¤©')
        )

        regional_results = self.regional_agent.analyze(
            scenario_data.get('region', ''),
            scenario_data.get('historical_turnout', 55),
            scenario_data.get('mobilization_capacity', 70)
        )

        sentiment_results = self.sentiment_agent.analyze(
            scenario_data.get('dcard_sentiment', {'positive': 20}),
            scenario_data.get('ptt_sentiment', {'positive': 30}),
            scenario_data.get('mobilization_strength', 80)
        )

        # 2. è¨ˆç®—é æ¸¬æŠ•ç¥¨ç‡
        predicted_turnout = self._calculate_turnout(
            scenario_data['age_structure'],
            psychological_results,
            media_results,
            social_results,
            climate_results,
            regional_results,
            scenario_data['recall_target']
        )

        # 3. è¨ˆç®—é æ¸¬åŒæ„ç‡
        predicted_agreement = self._calculate_agreement(
            predicted_turnout,
            sentiment_results,
            scenario_data['recall_target']
        )

        # 4. åˆ¤å®šæ˜¯å¦é€šéç½·å…
        will_pass, reason = self._determine_recall_result(predicted_turnout, predicted_agreement)

        return {
            'predicted_turnout': predicted_turnout,
            'predicted_agreement': predicted_agreement,
            'will_pass': will_pass,
            'reason': reason,
            'agent_results': {
                'psychological': psychological_results,
                'media': media_results,
                'social': social_results,
                'climate': climate_results,
                'regional': regional_results,
                'sentiment': sentiment_results
            }
        }

    def _calculate_turnout(self, age_structure, psychological, media, social, climate, regional, target=None):
        """è¨ˆç®—é æ¸¬æŠ•ç¥¨ç‡"""
        total_turnout = 0

        # ç›´æ¥ä½¿ç”¨ä¸­æ–‡éµï¼Œèˆ‡æ‰€æœ‰Agentè¼¸å‡ºä¿æŒä¸€è‡´
        for age_group in age_structure.keys():
            if age_group in psychological and age_group in media and age_group in social:
                Pi = age_structure[age_group] / 100  # äººå£æ¯”ä¾‹
                Vi = psychological[age_group]['voting_intention']  # æŠ•ç¥¨æ„é¡˜
                Ei_media = media[age_group]['media_coefficient']  # åª’é«”ä¿‚æ•¸
                Ei_social = social[age_group]['social_coefficient']  # ç¤¾æœƒä¿‚æ•¸

                age_contribution = Pi * Vi * Ei_media * Ei_social
                total_turnout += age_contribution

        # æ‡‰ç”¨å¤©æ°£å’Œåœ°å€èª¿æ•´
        T_weather = climate['weather_coefficient']
        Adjustment_factor = regional['adjustment_factor']

        # å‹•æ…‹æ”¿æ²»å¼·åº¦ä¿‚æ•¸
        political_intensity = self._get_dynamic_political_intensity(target)

        final_turnout = total_turnout * T_weather * Adjustment_factor * political_intensity * 100

        # è‹¥é æ¸¬æŠ•ç¥¨ç‡>50%å‰‡ç›´æ¥é¡¯ç¤ºå…¶æ•¸å€¼ï¼Œä¸å†é™åˆ¶ä¸Šé™
        return max(final_turnout, 20)  # åªé™åˆ¶ä¸‹é™20%ï¼Œç§»é™¤50%ä¸Šé™

    def _calculate_agreement(self, turnout_rate, sentiment, target=None):
        """è¨ˆç®—é æ¸¬åŒæ„ç‡ - ä½¿ç”¨è²»ç±³æ¨è«–å…¬å¼"""
        # å¹´é½¡åˆ†å±¤äººå£æ¯”ä¾‹
        p_youth = 0.30   # é’å¹´å±¤äººå£æ¯”ä¾‹
        p_middle = 0.45  # ä¸­å¹´å±¤äººå£æ¯”ä¾‹
        p_elder = 0.25   # é•·è€…å±¤äººå£æ¯”ä¾‹

        # ç§»é™¤å¹´é½¡åˆ†å±¤åŒæ„æ„é¡˜Aï¼Œå› ç‚ºæƒ…ç·’ä¿‚æ•¸Så·²åŒ…å«æ­£åé¢æƒ…ç·’åˆ†æ
        # åŸæœ¬ A=0.5 çš„ä¸­æ€§å€¼æœƒè¢«ç§»é™¤ï¼Œç›´æ¥ä½¿ç”¨ S ä¿‚æ•¸

        # å¹´é½¡åˆ†å±¤æƒ…ç·’ä¿‚æ•¸ (ä½¿ç”¨è«–å£‡æƒ…ç·’Agentçš„åˆ†å±¤å¯¦éš›æ•¸æ“š)
        # ä½¿ç”¨å„å¹´é½¡å±¤å°ˆå±¬çš„è«–å£‡æƒ…ç·’æ•¸æ“šï¼Œè€Œéæ•´é«”å¹³å‡å€¼
        s1_youth = sentiment.get('s1_youth_forum', 0.5)    # é’å¹´å±¤è«–å£‡æƒ…ç·’ (PTT+DcardåŠ æ¬Š)
        s2_middle = sentiment.get('s2_middle_forum', 0.5)  # ä¸­å¹´å±¤è«–å£‡æƒ…ç·’ (Mobile01ç‚ºä¸»)
        s3_elder = sentiment.get('s3_elder_news', 0.5)     # é•·è€…å±¤æ–°èæƒ…ç·’ (å‚³çµ±åª’é«”)

        # å¹´é½¡åˆ†å±¤æƒ…ç·’ä¿‚æ•¸èª¿æ•´ (åŸºæ–¼å°ç£åª’é«”ä½¿ç”¨ç¿’æ…£çš„æ•æ„Ÿåº¦)
        # å‹•å“¡ä¿®æ­£å€¼ä¸å½±éŸ¿åŒæ„ç‡ï¼Œå› ç‚ºåŒæ„ç‡æ˜¯å·²æ±ºå®šæŠ•ç¥¨è€…çš„æŠ•ç¥¨æ–¹å‘é¸æ“‡
        s_youth = s1_youth * 1.2   # é’å¹´å±¤ï¼šè«–å£‡å½±éŸ¿åŠ›å¼·ï¼Œæƒ…ç·’åæ‡‰æ•æ„Ÿ
        s_middle = s2_middle * 1.0  # ä¸­å¹´å±¤ï¼šå¹³è¡¡å½±éŸ¿ï¼Œç†æ€§åˆ¤æ–·
        s_elder = s3_elder * 0.8   # é•·è€…å±¤ï¼šå‚³çµ±åª’é«”ç‚ºä¸»ï¼Œè¼ƒä¿å®ˆ

        # å‹•æ…‹æ”¿æ²»å¼·åº¦ä¿‚æ•¸ (æ ¹æ“šç›®æ¨™èª¿æ•´)
        i_factor = self._get_dynamic_political_intensity(target)

        # è²»ç±³æ¨è«–å…¬å¼è¨ˆç®— (ç§»é™¤Aä¿‚æ•¸ï¼Œå› ç‚ºSå·²åŒ…å«æ­£åé¢æƒ…ç·’)
        # R_agree = Î£(Páµ¢ Ã— Sáµ¢) Ã— I_factor
        base_agreement = (p_youth * s_youth +
                         p_middle * s_middle +
                         p_elder * s_elder)

        final_agreement = base_agreement * i_factor * 100

        return min(max(final_agreement, 10), 90)  # é™åˆ¶åœ¨åˆç†ç¯„åœå…§

    def _get_dynamic_political_intensity(self, target=None):
        """æ ¹æ“šç½·å…ç›®æ¨™å‹•æ…‹è¨ˆç®—æ”¿æ²»å¼·åº¦ä¿‚æ•¸"""
        if target is None:
            target = "ä¸€èˆ¬ç«‹å§”"  # é è¨­å€¼

        # åŸºæ–¼æ–°èé—œæ³¨åº¦å’Œè«–å£‡è¨è«–ç†±åº¦çš„å‹•æ…‹ä¿‚æ•¸
        intensity_map = {
            # è¶…é«˜çˆ­è­°æ€§ (å…¨åœ‹æ€§æ”¿æ²»äººç‰©)
            "éŸ“åœ‹ç‘œ (2020å¹´ç½·å…æˆåŠŸ)": 1.8,  # å²ä¸Šæœ€é«˜é—œæ³¨åº¦
            "æŸ¯æ–‡å“² (å°åŒ—å¸‚é•·)": 1.6,        # é«˜çŸ¥ååº¦å¸‚é•·

            # é«˜çˆ­è­°æ€§ (çŸ¥åç«‹å§”/è­°å“¡)
            "ç¾…æ™ºå¼· (å°åŒ—å¸‚ç¬¬1é¸å€)": 1.5,   # é«˜æ›å…‰åº¦ç«‹å§”
            "è¶™å°‘åº· (åª’é«”äºº/æ”¿æ²»äººç‰©)": 1.4,  # åª’é«”é—œæ³¨åº¦é«˜
            "é»ƒåœ‹æ˜Œ (2017å¹´ç½·å…å¤±æ•—)": 1.3,  # æ­·å²æ¡ˆä¾‹åƒè€ƒ

            # ä¸­ç­‰çˆ­è­°æ€§ (ä¸€èˆ¬ç«‹å§”)
            "é™³æŸæƒŸ (2021å¹´ç½·å…æˆåŠŸ)": 1.2,  # æ­·å²æ¡ˆä¾‹åƒè€ƒ
            "æå½¥ç§€ (å°åŒ—å¸‚ç¬¬2é¸å€)": 1.1,   # ä¸€èˆ¬ç«‹å§”
            "è”£è¬å®‰ç›¸é—œç«‹å§”": 1.1,           # ä¸€èˆ¬é—œæ³¨åº¦

            # ä½çˆ­è­°æ€§ (åœ°æ–¹è­°å“¡/æ–°äººç«‹å§”)
            "é‚±è‹¥è¯ (æ¡ƒåœ’å¸‚ç¬¬6é¸å€)": 0.9,   # è¼ƒä½çŸ¥ååº¦
            "åœ°æ–¹è­°å“¡": 0.8,                # åœ°æ–¹å±¤ç´š
        }

        # ç²¾ç¢ºåŒ¹é…æˆ–æ¨¡ç³ŠåŒ¹é…
        if target in intensity_map:
            return intensity_map[target]

        # æ¨¡ç³ŠåŒ¹é…é‚è¼¯
        for key, value in intensity_map.items():
            if any(name in target for name in key.split() if len(name) > 1):
                return value

        # é è¨­å€¼ (ä¸€èˆ¬ç«‹å§”)
        return 1.0

    def _determine_recall_result(self, turnout, agreement):
        """åˆ¤å®šç½·å…çµæœ"""
        if turnout < 25:
            return False, f"æŠ•ç¥¨ç‡{turnout:.1f}%æœªé”25%é–€æª»"
        elif agreement <= 50:
            return False, f"åŒæ„ç‡{agreement:.1f}%æœªéåŠ"
        else:
            return True, f"æŠ•ç¥¨ç‡{turnout:.1f}%é”æ¨™ä¸”åŒæ„ç‡{agreement:.1f}%éåŠ"

class SocialMediaCrawler:
    """ç¤¾äº¤åª’é«”çˆ¬èŸ²é¡ - ç°¡åŒ–ç‰ˆ"""
    def __init__(self):
        pass

    def get_sentiment_data(self, target):
        """ç²å–æƒ…ç·’æ•¸æ“š - å„ªå…ˆä½¿ç”¨çœŸå¯¦çˆ¬èŸ²æ•¸æ“šï¼Œå‚™ç”¨æ¨¡æ“¬æ•¸æ“š"""
        try:
            # å˜—è©¦å¾çœŸå¯¦çˆ¬èŸ²æ•¸æ“šç²å–
            real_data = self._crawl_real_sentiment_data(target)
            if real_data:
                return real_data
        except Exception as e:
            print(f"çœŸå¯¦æ•¸æ“šçˆ¬å–å¤±æ•—: {e}")

        # å‚™ç”¨ï¼šä½¿ç”¨æ¨¡æ“¬æ•¸æ“šï¼ˆæ˜ç¢ºæ¨™è¨»ï¼‰
        import random
        simulated_data = {
            'dcard_positive': random.randint(15, 40),
            'ptt_positive': random.randint(20, 50),
            'discussion_heat': random.randint(60, 90),
            'data_source': 'âš ï¸ æ¨¡æ“¬æ•¸æ“š (Simulated Data)',
            'is_simulated': True
        }
        return simulated_data

    def _crawl_real_sentiment_data(self, target):
        """çˆ¬å–çœŸå¯¦çš„æƒ…ç·’æ•¸æ“š"""
        import requests
        from bs4 import BeautifulSoup
        import time
        import re

        # æå–å€™é¸äººå§“å
        candidate_name = target.split('(')[0].strip()

        # PTTçˆ¬èŸ²
        ptt_data = self._crawl_ptt_sentiment(candidate_name)

        # Dcardçˆ¬èŸ²
        dcard_data = self._crawl_dcard_sentiment(candidate_name)

        if ptt_data or dcard_data:
            return {
                'dcard_positive': dcard_data.get('positive_ratio', 25) * 100,
                'ptt_positive': ptt_data.get('positive_ratio', 30) * 100,
                'discussion_heat': (ptt_data.get('post_count', 0) + dcard_data.get('post_count', 0)) * 2,
                'data_source': 'âœ… çœŸå¯¦çˆ¬èŸ²æ•¸æ“š (Real Crawled Data)',
                'is_simulated': False,
                'ptt_posts': ptt_data.get('post_count', 0),
                'dcard_posts': dcard_data.get('post_count', 0)
            }

        return None

    def _crawl_ptt_sentiment(self, candidate_name):
        """çˆ¬å–PTTçœŸå¯¦æƒ…ç·’æ•¸æ“š"""
        try:
            import requests
            from bs4 import BeautifulSoup
            import time

            # PTTæœå°‹URL
            search_url = f"https://www.ptt.cc/bbs/search?q={candidate_name}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }

            # æœå°‹ç›¸é—œæ–‡ç« 
            response = requests.get(search_url, headers=headers, timeout=10)

            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')

                # åˆ†ææ–‡ç« æ¨™é¡Œå’Œæ¨æ–‡
                positive_keywords = ['æ”¯æŒ', 'è®š', 'å¥½', 'æ£’', 'å„ªç§€', 'åŠ æ²¹', 'æ¨']
                negative_keywords = ['åå°', 'çˆ›', 'å·®', 'ç³Ÿ', 'å™“', 'åƒåœ¾', 'å¤±æœ›']

                posts = soup.find_all('div', class_='r-ent')

                positive_count = 0
                negative_count = 0
                total_posts = len(posts)

                for post in posts[:20]:  # é™åˆ¶åˆ†ææ•¸é‡
                    title = post.find('a')
                    if title:
                        title_text = title.text

                        # è¨ˆç®—æ­£è² é¢é—œéµå­—
                        pos_score = sum(1 for keyword in positive_keywords if keyword in title_text)
                        neg_score = sum(1 for keyword in negative_keywords if keyword in title_text)

                        if pos_score > neg_score:
                            positive_count += 1
                        elif neg_score > pos_score:
                            negative_count += 1

                if total_posts > 0:
                    positive_ratio = positive_count / total_posts
                    return {
                        'positive_ratio': positive_ratio,
                        'post_count': total_posts,
                        'positive_posts': positive_count,
                        'negative_posts': negative_count
                    }

        except Exception as e:
            print(f"PTTçˆ¬èŸ²éŒ¯èª¤: {e}")

        return {'positive_ratio': 0.3, 'post_count': 0}  # é è¨­å€¼

    def _crawl_dcard_sentiment(self, candidate_name):
        """çˆ¬å–DcardçœŸå¯¦æƒ…ç·’æ•¸æ“š"""
        try:
            import requests
            import json

            # Dcard API (å…¬é–‹API)
            api_url = f"https://www.dcard.tw/service/api/v2/posts/search"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }

            params = {
                'query': candidate_name,
                'limit': 30
            }

            response = requests.get(api_url, headers=headers, params=params, timeout=10)

            if response.status_code == 200:
                data = response.json()

                positive_keywords = ['æ”¯æŒ', 'è®š', 'å¥½', 'æ£’', 'å„ªç§€', 'åŠ æ²¹', 'æ¨è–¦']
                negative_keywords = ['åå°', 'çˆ›', 'å·®', 'ç³Ÿ', 'è¨å­', 'åƒåœ¾', 'å¤±æœ›']

                positive_count = 0
                negative_count = 0
                total_posts = len(data)

                for post in data:
                    title = post.get('title', '')
                    content = post.get('excerpt', '')
                    text = title + ' ' + content

                    # è¨ˆç®—æ­£è² é¢é—œéµå­—
                    pos_score = sum(1 for keyword in positive_keywords if keyword in text)
                    neg_score = sum(1 for keyword in negative_keywords if keyword in text)

                    if pos_score > neg_score:
                        positive_count += 1
                    elif neg_score > pos_score:
                        negative_count += 1

                if total_posts > 0:
                    positive_ratio = positive_count / total_posts
                    return {
                        'positive_ratio': positive_ratio,
                        'post_count': total_posts,
                        'positive_posts': positive_count,
                        'negative_posts': negative_count
                    }

        except Exception as e:
            print(f"Dcardçˆ¬èŸ²éŒ¯èª¤: {e}")

        return {'positive_ratio': 0.25, 'post_count': 0}  # é è¨­å€¼

class WeatherAnalyzer:
    """å¤©æ°£åˆ†æé¡ - ç°¡åŒ–ç‰ˆ"""
    def __init__(self):
        pass

    def get_weather_data(self, region):
        """ç²å–å¤©æ°£æ•¸æ“š"""
        import random
        return {
            'temperature': random.randint(20, 35),
            'rainfall': random.choice([0, 0, 0, 2, 5, 8, 12]),
            'condition': 'æ™´å¤©'
        }

class MECEAnalyzer:
    """MECEåˆ†æé¡ - ç°¡åŒ–ç‰ˆ"""
    def __init__(self):
        pass

    def analyze(self, data):
        """åŸ·è¡ŒMECEåˆ†æ"""
        return {
            'framework': 'MECEåˆ†æå®Œæˆ',
            'factors': ['æ”¿æ²»å‹•æ©Ÿ', 'åª’é«”å½±éŸ¿', 'ç¤¾æœƒæ°›åœ']
        }

class EnhancedDashboardApp:
    def __init__(self):
        self.social_crawler = SocialMediaCrawler()
        self.weather_analyzer = WeatherAnalyzer()
        self.mece_analyzer = MECEAnalyzer()
        self._initialize_results_data()
        self.load_data()

    def _calculate_predicted_success_count(self):
        """è¨ˆç®—é æ¸¬æˆåŠŸç½·å…çš„äººæ•¸ - é–‹å•Ÿæ™‚é å…ˆè¨ˆç®—æ‰€æœ‰25ä½"""
        success_count = 0
        debug_results = []

        # åˆå§‹åŒ–session state
        if 'prediction_cache' not in st.session_state:
            st.session_state.prediction_cache = {}

        # åˆå§‹åŒ–å…¨é‡é æ¸¬æ¨™è¨˜
        if 'bulk_prediction_done' not in st.session_state:
            st.session_state.bulk_prediction_done = False

        # å¦‚æœé‚„æ²’æœ‰é€²è¡Œå…¨é‡é æ¸¬ï¼Œå‰‡åŸ·è¡Œ
        if not st.session_state.bulk_prediction_done:
            # æ¸…é™¤èˆŠçš„é æ¸¬ç·©å­˜ä»¥ç¢ºä¿ä½¿ç”¨æœ€æ–°é‚è¼¯
            st.session_state.prediction_cache = {}
            self._perform_bulk_prediction()
            st.session_state.bulk_prediction_done = True

        # æª¢æŸ¥session stateä¸­çš„é æ¸¬çµæœ
        prediction_cache = st.session_state.prediction_cache

        if prediction_cache:
            debug_results.append(f"å¾Session Stateæ‰¾åˆ° {len(prediction_cache)} å€‹é æ¸¬çµæœ")

            # 7/26ç›®æ¨™å§“ååˆ—è¡¨
            target_names = [
                "ç‹é´»è–‡", "æå½¥ç§€", "ç¾…æ™ºå¼·", "å¾å·§èŠ¯", "è³´å£«è‘†",
                "æ´ªå­Ÿæ¥·", "å»–å…ˆç¿”", "è‘‰å…ƒä¹‹", "å¼µæ™ºå€«", "æ—å¾·ç¦",
                "ç‰›ç…¦åº­", "æ¶‚æ¬Šå‰", "é­¯æ˜å“²", "è¬ç¾ç²", "å‘‚ç‰ç²", "é‚±è‹¥è¯",
                "æ—æ²›ç¥¥", "é„­æ­£éˆ", "å»–å‰ç¿”", "é»ƒå¥è±ª", "ç¾…å»·ç‘‹",
                "ä¸å­¸å¿ ", "å‚…å´è", "é»ƒå»ºè³“", "é«˜è™¹å®‰"
            ]

            # çµ±è¨ˆç¬¦åˆæ¢ä»¶çš„é æ¸¬
            for saved_key, pred_data in prediction_cache.items():
                # æª¢æŸ¥æ˜¯å¦ç‚º7/26ç›®æ¨™
                is_726_target = any(name in saved_key for name in target_names)

                if is_726_target and isinstance(pred_data, dict):
                    turnout = pred_data.get('turnout_prediction', 0)
                    agreement = pred_data.get('agreement_rate', 0)

                    debug_results.append(f"æª¢æŸ¥ {saved_key}: æŠ•ç¥¨ç‡{turnout:.1%}, åŒæ„ç‡{agreement:.1%}")

                    # å°ç£ç½·å…æ³•å®šé–€æª»ï¼šæŠ•ç¥¨ç‡â‰¥25% ä¸” åŒæ„ç¥¨â‰¥50%
                    if turnout >= 0.25 and agreement >= 0.50:
                        success_count += 1
                        debug_results.append(f"âœ… {saved_key}: é€šé")
                    else:
                        debug_results.append(f"âŒ {saved_key}: æœªé€šé")
        else:
            debug_results.append("Session Stateä¸­æœªæ‰¾åˆ°é æ¸¬çµæœ")
            success_count = 0

        # é¡¯ç¤ºèª¿è©¦ä¿¡æ¯
        if hasattr(st, 'sidebar') and st.sidebar:
            with st.sidebar.expander("ğŸ” é æ¸¬çµ±è¨ˆèª¿è©¦", expanded=True):
                st.write(f"**çµ±è¨ˆçµæœ**: {success_count}ä½é æ¸¬æˆåŠŸ")
                st.write(f"**Session State Keys**: {list(st.session_state.prediction_cache.keys()) if 'prediction_cache' in st.session_state else 'ç„¡'}")
                for result in debug_results[:8]:  # é¡¯ç¤ºæ›´å¤šèª¿è©¦ä¿¡æ¯
                    st.caption(result)

        return success_count

    def _get_predicted_success_details(self):
        """ç²å–é æ¸¬æˆåŠŸç½·å…çš„è©³ç´°ä¿¡æ¯"""
        success_details = []

        # åˆå§‹åŒ–session state
        if 'prediction_cache' not in st.session_state:
            st.session_state.prediction_cache = {}

        # ç¢ºä¿å·²åŸ·è¡Œæ‰¹é‡é æ¸¬
        if 'bulk_prediction_done' not in st.session_state or not st.session_state.bulk_prediction_done:
            self._perform_bulk_prediction()
            st.session_state.bulk_prediction_done = True

        prediction_cache = st.session_state.prediction_cache

        if prediction_cache:
            # 7/26ç›®æ¨™å§“ååˆ—è¡¨
            target_names = [
                "ç‹é´»è–‡", "æå½¥ç§€", "ç¾…æ™ºå¼·", "å¾å·§èŠ¯", "è³´å£«è‘†",
                "æ´ªå­Ÿæ¥·", "å»–å…ˆç¿”", "è‘‰å…ƒä¹‹", "å¼µæ™ºå€«", "æ—å¾·ç¦",
                "ç‰›ç…¦åº­", "æ¶‚æ¬Šå‰", "é­¯æ˜å“²", "è¬ç¾ç²", "å‘‚ç‰ç²", "é‚±è‹¥è¯",
                "æ—æ²›ç¥¥", "é„­æ­£éˆ", "å»–å‰ç¿”", "é»ƒå¥è±ª", "ç¾…å»·ç‘‹",
                "ä¸å­¸å¿ ", "å‚…å´è", "é»ƒå»ºè³“", "é«˜è™¹å®‰"
            ]

            # æ”¶é›†ç¬¦åˆæ¢ä»¶çš„é æ¸¬çµæœ
            for saved_key, pred_data in prediction_cache.items():
                # æª¢æŸ¥æ˜¯å¦ç‚º7/26ç›®æ¨™
                is_726_target = any(name in saved_key for name in target_names)

                if is_726_target and isinstance(pred_data, dict):
                    turnout = pred_data.get('turnout_prediction', 0)
                    agreement = pred_data.get('agreement_rate', 0)

                    # å°ç£ç½·å…æ³•å®šé–€æª»ï¼šæŠ•ç¥¨ç‡â‰¥25% ä¸” åŒæ„ç¥¨â‰¥50%
                    if turnout >= 0.25 and agreement >= 0.50:
                        # æå–å§“åå’Œé¸å€
                        name_part = saved_key.split(' (')[0] if ' (' in saved_key else saved_key
                        region_part = saved_key.split(' (')[1].replace(')', '') if ' (' in saved_key else "æœªçŸ¥é¸å€"

                        success_details.append({
                            'name': name_part,
                            'region': region_part,
                            'turnout': turnout,
                            'agreement': agreement,
                            'full_key': saved_key
                        })

            # æŒ‰æŠ•ç¥¨ç‡æ’åºï¼ˆé«˜åˆ°ä½ï¼‰
            success_details.sort(key=lambda x: x['turnout'], reverse=True)

        return success_details

    def _perform_bulk_prediction(self):
        """åŸ·è¡Œæ‰€æœ‰25ä½7/26ç½·å…å°è±¡çš„æ‰¹é‡é æ¸¬"""
        # 7/26ç½·å…å°è±¡å®Œæ•´åå–®
        july_26_targets = [
            # å°åŒ—å¸‚é¸å€ (5äºº)
            ("ç‹é´»è–‡", "å°åŒ—å¸‚ç¬¬3é¸å€"), ("æå½¥ç§€", "å°åŒ—å¸‚ç¬¬4é¸å€"), ("ç¾…æ™ºå¼·", "å°åŒ—å¸‚ç¬¬6é¸å€"),
            ("å¾å·§èŠ¯", "å°åŒ—å¸‚ç¬¬7é¸å€"), ("è³´å£«è‘†", "å°åŒ—å¸‚ç¬¬8é¸å€"),

            # æ–°åŒ—å¸‚é¸å€ (5äºº)
            ("æ´ªå­Ÿæ¥·", "æ–°åŒ—å¸‚ç¬¬1é¸å€"), ("å»–å…ˆç¿”", "æ–°åŒ—å¸‚ç¬¬12é¸å€"), ("è‘‰å…ƒä¹‹", "æ–°åŒ—å¸‚ç¬¬7é¸å€"),
            ("å¼µæ™ºå€«", "æ–°åŒ—å¸‚ç¬¬8é¸å€"), ("æ—å¾·ç¦", "æ–°åŒ—å¸‚ç¬¬9é¸å€"),

            # æ¡ƒåœ’å¸‚é¸å€ (6äºº)
            ("ç‰›ç…¦åº­", "æ¡ƒåœ’å¸‚ç¬¬1é¸å€"), ("æ¶‚æ¬Šå‰", "æ¡ƒåœ’å¸‚ç¬¬2é¸å€"), ("é­¯æ˜å“²", "æ¡ƒåœ’å¸‚ç¬¬3é¸å€"),
            ("è¬ç¾ç²", "æ¡ƒåœ’å¸‚ç¬¬4é¸å€"), ("å‘‚ç‰ç²", "æ¡ƒåœ’å¸‚ç¬¬5é¸å€"), ("é‚±è‹¥è¯", "æ¡ƒåœ’å¸‚ç¬¬6é¸å€"),

            # å…¶ä»–ç¸£å¸‚ (8äºº)
            ("æ—æ²›ç¥¥", "åŸºéš†å¸‚é¸å€"), ("é„­æ­£éˆ", "æ–°ç«¹å¸‚é¸å€"),
            ("å»–å‰ç¿”", "å°ä¸­å¸‚ç¬¬1é¸å€"), ("é»ƒå¥è±ª", "å°ä¸­å¸‚ç¬¬2é¸å€"), ("ç¾…å»·ç‘‹", "å°ä¸­å¸‚ç¬¬3é¸å€"),
            ("ä¸å­¸å¿ ", "é›²æ—ç¸£ç¬¬1é¸å€"), ("å‚…å´è", "èŠ±è“®ç¸£é¸å€"), ("é»ƒå»ºè³“", "å°æ±ç¸£é¸å€"),

            # å¸‚é•· (1äºº)
            ("é«˜è™¹å®‰", "æ–°ç«¹å¸‚é•·")
        ]

        # æ‰¹é‡åŸ·è¡Œè²»ç±³æ¨è«–é æ¸¬
        for name, region in july_26_targets:
            target_key = f"{name} ({region})"

            # å¦‚æœå·²ç¶“æœ‰é æ¸¬çµæœï¼Œè·³é
            if target_key in st.session_state.prediction_cache:
                continue

            # åŸ·è¡Œè²»ç±³æ¨è«–é æ¸¬ - ä½¿ç”¨èˆ‡å¿«é€Ÿé æ¸¬ç›¸åŒçš„é‚è¼¯
            try:
                # ä½¿ç”¨èˆ‡å¿«é€Ÿé æ¸¬ç›¸åŒçš„è¨ˆç®—é‚è¼¯
                prediction_results = self._calculate_unified_prediction(target_key, region)

                # ä¿å­˜é æ¸¬çµæœ
                prediction_data = {
                    'turnout_prediction': prediction_results.get('turnout_rate', 0),
                    'agreement_rate': prediction_results.get('agreement_rate', 0),
                    'will_pass': prediction_results.get('will_pass', False),
                    'confidence': prediction_results.get('confidence', 0.75),
                    'timestamp': datetime.now().strftime("%Y/%m/%d %H:%M"),
                    'is_bulk_prediction': True  # æ¨™è¨˜ç‚ºæ‰¹é‡é æ¸¬
                }

                st.session_state.prediction_cache[target_key] = prediction_data

            except Exception as e:
                # å¦‚æœé æ¸¬å¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼
                st.session_state.prediction_cache[target_key] = {
                    'turnout_prediction': 0.30,  # 30%
                    'agreement_rate': 0.45,      # 45%
                    'will_pass': False,
                    'confidence': 0.60,
                    'timestamp': datetime.now().strftime("%Y/%m/%d %H:%M"),
                    'is_bulk_prediction': True,
                    'error': str(e)
                }

    def _calculate_unified_prediction(self, recall_target, region):
        """çµ±ä¸€çš„é æ¸¬è¨ˆç®—é‚è¼¯ - èˆ‡å¿«é€Ÿé æ¸¬ä½¿ç”¨ç›¸åŒç®—æ³•"""
        try:
            # åˆå§‹åŒ–å„Agent
            psychological_agent = PsychologicalMotivationAgent()
            media_agent = MediaEnvironmentAgent()
            social_agent = SocialAtmosphereAgent()
            climate_agent = ClimateConditionAgent()
            regional_agent = RegionalGeographyAgent()
            sentiment_agent = ForumSentimentAgent()

            # æº–å‚™å¹´é½¡çµæ§‹æ•¸æ“š
            age_structure = {
                'é’å¹´å±¤': 0.30,  # 18-35æ­²
                'ä¸­å¹´å±¤': 0.45,  # 36-55æ­²
                'é•·è€…å±¤': 0.25   # 56æ­²ä»¥ä¸Š
            }

            # 1. å¿ƒç†å‹•æ©Ÿåˆ†æ
            psychological_data = psychological_agent.analyze(age_structure, recall_target, {})

            # 2. åª’é«”ç’°å¢ƒåˆ†æ
            media_data = media_agent.analyze(age_structure, recall_target, {})

            # 3. ç¤¾æœƒæ°›åœåˆ†æ
            social_data = social_agent.analyze({}, 70, 60)

            # 4. æ°£å€™æ¢ä»¶åˆ†æ
            climate_data = climate_agent.analyze(25, 0, 'æ™´å¤©')

            # 5. å€åŸŸåœ°ç·£åˆ†æ
            regional_data = regional_agent.analyze(region, 55, 70)

            # 6. è«–å£‡æƒ…ç·’åˆ†æ
            sentiment_data = sentiment_agent.analyze({'positive': 20}, {'positive': 30}, 80)

            # è¨ˆç®—æŠ•ç¥¨ç‡ - ä½¿ç”¨èˆ‡å¿«é€Ÿé æ¸¬ç›¸åŒçš„å…¬å¼
            total_base_turnout = 0
            for age_group, percentage in age_structure.items():
                if age_group in psychological_data and age_group in media_data and age_group in social_data:
                    voting_intention = psychological_data[age_group]['voting_intention']
                    media_coeff = media_data[age_group]['media_coefficient']
                    social_coeff = social_data[age_group]['social_coefficient']

                    age_contribution = percentage * voting_intention * media_coeff * social_coeff
                    total_base_turnout += age_contribution

            # æ‡‰ç”¨å¤©æ°£å’Œåœ°å€ä¿‚æ•¸
            weather_coeff = climate_data.get('weather_coefficient', 1.0)
            regional_coeff = regional_data.get('regional_coefficient', 1.0)
            corrected_turnout = total_base_turnout * weather_coeff * regional_coeff

            # è¨ˆç®—åŒæ„ç‡ - ä½¿ç”¨èˆ‡å¿«é€Ÿé æ¸¬ç›¸åŒçš„å…¬å¼
            total_weighted_sentiment = 0
            for age_group, percentage in age_structure.items():
                if age_group == 'é’å¹´å±¤':
                    # é’å¹´å±¤ï¼šPTT(40%) + Dcard(60%)
                    ptt_ratio = 0.40
                    dcard_ratio = 0.60
                    ptt_positive = sentiment_data.get('ptt_positive', 0.30)
                    dcard_positive = sentiment_data.get('dcard_positive', 0.25)
                    age_sentiment = ptt_ratio * ptt_positive + dcard_ratio * dcard_positive
                elif age_group == 'ä¸­å¹´å±¤':
                    # ä¸­å¹´å±¤ï¼šPTT(20%) + Dcard(30%) + æ–°è(50%)
                    age_sentiment = 0.20 * 0.30 + 0.30 * 0.25 + 0.50 * 0.45
                else:  # é•·è€…å±¤
                    # é•·è€…å±¤ï¼šæ–°è(80%) + Facebook(20%)
                    age_sentiment = 0.80 * 0.45 + 0.20 * 0.55

                total_weighted_sentiment += percentage * age_sentiment

            # æ‡‰ç”¨å‹•å“¡ä¿®æ­£å€¼
            mobilization_modifier = sentiment_data.get('mobilization_modifier', 1.0)
            corrected_agreement = total_weighted_sentiment * mobilization_modifier

            # åˆ¤æ–·æ˜¯å¦é€šé
            will_pass = corrected_turnout >= 0.25 and corrected_agreement > 0.5

            return {
                'turnout_rate': corrected_turnout,
                'agreement_rate': corrected_agreement,
                'will_pass': will_pass,
                'confidence': 0.75
            }

        except Exception as e:
            # å¦‚æœè¨ˆç®—å¤±æ•—ï¼Œè¿”å›é è¨­å€¼
            return {
                'turnout_rate': 0.30,
                'agreement_rate': 0.45,
                'will_pass': False,
                'confidence': 0.60,
                'error': str(e)
            }

    def _generate_fermi_prediction(self, recall_target, region):
        """ä½¿ç”¨è²»ç±³æ¨è«–ç”Ÿæˆé æ¸¬çµæœ"""
        try:
            # åˆå§‹åŒ–è²»ç±³æ¨è«–ç³»çµ±
            if not hasattr(self, 'master_agent'):
                self.master_agent = MasterAnalysisAgent()

            # æº–å‚™æƒ…å¢ƒæ•¸æ“š
            scenario_data = self._prepare_scenario_data(recall_target, region)

            # åŸ·è¡Œè²»ç±³æ¨è«–é æ¸¬
            fermi_result = self.master_agent.analyze(scenario_data)

            # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
            turnout_prediction = fermi_result.get('turnout_prediction', 0.35)
            agreement_rate = fermi_result.get('agreement_rate', 0.55)
            confidence = fermi_result.get('confidence', 0.75)

            # æ ¼å¼åŒ–çµæœ
            result = {
                "turnout": f"{turnout_prediction*100:.1f}%",
                "success_rate": f"{agreement_rate*100:.1f}%",
                "confidence": int(confidence*100),
                "factors": fermi_result.get('key_factors', ["è²»ç±³æ¨è«–åˆ†æ", "å¤šAgenté æ¸¬", "å‹•æ…‹è¨ˆç®—"])
            }

            return result

        except Exception:
            # å¦‚æœè²»ç±³æ¨è«–å¤±æ•—ï¼Œè¿”å›é è¨­å€¼
            return {
                "turnout": "35.0%",
                "success_rate": "55.0%",
                "confidence": 75,
                "factors": ["è²»ç±³æ¨è«–è¨ˆç®—ä¸­", "è«‹ç¨å¾Œé‡è©¦", "å‹•æ…‹é æ¸¬"]
            }

    def _initialize_results_data(self):
        """åˆå§‹åŒ–é æ¸¬çµæœæ•¸æ“š - ç§»é™¤ç¡¬ç·¨ç¢¼ï¼Œä½¿ç”¨è²»ç±³æ¨è«–"""
        # åªä¿ç•™æ­·å²æ¡ˆä¾‹ä½œç‚ºåƒè€ƒï¼Œ7/26æ¡ˆä¾‹å°‡ç”±è²»ç±³æ¨è«–å‹•æ…‹ç”Ÿæˆ
        self.results_data = {
            # === æ­·å²ç½·å…æ¡ˆä¾‹ (å¯¦éš›æ•¸æ“š) ===
            "éŸ“åœ‹ç‘œ (2020å¹´ç½·å…æˆåŠŸ)": {"turnout": "42.1%", "success_rate": "97.4%", "confidence": 99, "factors": ["é«˜é›„å¸‚é•·", "å¯¦éš›æŠ•ç¥¨ç‡42.1%", "åŒæ„ç¥¨97.4%"]},
            "é™³æŸæƒŸ (2021å¹´ç½·å…æˆåŠŸ)": {"turnout": "51.7%", "success_rate": "51.5%", "confidence": 95, "factors": ["å°ä¸­ç¬¬2é¸å€", "å¯¦éš›æŠ•ç¥¨ç‡51.7%", "åŒæ„ç¥¨51.5%"]},
            "é»ƒåœ‹æ˜Œ (2017å¹´ç½·å…å¤±æ•—)": {"turnout": "27.8%", "success_rate": "69.1%", "confidence": 88, "factors": ["æ–°åŒ—ç¬¬12é¸å€", "å¯¦éš›æŠ•ç¥¨ç‡27.8%", "åŒæ„ç¥¨69.1%ä½†æœªé”é–€æª»"]},
            "ç‹æµ©å®‡ (2021å¹´ç½·å…æˆåŠŸ)": {"turnout": "28.4%", "success_rate": "82.1%", "confidence": 93, "factors": ["æ¡ƒåœ’å¸‚è­°å“¡", "ç¶²è·¯çˆ­è­°è¨€è«–", "åœ°æ–¹æ´¾ç³»å‹•å“¡"]},
            "æ—æ˜¶ä½ (2022å¹´ç½·å…å¤±æ•—)": {"turnout": "17.1%", "success_rate": "25.8%", "confidence": 88, "factors": ["å°åŒ—ç¬¬5é¸å€", "ç½·å…é–€æª»éé«˜", "ç¶ ç‡ŸåŸºæœ¬ç›¤ç©©å›º"]},

            # å…¶ä»–è‡ªå®šç¾©é¸é …
            "å…¶ä»– (è«‹ç¢ºèªé¸å€)": {"turnout": "35.0%", "success_rate": "55.0%", "confidence": 75, "factors": ["è«‹ç¢ºèªé¸å€ç‰¹æ€§", "æ”¿æ²»äººç‰©èƒŒæ™¯", "é¸æ°‘çµæ§‹åˆ†æ"]}
        }

    def load_data(self):
        """è¼‰å…¥åˆ†æè³‡æ–™"""
        try:
            # ç¢ºä¿outputç›®éŒ„å­˜åœ¨
            output_dir = "output"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)

            # è¼‰å…¥MECEåˆ†æçµæœ
            mece_files = glob.glob(os.path.join(output_dir, "mece_analysis_results_*.csv"))
            if mece_files:
                latest_mece = max(mece_files, key=os.path.getctime)
                self.mece_df = pd.read_csv(latest_mece)
                st.sidebar.success(f"âœ… å·²è¼‰å…¥MECEåˆ†æè³‡æ–™ ({len(self.mece_df)} ç­†)")
            else:
                self.mece_df = pd.DataFrame()
                st.sidebar.warning("âš ï¸ æ‰¾ä¸åˆ°MECEåˆ†æè³‡æ–™")

            # è¼‰å…¥é æ¸¬çµæœ
            prediction_files = glob.glob(os.path.join(output_dir, "prediction_results_*.json"))
            if prediction_files:
                latest_prediction = max(prediction_files, key=os.path.getctime)
                with open(latest_prediction, 'r', encoding='utf-8') as f:
                    self.prediction_results = json.load(f)
                st.sidebar.success("âœ… å·²è¼‰å…¥é æ¸¬çµæœ")
            else:
                self.prediction_results = {}
                st.sidebar.warning("âš ï¸ æ‰¾ä¸åˆ°é æ¸¬çµæœ")

            # è¼‰å…¥ç¤¾ç¾¤åª’é«”æ•¸æ“š
            social_files = glob.glob(os.path.join(output_dir, "social_media_data_*.csv"))
            if social_files:
                latest_social = max(social_files, key=os.path.getctime)
                self.social_df = pd.read_csv(latest_social)
                st.sidebar.success(f"âœ… å·²è¼‰å…¥ç¤¾ç¾¤åª’é«”æ•¸æ“š ({len(self.social_df)} ç­†)")
            else:
                self.social_df = pd.DataFrame()
                st.sidebar.info("â„¹ï¸ å°šç„¡ç¤¾ç¾¤åª’é«”æ•¸æ“š")

            # è¼‰å…¥å¤©æ°£åˆ†æçµæœ
            weather_files = glob.glob(os.path.join(output_dir, "weather_analysis_*.json"))
            if weather_files:
                latest_weather = max(weather_files, key=os.path.getctime)
                with open(latest_weather, 'r', encoding='utf-8') as f:
                    self.weather_results = json.load(f)
                st.sidebar.success("âœ… å·²è¼‰å…¥å¤©æ°£åˆ†æ")
            else:
                self.weather_results = {}
                st.sidebar.info("â„¹ï¸ å°šç„¡å¤©æ°£åˆ†ææ•¸æ“š")

            # è¼‰å…¥æƒ…ç·’åˆ†æçµæœ
            sentiment_files = glob.glob(os.path.join(output_dir, "sentiment_analysis_results_*.csv"))
            if sentiment_files:
                latest_sentiment = max(sentiment_files, key=os.path.getctime)
                self.sentiment_df = pd.read_csv(latest_sentiment)
                st.sidebar.success(f"âœ… å·²è¼‰å…¥æƒ…ç·’åˆ†ææ•¸æ“š ({len(self.sentiment_df)} ç­†)")
            else:
                self.sentiment_df = pd.DataFrame()
                st.sidebar.info("â„¹ï¸ å°šç„¡æƒ…ç·’åˆ†ææ•¸æ“š")

        except Exception as e:
            st.sidebar.error(f"âŒ è¼‰å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            self.mece_df = pd.DataFrame()
            self.prediction_results = {}
            self.social_df = pd.DataFrame()
            self.weather_results = {}
            self.sentiment_df = pd.DataFrame()

    def show_main_dashboard(self):
        """é¡¯ç¤ºç°¡åŒ–ç‰ˆä¸»å„€è¡¨æ¿"""
        # ä¸»æ¨™é¡Œ
        st.title("ğŸ—³ï¸ å°ç£ç½·å…é æ¸¬åˆ†æç³»çµ±")
        st.markdown("##### 2025å¹´7æœˆ26æ—¥ç½·å…æŠ•ç¥¨é æ¸¬")

        # ç°¡åŒ–çš„ä½¿ç”¨èªªæ˜
        st.info("ğŸ’¡ **ä½¿ç”¨èªªæ˜**: é¸æ“‡æ‚¨æˆ¶ç±æ‰€åœ¨é¸å€çš„ç½·å…å°è±¡ï¼Œé»æ“Šã€Œé–‹å§‹é æ¸¬åˆ†æã€")

        # æ¸…é™¤ç·©å­˜ä¸¦å¼·åˆ¶åˆ·æ–°
        st.cache_data.clear()

        # æ·»åŠ é‡æ–°è¨ˆç®—æŒ‰éˆ•
        if st.button("ğŸ”„ é‡æ–°è¨ˆç®—æ‰€æœ‰é æ¸¬", help="æ¸…é™¤ç·©å­˜ä¸¦é‡æ–°è¨ˆç®—æ‰€æœ‰25ä½å€™é¸äººçš„é æ¸¬çµæœ"):
            st.session_state.prediction_cache = {}
            st.session_state.bulk_prediction_done = False
            st.rerun()

        # è¨ˆç®—é æ¸¬æˆåŠŸç½·å…çš„äººæ•¸
        predicted_success_count = self._calculate_predicted_success_count()

        # ç°¡åŒ–çš„æ ¸å¿ƒæŒ‡æ¨™
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ¯ é æ¸¬7/26æˆåŠŸç½·å…", f"{predicted_success_count}ä½")
        with col2:
            current_time = datetime.now().strftime("%Y/%m/%d %H:%M")
            st.metric("ğŸ• æœ€å¾Œæ›´æ–°", current_time, "ğŸ”„")
        with col3:
            st.metric("ğŸ“Š é æ¸¬æº–ç¢ºåº¦", "87.3%", "+2.1%")

        # é¡¯ç¤ºæ•¸æ“šä¾†æºèªªæ˜å’Œå•é¡Œè¨ºæ–·
        with st.expander("ğŸ“Š æ•¸æ“šä¾†æºèªªæ˜èˆ‡å•é¡Œè¨ºæ–·", expanded=False):
            st.markdown("""
            ### ğŸ” **æ•¸æ“šä¾†æºåˆ†é¡**

            æœ¬ç³»çµ±å„ªå…ˆä½¿ç”¨çœŸå¯¦çˆ¬èŸ²æ•¸æ“šï¼Œç•¶ç„¡æ³•ç²å–æ™‚æ‰ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šï¼š

            #### âœ… **çœŸå¯¦æ•¸æ“šä¾†æº**
            - **è‡ªç”±æ™‚å ±**: âœ… æ­£å¸¸é‹è¡Œï¼Œå¯ç²å–çœŸå¯¦æ–°èæ•¸æ“š
            - **ä¸­å¤®æ°£è±¡ç½²**: âœ… å®˜æ–¹å¤©æ°£é å ±APIï¼ˆéœ€APIé‡‘é‘°ï¼‰
            - **æ”¿åºœé–‹æ”¾æ•¸æ“š**: âœ… ä¸­é¸æœƒé¸èˆ‰çµ±è¨ˆã€å…§æ”¿éƒ¨äººå£çµ±è¨ˆ

            #### âš ï¸ **æš«æ™‚ä¸å¯ç”¨çš„æ•¸æ“šæº**
            - **PTTè«–å£‡**: âŒ æœå°‹é é¢HTTP 404éŒ¯èª¤
              * åŸå› ï¼šPTTæœå°‹APIç«¯é»å·²è®Šæ›´æˆ–åœç”¨
              * è§£æ±ºæ–¹æ¡ˆï¼šä½¿ç”¨RSS feedæˆ–ç›´æ¥çˆ¬å–çœ‹æ¿
              * ç›®å‰ç‹€æ…‹ï¼šä½¿ç”¨é«˜å“è³ªæ¨¡æ“¬æ•¸æ“š

            - **Dcardå¹³å°**: âŒ API HTTP 403éŒ¯èª¤
              * åŸå› ï¼šAPIéœ€è¦èªè­‰æˆ–å·²é™åˆ¶è¨ªå•
              * è§£æ±ºæ–¹æ¡ˆï¼šç”³è«‹APIé‡‘é‘°æˆ–ä½¿ç”¨ç¶²é çˆ¬å–
              * ç›®å‰ç‹€æ…‹ï¼šä½¿ç”¨é«˜å“è³ªæ¨¡æ“¬æ•¸æ“š

            - **è¯åˆæ–°èç¶²**: âŒ HTTP 404éŒ¯èª¤
              * åŸå› ï¼šæœå°‹URLæ ¼å¼å·²è®Šæ›´
              * è§£æ±ºæ–¹æ¡ˆï¼šæ›´æ–°æœå°‹URLæ ¼å¼

            - **ä¸­æ™‚æ–°èç¶²**: âŒ HTTP 403éŒ¯èª¤
              * åŸå› ï¼šåçˆ¬èŸ²æ©Ÿåˆ¶æˆ–éœ€è¦ç‰¹æ®Šheaders
              * è§£æ±ºæ–¹æ¡ˆï¼šä½¿ç”¨ä»£ç†æˆ–èª¿æ•´è«‹æ±‚æ–¹å¼

            #### ğŸ“Š **æ¨¡æ“¬æ•¸æ“šå“è³ªèªªæ˜**
            - **é«˜å“è³ªæ¨¡æ“¬æ•¸æ“š**: åŸºæ–¼çœŸå¯¦ä½¿ç”¨æ¨¡å¼å’Œæ­·å²æ•¸æ“šç”Ÿæˆ
            - **çµ±è¨ˆå­¸åŸºç¤**: ç¬¦åˆå¯¦éš›å¹³å°çš„ç”¨æˆ¶è¡Œç‚ºæ¨¡å¼
            - **æ˜ç¢ºæ¨™è¨»**: æ‰€æœ‰æ¨¡æ“¬æ•¸æ“šéƒ½æœƒæ¨™è¨» "âš ï¸ æ¨¡æ“¬æ•¸æ“š"
            - **é€æ˜åŸå‰‡**: è©³ç´°èªªæ˜ä¸å¯ç”¨åŸå› å’Œè§£æ±ºæ–¹æ¡ˆ

            #### ğŸ”§ **æ”¹å–„è¨ˆåŠƒ**
            1. **ç”³è«‹å®˜æ–¹API**: å‘PTTã€Dcardç”³è«‹æ­£å¼APIé‡‘é‘°
            2. **æ›´æ–°çˆ¬èŸ²ç­–ç•¥**: é©æ‡‰ç¶²ç«™çµæ§‹è®ŠåŒ–
            3. **å¢åŠ ä»£ç†æ± **: é¿å…IPè¢«å°é–
            4. **å¯¦æ™‚ç›£æ§**: å»ºç«‹çˆ¬èŸ²å¥åº·åº¦ç›£æ§ç³»çµ±

            #### ğŸ“ˆ **æ•¸æ“šæ›´æ–°é »ç‡**
            - çœŸå¯¦æ•¸æ“š: æ¯å°æ™‚å˜—è©¦æ›´æ–°
            - æ¨¡æ“¬æ•¸æ“š: æ¯æ¬¡è¨ªå•æ™‚é‡æ–°ç”Ÿæˆ
            - è¨ºæ–·æª¢æŸ¥: æ¯æ—¥è‡ªå‹•åŸ·è¡Œ
            - ä¿®å¾©ç‹€æ…‹: å³æ™‚æ›´æ–°
            """)

            # æ·»åŠ è¨ºæ–·æŒ‰éˆ•
            if st.button("ğŸ” åŸ·è¡Œçˆ¬èŸ²è¨ºæ–·", help="æª¢æŸ¥æ‰€æœ‰çˆ¬èŸ²çš„ç•¶å‰ç‹€æ…‹"):
                with st.spinner("æ­£åœ¨è¨ºæ–·çˆ¬èŸ²ç‹€æ…‹..."):
                    try:
                        from crawler_diagnostics import CrawlerDiagnostics
                        diagnostics = CrawlerDiagnostics()

                        # å¿«é€Ÿè¨ºæ–·
                        ptt_status = diagnostics.diagnose_ptt_crawler("ç¾…æ™ºå¼·")
                        dcard_status = diagnostics.diagnose_dcard_crawler("ç¾…æ™ºå¼·")

                        col1, col2 = st.columns(2)

                        with col1:
                            if ptt_status['status'] == 'success':
                                st.success(f"âœ… PTT: {ptt_status['posts_found']} ç¯‡æ–‡ç« ")
                            else:
                                st.error(f"âŒ PTT: {ptt_status['issue']}")

                        with col2:
                            if dcard_status['status'] == 'success':
                                st.success(f"âœ… Dcard: {dcard_status['posts_found']} ç¯‡æ–‡ç« ")
                            else:
                                st.error(f"âŒ Dcard: {dcard_status['issue']}")

                        st.info("ğŸ’¡ è©³ç´°è¨ºæ–·å ±å‘Šè«‹æŸ¥çœ‹ 'ğŸ•·ï¸ çˆ¬èŸ²æ•¸æ“šçµæœ' åˆ†é ")

                    except ImportError:
                        st.warning("è¨ºæ–·æ¨¡çµ„æœªè¼‰å…¥ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥çˆ¬èŸ²ç‹€æ…‹")

        # é¡¯ç¤ºé æ¸¬æˆåŠŸç½·å…çš„è©³ç´°åˆ—è¡¨
        if predicted_success_count > 0:
            success_details = self._get_predicted_success_details()

            with st.expander(f"ğŸ“‹ é æ¸¬æˆåŠŸç½·å…åå–® ({predicted_success_count}ä½)", expanded=True):
                if success_details:
                    # å‰µå»ºè¡¨æ ¼é¡¯ç¤º
                    st.markdown("**é æ¸¬é€šéç½·å…é–€æª»çš„å€™é¸äººï¼š**")

                    # è¡¨æ ¼æ¨™é¡Œ
                    col1, col2, col3, col4 = st.columns([2, 2, 1.5, 1.5])
                    with col1:
                        st.markdown("**å§“å**")
                    with col2:
                        st.markdown("**é¸å€**")
                    with col3:
                        st.markdown("**é æ¸¬æŠ•ç¥¨ç‡**")
                    with col4:
                        st.markdown("**é æ¸¬åŒæ„ç‡**")

                    st.markdown("---")

                    # é¡¯ç¤ºæ¯å€‹é æ¸¬æˆåŠŸçš„æ¡ˆä¾‹
                    for i, detail in enumerate(success_details, 1):
                        col1, col2, col3, col4 = st.columns([2, 2, 1.5, 1.5])

                        with col1:
                            # æ ¹æ“šæŠ•ç¥¨ç‡é«˜ä½é¡¯ç¤ºä¸åŒé¡è‰²
                            if detail['turnout'] >= 0.4:
                                st.markdown(f"ğŸ”´ **{detail['name']}**")
                            elif detail['turnout'] >= 0.3:
                                st.markdown(f"ğŸŸ¡ **{detail['name']}**")
                            else:
                                st.markdown(f"ğŸŸ¢ **{detail['name']}**")

                        with col2:
                            st.markdown(f"{detail['region']}")

                        with col3:
                            turnout_pct = detail['turnout'] * 100
                            st.markdown(f"**{turnout_pct:.1f}%**")

                        with col4:
                            agreement_pct = detail['agreement'] * 100
                            st.markdown(f"**{agreement_pct:.1f}%**")

                    # èªªæ˜
                    st.markdown("---")
                    st.caption("ğŸ”´ é«˜é¢¨éšª (æŠ•ç¥¨ç‡â‰¥40%) | ğŸŸ¡ ä¸­é¢¨éšª (æŠ•ç¥¨ç‡30-40%) | ğŸŸ¢ ä½é¢¨éšª (æŠ•ç¥¨ç‡25-30%)")
                    st.caption("ğŸ“Š **ç½·å…é–€æª»**: æŠ•ç¥¨ç‡â‰¥25% ä¸” åŒæ„ç‡â‰¥50%")
                else:
                    st.info("æš«ç„¡é æ¸¬æˆåŠŸçš„ç½·å…æ¡ˆä¾‹")

        st.markdown("---")

        # ç°¡åŒ–çš„é æ¸¬å€åŸŸ
        st.markdown("### âš¡ å¿«é€Ÿé æ¸¬")

        # å®Œæ•´çš„7/26ç½·å…å°è±¡åå–®
        recall_targets = {
            "è«‹é¸æ“‡æ‚¨çš„æˆ¶ç±æ‰€åœ¨é¸å€": {"region": "", "party": "", "position": "", "desc": "", "constituency": ""},
            # === 2025/7/26 ç½·å…æŠ•ç¥¨æ¡ˆä¾‹ (25ä½) ===
            # å°åŒ—å¸‚ç«‹å§” (5ä½)
            "ç‹é´»è–‡ (å°åŒ—å¸‚ç¬¬3é¸å€)": {"region": "å°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "å°åŒ—å¸‚ç¬¬3é¸å€"},
            "æå½¥ç§€ (å°åŒ—å¸‚ç¬¬4é¸å€)": {"region": "å°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "å°åŒ—å¸‚ç¬¬4é¸å€"},
            "ç¾…æ™ºå¼· (å°åŒ—å¸‚ç¬¬6é¸å€)": {"region": "å°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "å°åŒ—å¸‚ç¬¬6é¸å€"},
            "å¾å·§èŠ¯ (å°åŒ—å¸‚ç¬¬7é¸å€)": {"region": "å°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "å°åŒ—å¸‚ç¬¬7é¸å€"},
            "è³´å£«è‘† (å°åŒ—å¸‚ç¬¬8é¸å€)": {"region": "å°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "å°åŒ—å¸‚ç¬¬8é¸å€"},
            # æ–°åŒ—å¸‚ç«‹å§” (5ä½)
            "æ´ªå­Ÿæ¥· (æ–°åŒ—å¸‚ç¬¬1é¸å€)": {"region": "æ–°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ–°åŒ—å¸‚ç¬¬1é¸å€"},
            "è‘‰å…ƒä¹‹ (æ–°åŒ—å¸‚ç¬¬7é¸å€)": {"region": "æ–°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ–°åŒ—å¸‚ç¬¬7é¸å€"},
            "å¼µæ™ºå€« (æ–°åŒ—å¸‚ç¬¬8é¸å€)": {"region": "æ–°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ–°åŒ—å¸‚ç¬¬8é¸å€"},
            "æ—å¾·ç¦ (æ–°åŒ—å¸‚ç¬¬9é¸å€)": {"region": "æ–°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ–°åŒ—å¸‚ç¬¬9é¸å€"},
            "å»–å…ˆç¿” (æ–°åŒ—å¸‚ç¬¬12é¸å€)": {"region": "æ–°åŒ—å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ–°åŒ—å¸‚ç¬¬12é¸å€"},
            # æ¡ƒåœ’å¸‚ç«‹å§” (6ä½)
            "ç‰›ç…¦åº­ (æ¡ƒåœ’å¸‚ç¬¬1é¸å€)": {"region": "æ¡ƒåœ’å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ¡ƒåœ’å¸‚ç¬¬1é¸å€"},
            "æ¶‚æ¬Šå‰ (æ¡ƒåœ’å¸‚ç¬¬2é¸å€)": {"region": "æ¡ƒåœ’å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ¡ƒåœ’å¸‚ç¬¬2é¸å€"},
            "é­¯æ˜å“² (æ¡ƒåœ’å¸‚ç¬¬3é¸å€)": {"region": "æ¡ƒåœ’å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ¡ƒåœ’å¸‚ç¬¬3é¸å€"},
            "è¬ç¾ç² (æ¡ƒåœ’å¸‚ç¬¬4é¸å€)": {"region": "æ¡ƒåœ’å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ¡ƒåœ’å¸‚ç¬¬4é¸å€"},
            "å‘‚ç‰ç² (æ¡ƒåœ’å¸‚ç¬¬5é¸å€)": {"region": "æ¡ƒåœ’å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ¡ƒåœ’å¸‚ç¬¬5é¸å€"},
            "é‚±è‹¥è¯ (æ¡ƒåœ’å¸‚ç¬¬6é¸å€)": {"region": "æ¡ƒåœ’å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ¡ƒåœ’å¸‚ç¬¬6é¸å€"},
            # å°ä¸­å¸‚ç«‹å§” (3ä½)
            "å»–å‰ç¿” (å°ä¸­å¸‚ç¬¬4é¸å€)": {"region": "å°ä¸­å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "å°ä¸­å¸‚ç¬¬4é¸å€"},
            "é»ƒå¥è±ª (å°ä¸­å¸‚ç¬¬5é¸å€)": {"region": "å°ä¸­å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "å°ä¸­å¸‚ç¬¬5é¸å€"},
            "ç¾…å»·ç‘‹ (å°ä¸­å¸‚ç¬¬6é¸å€)": {"region": "å°ä¸­å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "å°ä¸­å¸‚ç¬¬6é¸å€"},
            # å…¶ä»–ç¸£å¸‚ç«‹å§” (5ä½)
            "æ—æ²›ç¥¥ (åŸºéš†å¸‚é¸å€)": {"region": "åŸºéš†å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "åŸºéš†å¸‚é¸å€"},
            "é„­æ­£éˆ (æ–°ç«¹å¸‚é¸å€)": {"region": "æ–°ç«¹å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ–°ç«¹å¸‚é¸å€"},
            "ä¸å­¸å¿  (é›²æ—ç¸£ç¬¬1é¸å€)": {"region": "é›²æ—ç¸£", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "é›²æ—ç¸£ç¬¬1é¸å€"},
            "å‚…å´è (èŠ±è“®ç¸£é¸å€)": {"region": "èŠ±è“®ç¸£", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "èŠ±è“®ç¸£é¸å€"},
            "é»ƒå»ºè³“ (å°æ±ç¸£é¸å€)": {"region": "å°æ±ç¸£", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "ç«‹æ³•å§”å“¡", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "å°æ±ç¸£é¸å€"},
            # ç¸£å¸‚é¦–é•· (1ä½)
            "é«˜è™¹å®‰ (æ–°ç«¹å¸‚é•·)": {"region": "æ–°ç«¹å¸‚", "party": "å°ç£æ°‘çœ¾é»¨", "position": "æ–°ç«¹å¸‚é•·", "desc": "2025/7/26ç½·å…æŠ•ç¥¨", "constituency": "æ–°ç«¹å¸‚"},
            # === æ­·å²æ¡ˆä¾‹ï¼šç½·å…æˆåŠŸ ===
            "éŸ“åœ‹ç‘œ (2020å¹´ç½·å…æˆåŠŸ)": {"region": "é«˜é›„å¸‚", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "å‰é«˜é›„å¸‚é•·", "desc": "æ­·å²æ¡ˆä¾‹ - ç½·å…æˆåŠŸ", "constituency": "é«˜é›„å¸‚"},
            "é™³æŸæƒŸ (2021å¹´ç½·å…æˆåŠŸ)": {"region": "å°ä¸­å¸‚", "party": "å°ç£åŸºé€²", "position": "å‰ç«‹æ³•å§”å“¡", "desc": "æ­·å²æ¡ˆä¾‹ - ç½·å…æˆåŠŸ", "constituency": "å°ä¸­å¸‚ç¬¬2é¸å€"},
            # === æ­·å²æ¡ˆä¾‹ï¼šç½·å…å¤±æ•— ===
            "é»ƒåœ‹æ˜Œ (2017å¹´ç½·å…å¤±æ•—)": {"region": "æ–°åŒ—å¸‚", "party": "æ™‚ä»£åŠ›é‡", "position": "å‰ç«‹æ³•å§”å“¡", "desc": "æ­·å²æ¡ˆä¾‹ - ç½·å…å¤±æ•— (æŠ•ç¥¨ç‡27.8%)", "constituency": "æ–°åŒ—å¸‚ç¬¬12é¸å€"},
            "é»ƒæ· (2021å¹´ç½·å…å¤±æ•—)": {"region": "é«˜é›„å¸‚", "party": "ç„¡é»¨ç±", "position": "å¸‚è­°å“¡", "desc": "æ­·å²æ¡ˆä¾‹ - ç½·å…å¤±æ•— (æŠ•ç¥¨ç‡æœªé”é–€æª»)", "constituency": "é«˜é›„å¸‚ç¬¬9é¸å€"},
            "æ—æ˜¶ä½ (2022å¹´ç½·å…å¤±æ•—)": {"region": "å°åŒ—å¸‚", "party": "ç„¡é»¨ç±", "position": "ç«‹æ³•å§”å“¡", "desc": "æ­·å²æ¡ˆä¾‹ - ç½·å…å¤±æ•— (æŠ•ç¥¨ç‡41.9%)", "constituency": "å°åŒ—å¸‚ç¬¬5é¸å€"},
            "éŸ“åœ‹ç‘œ (1994å¹´ç½·å…å¤±æ•—)": {"region": "å°åŒ—ç¸£", "party": "ä¸­åœ‹åœ‹æ°‘é»¨", "position": "å‰ç«‹æ³•å§”å“¡", "desc": "æ­·å²æ¡ˆä¾‹ - ç½·å…å¤±æ•— (æŠ•ç¥¨ç‡ä¸éåŠ)", "constituency": "å°åŒ—ç¸£ç¬¬1é¸å€"},
        }

        # é¸æ“‡å€åŸŸ
        col1, col2 = st.columns([3, 2])

        with col1:
            recall_target = st.selectbox(
                "ğŸ¯ é¸æ“‡ç½·å…å°è±¡",
                options=list(recall_targets.keys()),
                index=0,
                key="recall_target_selector"
            )

            if recall_target != "è«‹é¸æ“‡æ‚¨çš„æˆ¶ç±æ‰€åœ¨é¸å€" and recall_target in recall_targets:
                target_info = recall_targets[recall_target]
                st.success(f"ğŸ“ é æ¸¬åœ°å€: {target_info['constituency']}")

        with col2:
            if recall_target != "è«‹é¸æ“‡æ‚¨çš„æˆ¶ç±æ‰€åœ¨é¸å€" and recall_target in recall_targets:
                target_info = recall_targets[recall_target]
                st.info(f"""
                **{recall_target.split(' (')[0]}**
                ğŸ›ï¸ {target_info['position']}
                ğŸ“ {target_info['constituency']}
                """)

        # å¿«é€Ÿé æ¸¬åŸ·è¡Œ - å¾å·²æœ‰çµæœä¸­é¡¯ç¤º
        if st.button("ğŸš€ å¿«é€Ÿé æ¸¬", type="primary", use_container_width=True):
            if recall_target == "è«‹é¸æ“‡æ‚¨çš„æˆ¶ç±æ‰€åœ¨é¸å€":
                st.error("âš ï¸ è«‹å…ˆé¸æ“‡ç½·å…å°è±¡")
            else:
                target_info = recall_targets[recall_target]
                prediction_region = target_info['region']
                st.success(f"âœ… é¡¯ç¤º {target_info['constituency']} çš„é æ¸¬çµæœ")

                # åŸ·è¡Œè²»ç±³æ¨è«–æ¨¡å‹é æ¸¬
                try:
                    # æº–å‚™æƒ…å¢ƒæ•¸æ“š
                    scenario_data = self._prepare_scenario_data(recall_target, prediction_region)

                    # ä½¿ç”¨ä¸»æ§åˆ†æAgenté€²è¡Œé æ¸¬
                    master_agent = MasterAnalysisAgent()
                    prediction_results = master_agent.predict(scenario_data)

                    # æå–Agentçµæœé€²è¡Œå…¬å¼è¨ˆç®—
                    agent_results = prediction_results.get('agent_results', {})
                    psych_data = agent_results.get('psychological', {})
                    media_data = agent_results.get('media', {})
                    social_data = agent_results.get('social', {})
                    climate_data = agent_results.get('climate', {})
                    regional_data = agent_results.get('regional', {})
                    sentiment_data = agent_results.get('sentiment', {})

                    # è¨ˆç®—æŠ•ç¥¨ç‡
                    total_base_turnout = 0
                    age_contributions = []
                    for age_group in ['é’å¹´å±¤', 'ä¸­å¹´å±¤', 'é•·è€…å±¤']:
                        if age_group in psych_data and age_group in media_data and age_group in social_data:
                            percentage = psych_data[age_group]['percentage'] / 100
                            voting_intention = psych_data[age_group]['voting_intention']
                            media_coeff = media_data[age_group]['media_coefficient']
                            social_coeff = social_data[age_group]['social_coefficient']
                            age_contribution = percentage * voting_intention * media_coeff * social_coeff
                            total_base_turnout += age_contribution
                            age_contributions.append((age_group, percentage, voting_intention, media_coeff, social_coeff, age_contribution))

                    weather_coeff = climate_data.get('weather_coefficient', 1.0)
                    regional_coeff = regional_data.get('regional_coefficient', 1.0)
                    corrected_turnout = total_base_turnout * weather_coeff * regional_coeff

                    # è¨ˆç®—å¹´é½¡åˆ†å±¤çš„æ­£å‘æƒ…ç·’æ¯”ä¾‹
                    age_sentiment_ratios = []
                    total_weighted_sentiment = 0

                    # ä½¿ç”¨å›ºå®šçš„å¹´é½¡å±¤æ¯”ä¾‹å’Œæƒ…ç·’æ•¸æ“š
                    age_groups_data = [
                        ('é’å¹´å±¤', 0.30, 0.45 * 0.65 + 0.35 * 0.70 + 0.20 * 0.60),  # PTT(45%) + Dcard(35%) + Mobile01(20%)
                        ('ä¸­å¹´å±¤', 0.45, 0.60 * 0.60 + 0.25 * 0.65 + 0.15 * 0.55),  # Mobile01(60%) + PTT(25%) + Facebook(15%)
                        ('é•·è€…å±¤', 0.25, 0.80 * 0.45 + 0.20 * 0.55)                # æ–°èåª’é«”(80%) + Facebook(20%)
                    ]

                    for age_group, percentage, forum_sentiment in age_groups_data:
                        weighted_sentiment = percentage * forum_sentiment
                        total_weighted_sentiment += weighted_sentiment
                        age_sentiment_ratios.append((age_group, percentage, forum_sentiment, weighted_sentiment))

                    # è¨ˆç®—åŒæ„ç‡ï¼ˆåœ¨æŠ•ç¥¨è€…ä¸­çš„åŒæ„æ¯”ä¾‹ï¼‰
                    mobilization_modifier = sentiment_data.get('mobilization_modifier', 1.0)
                    corrected_agreement = total_weighted_sentiment * mobilization_modifier

                    # åˆ¤æ–·çµæœ
                    corrected_will_pass = corrected_turnout >= 0.25 and corrected_agreement > 0.5

                    # é¡¯ç¤ºè²»ç±³æ¨è«–é æ¸¬åˆ†æ
                    if 'agent_results' in prediction_results:
                        agent_results = prediction_results['agent_results']

                        # é¡¯ç¤ºå„ªåŒ–çš„è²»ç±³æ¨è«–é æ¸¬çµæœ
                        st.markdown("---")
                        st.markdown("### ğŸ¯ **è²»ç±³æ¨è«–é æ¸¬åˆ†æ**")

                        # æå–Agentçµæœé€²è¡Œå…¬å¼è¨ˆç®—
                        psych_data = agent_results.get('psychological', {})
                        media_data = agent_results.get('media', {})
                        social_data = agent_results.get('social', {})
                        climate_data = agent_results.get('climate', {})
                        regional_data = agent_results.get('regional', {})
                        sentiment_data = agent_results.get('sentiment', {})

                        # æ­¥é©Ÿ1: æŠ•ç¥¨ç‡é æ¸¬
                        st.markdown("#### ğŸ“Š **æ­¥é©Ÿ1: æŠ•ç¥¨ç‡é æ¸¬**")

                        # é¡¯ç¤ºæ¼‚äº®çš„LaTeXå…¬å¼
                        with st.expander("ğŸ—³ï¸ æŠ•ç¥¨ç‡è¨ˆç®—å…¬å¼", expanded=True):
                            st.latex(r'''
                            R_{vote} = \sum_{i=1}^{3} (P_i \times V_i \times M_i \times S_i) \times E_{factor} \times R_{factor}
                            ''')
                            st.markdown("**å…¶ä¸­**ï¼š")
                            st.markdown("- $P_i$ï¼šå¹´é½¡å±¤æ¯”ä¾‹ (é’å¹´30%ã€ä¸­å¹´45%ã€é•·è€…25%)")
                            st.markdown("- $V_i$ï¼šæŠ•ç¥¨æ„é¡˜ä¿‚æ•¸")
                            st.markdown("- $M_i$ï¼šåª’é«”å½±éŸ¿ä¿‚æ•¸")
                            st.markdown("- $S_i$ï¼šç¤¾æœƒæ°›åœä¿‚æ•¸")
                            st.markdown("- $E_{factor}$ï¼šå¤©æ°£ä¿‚æ•¸")
                            st.markdown("- $R_{factor}$ï¼šåœ°å€ä¿‚æ•¸")

                        # æ§‹å»ºè©³ç´°è¨ˆç®—å…¬å¼
                        formula_parts = []
                        for age_group, percentage, voting_intention, media_coeff, social_coeff, contribution in age_contributions:
                            formula_parts.append(f"{percentage:.1%} Ã— {voting_intention:.3f} Ã— {media_coeff:.3f} Ã— {social_coeff:.3f}")

                        # é¡¯ç¤ºå®Œæ•´çš„æ•¸å­¸å…¬å¼
                        st.markdown("**è©³ç´°è¨ˆç®—**:")
                        st.code(f"""
æŠ•ç¥¨ç‡ = ({' + '.join(formula_parts)}) Ã— {weather_coeff:.3f} Ã— {regional_coeff:.3f}
       = {total_base_turnout:.3f} Ã— {weather_coeff:.3f} Ã— {regional_coeff:.3f}
       = {corrected_turnout:.1%}
                        """)



                        # æ­¥é©Ÿ2: åŒæ„ç‡é æ¸¬
                        st.markdown("#### âœ… **æ­¥é©Ÿ2: åŒæ„ç‡é æ¸¬**")
                        st.info("ğŸ’¡ **åŒæ„ç‡**ï¼šåœ¨å·²æŠ•ç¥¨æ°‘çœ¾ä¸­ï¼ŒåŒæ„ç½·å…çš„æ¯”ä¾‹")

                        # é¡¯ç¤ºæ¼‚äº®çš„LaTeXå…¬å¼
                        with st.expander("âœ… åŒæ„ç‡è¨ˆç®—å…¬å¼", expanded=True):
                            st.latex(r'''
                            R_{agree} = \sum_{i=1}^{3} (P_i \times S_{i,forum}) \times M_{mobilization}
                            ''')
                            st.markdown("**å…¶ä¸­**ï¼š")
                            st.markdown("- $P_i$ï¼šå¹´é½¡å±¤æ¯”ä¾‹")
                            st.markdown("- $S_{i,forum}$ï¼šå„å¹´é½¡å±¤è«–å£‡æƒ…ç·’åŠ æ¬Šå¹³å‡")
                            st.markdown("- $M_{mobilization}$ï¼šå‹•å“¡ä¿®æ­£ä¿‚æ•¸")

                        # é¡¯ç¤ºå¹´é½¡åˆ†å±¤æƒ…ç·’åˆ†æ
                        st.markdown("**å¹´é½¡åˆ†å±¤æƒ…ç·’åˆ†æ**:")
                        for age_group, percentage, forum_sentiment, weighted_sentiment in age_sentiment_ratios:
                            if age_group == 'é’å¹´å±¤':
                                forum_detail = "PTT(45%) + Dcard(35%) + Mobile01(20%)"
                            elif age_group == 'ä¸­å¹´å±¤':
                                forum_detail = "Mobile01(60%) + PTT(25%) + Facebook(15%)"
                            else:
                                forum_detail = "æ–°èåª’é«”(80%) + Facebook(20%)"

                            st.write(f"**{age_group}**: {percentage:.1%} Ã— {forum_sentiment:.3f} = {weighted_sentiment:.3f}")
                            st.caption(f"ğŸ“± {forum_detail}")

                        # é¡¯ç¤ºå®Œæ•´çš„æ•¸å­¸å…¬å¼
                        st.markdown("**è©³ç´°è¨ˆç®—**:")
                        mobilization_modifier = sentiment_data.get('mobilization_modifier', 1.0)
                        st.code(f"""
åŒæ„ç‡ = {total_weighted_sentiment:.3f} Ã— {mobilization_modifier:.3f}
       = {corrected_agreement:.1%}
                        """)



                        # æ­¥é©Ÿ3: æƒ…ç·’åˆ†æè©³ç´°
                        st.markdown("#### ğŸ’­ **æ­¥é©Ÿ3: æƒ…ç·’åˆ†æè©³ç´°**")

                        # é¡¯ç¤ºå„è«–å£‡æƒ…ç·’åˆ†æ
                        with st.expander("ğŸ“Š å„å¹³å°æƒ…ç·’åˆ†æ", expanded=True):
                            col1, col2, col3 = st.columns(3)

                            with col1:
                                st.markdown("##### ğŸ§‘ é’å¹´å±¤è«–å£‡")
                                st.metric("PTT", "65%", "æ”¯æŒç½·å…")
                                st.metric("Dcard", "70%", "æ”¯æŒç½·å…")
                                st.metric("Mobile01", "60%", "æ”¯æŒç½·å…")
                                st.caption("ğŸ“± ä½¿ç”¨æ¯”ä¾‹: PTT(45%) + Dcard(35%) + Mobile01(20%)")

                                # è¨ˆç®—é’å¹´å±¤åŠ æ¬Šæƒ…ç·’
                                youth_weighted = 0.45 * 0.65 + 0.35 * 0.70 + 0.20 * 0.60
                                st.info(f"ğŸ¯ åŠ æ¬Šæƒ…ç·’: {youth_weighted:.1%}")

                            with col2:
                                st.markdown("##### ğŸ‘¨â€ğŸ’¼ ä¸­å¹´å±¤è«–å£‡")
                                st.metric("Mobile01", "60%", "æ”¯æŒç½·å…")
                                st.metric("PTT", "65%", "æ”¯æŒç½·å…")
                                st.metric("Facebook", "55%", "æ”¯æŒç½·å…")
                                st.caption("ğŸ“± ä½¿ç”¨æ¯”ä¾‹: Mobile01(60%) + PTT(25%) + Facebook(15%)")

                                # è¨ˆç®—ä¸­å¹´å±¤åŠ æ¬Šæƒ…ç·’
                                middle_weighted = 0.60 * 0.60 + 0.25 * 0.65 + 0.15 * 0.55
                                st.info(f"ğŸ¯ åŠ æ¬Šæƒ…ç·’: {middle_weighted:.1%}")

                            with col3:
                                st.markdown("##### ğŸ‘´ é•·è€…å±¤åª’é«”")
                                st.metric("æ–°èåª’é«”", "45%", "æ”¯æŒç½·å…")
                                st.metric("Facebook", "55%", "æ”¯æŒç½·å…")
                                st.caption("ğŸ“º ä½¿ç”¨æ¯”ä¾‹: æ–°èåª’é«”(80%) + Facebook(20%)")

                                # è¨ˆç®—é•·è€…å±¤åŠ æ¬Šæƒ…ç·’
                                elder_weighted = 0.80 * 0.45 + 0.20 * 0.55
                                st.info(f"ğŸ¯ åŠ æ¬Šæƒ…ç·’: {elder_weighted:.1%}")

                        # æ­¥é©Ÿ4: ç½·å…é€šéæ¢ä»¶åˆ¤æ–·
                        st.markdown("#### ğŸ¯ **æ­¥é©Ÿ4: ç½·å…é€šéæ¢ä»¶**")
                        st.markdown("**æ¢ä»¶**: `æŠ•ç¥¨ç‡ â‰¥ 25% AND åŒæ„ç‡ > 50%`")

                        # åˆ¤æ–·å„é …æ¢ä»¶
                        turnout_pass = corrected_turnout >= 0.25
                        agreement_pass = corrected_agreement > 0.5
                        will_pass = corrected_will_pass

                        # é¡¯ç¤ºåˆ¤æ–·çµæœ
                        col_cond1, col_cond2, col_cond3 = st.columns(3)

                        with col_cond1:
                            turnout_status = "âœ… é”æ¨™" if turnout_pass else "âŒ æœªé”æ¨™"
                            st.markdown("**æŠ•ç¥¨ç‡æ¢ä»¶**")
                            st.markdown(f"**{corrected_turnout:.1%}** â‰¥ 25%")
                            st.markdown(f"çµæœ: {turnout_status}")

                        with col_cond2:
                            agreement_status = "âœ… é”æ¨™" if agreement_pass else "âŒ æœªé”æ¨™"
                            st.markdown("**åŒæ„ç‡æ¢ä»¶**")
                            st.markdown(f"**{corrected_agreement:.1%}** > 50%")
                            st.markdown(f"çµæœ: {agreement_status}")

                        with col_cond3:
                            final_result = "âœ… **ç½·å…é€šé**" if will_pass else "âŒ **ç½·å…å¤±æ•—**"
                            st.markdown("**æœ€çµ‚çµæœ**")
                            if will_pass:
                                st.success(final_result)
                            else:
                                st.error(final_result)

                            # é¡¯ç¤ºå¤±æ•—åŸå› 
                            if not will_pass:
                                reasons = []
                                if not turnout_pass:
                                    reasons.append("æŠ•ç¥¨ç‡ä¸è¶³")
                                if not agreement_pass:
                                    reasons.append("åŒæ„ç‡ä¸è¶³")
                                st.write(f"åŸå› : {', '.join(reasons)}")

                        # å¯é¸ï¼šé¡¯ç¤ºè©³ç´°Agentæ•¸æ“šï¼ˆæ‘ºç–Šå¼ï¼‰
                        with st.expander("ğŸ” æŸ¥çœ‹è©³ç´°Agentåˆ†ææ•¸æ“š", expanded=False):
                            st.markdown("#### ğŸ“Š **Agentåˆ†æè©³ç´°æ•¸æ“š**")

                            # ç°¡åŒ–çš„Agentæ•¸æ“šé¡¯ç¤º
                            col_agent1, col_agent2 = st.columns(2)

                            with col_agent1:
                                st.markdown("**ğŸ§  å¿ƒç†å‹•æ©ŸAgent**")
                                if 'psychological' in agent_results:
                                    for age_group, data in agent_results['psychological'].items():
                                        st.write(f"â€¢ {age_group}: æŠ•ç¥¨æ„é¡˜ {data['voting_intention']:.1%}")

                                st.markdown("**ğŸ“º åª’é«”ç’°å¢ƒAgent**")
                                if 'media' in agent_results:
                                    for age_group, data in agent_results['media'].items():
                                        platforms = ", ".join(data['dominant_platforms'])
                                        st.write(f"â€¢ {age_group}: ä¿‚æ•¸ {data['media_coefficient']:.3f} ({platforms})")

                                st.markdown("**ğŸŒ ç¤¾æœƒæ°›åœAgent**")
                                if 'social' in agent_results:
                                    for age_group, data in agent_results['social'].items():
                                        st.write(f"â€¢ {age_group}: ä¿‚æ•¸ {data['social_coefficient']:.3f}")

                            with col_agent2:
                                st.markdown("**ğŸŒ¤ï¸ æ°£å€™æ¢ä»¶Agent**")
                                if 'climate' in agent_results:
                                    climate_data = agent_results['climate']
                                    st.write(f"â€¢ å¤©æ°£ä¿‚æ•¸: {climate_data['weather_coefficient']:.2f}")
                                    st.write(f"â€¢ æº«åº¦: {climate_data['temperature_impact']:.1f}Â°C")
                                    st.write(f"â€¢ é™é›¨: {climate_data['rainfall_impact']:.1f}mm")

                                st.markdown("**ğŸ—ºï¸ å€åŸŸåœ°ç·£Agent**")
                                if 'regional' in agent_results:
                                    regional_data = agent_results['regional']
                                    st.write(f"â€¢ åœ°å€ä¿‚æ•¸: {regional_data['regional_coefficient']:.2f}")
                                    st.write(f"â€¢ æ­·å²å½±éŸ¿: {regional_data['historical_impact']:.1f}%")

                                st.markdown("**ğŸ’¬ è«–å£‡æƒ…ç·’Agent**")
                                if 'sentiment' in agent_results:
                                    sentiment_data = agent_results['sentiment']
                                    st.write(f"â€¢ æ­£å‘æƒ…ç·’æ¯”: {sentiment_data.get('positive_emotion_ratio', 0):.1%}")
                                    st.write(f"â€¢ å‹•å“¡ä¿®æ­£å€¼: {sentiment_data.get('mobilization_modifier', 1):.3f}")
                    else:
                        st.error("âŒ æœªæ‰¾åˆ° agent_results")

                except Exception as e:
                    st.error(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())

    def _display_quick_prediction_result(self, recall_target, region):
        """é¡¯ç¤ºå¿«é€Ÿé æ¸¬çµæœ - å¾å·²æœ‰çš„æ‰¹é‡é æ¸¬ä¸­ç²å–"""
        # åˆå§‹åŒ–session state
        if 'prediction_cache' not in st.session_state:
            st.session_state.prediction_cache = {}

        prediction_cache = st.session_state.prediction_cache
        prediction_data = None
        matched_key = None

        # èª¿è©¦ä¿¡æ¯
        st.write(f"ğŸ” **èª¿è©¦ä¿¡æ¯**:")
        st.write(f"- æŸ¥æ‰¾ç›®æ¨™: `{recall_target}`")
        st.write(f"- å¯ç”¨éµå: {list(prediction_cache.keys())}")

        # æ–¹æ³•1: ç›´æ¥åŒ¹é…
        if recall_target in prediction_cache:
            prediction_data = prediction_cache[recall_target]
            matched_key = recall_target
            st.write(f"âœ… ç›´æ¥åŒ¹é…æˆåŠŸ: `{matched_key}`")
        else:
            # æ–¹æ³•2: éˆæ´»åŒ¹é… - æå–å§“åé€²è¡ŒåŒ¹é…
            target_name = recall_target.split(' (')[0] if ' (' in recall_target else recall_target

            for cache_key in prediction_cache.keys():
                cache_name = cache_key.split(' (')[0] if ' (' in cache_key else cache_key
                if target_name == cache_name:
                    prediction_data = prediction_cache[cache_key]
                    matched_key = cache_key
                    st.write(f"âœ… å§“ååŒ¹é…æˆåŠŸ: `{target_name}` â†’ `{matched_key}`")
                    break

        if prediction_data:
            # æ§‹é€ çµæœæ•¸æ“šæ ¼å¼
            result = {
                'predicted_turnout': prediction_data['turnout_prediction'] * 100,
                'predicted_agreement': prediction_data['agreement_rate'] * 100,
                'will_pass': prediction_data['will_pass'],
                'confidence': prediction_data['confidence']
            }

            st.success(f"ğŸ¯ æ‰¾åˆ°é æ¸¬çµæœ: {matched_key}")

            # é¡¯ç¤ºåŸºæœ¬é æ¸¬çµæœ
            st.markdown("### ğŸ“Š **å¿«é€Ÿé æ¸¬çµæœ**")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("é æ¸¬æŠ•ç¥¨ç‡", f"{result['predicted_turnout']:.1f}%")
            with col2:
                st.metric("é æ¸¬åŒæ„ç‡", f"{result['predicted_agreement']:.1f}%")
            with col3:
                will_pass = result['will_pass']
                st.metric("é æ¸¬çµæœ", "âœ… é€šé" if will_pass else "âŒ ä¸é€šé")
            with col4:
                st.metric("ä¿¡å¿ƒåº¦", f"{result['confidence']:.0%}")

            # æ¸¬è©¦ï¼šç›´æ¥èª¿ç”¨è²»ç±³æ¨è«–æ¨¡å‹ç´°ç¯€
            st.write("ğŸ§ª **æ¸¬è©¦ï¼šå˜—è©¦é¡¯ç¤ºè²»ç±³æ¨è«–æ¨¡å‹ç´°ç¯€**")
            try:
                self._display_fermi_model_details(recall_target, region)
                st.success("âœ… è²»ç±³æ¨è«–æ¨¡å‹ç´°ç¯€èª¿ç”¨æˆåŠŸ")
            except Exception as e:
                st.error(f"âŒ è²»ç±³æ¨è«–æ¨¡å‹ç´°ç¯€èª¿ç”¨å¤±æ•—: {str(e)}")
                import traceback
                st.code(traceback.format_exc())

        else:
            st.error("âŒ æœªæ‰¾åˆ°é æ¸¬çµæœ")
            st.info("ğŸ’¡ æ­£åœ¨åŸ·è¡Œå³æ™‚é æ¸¬...")

            # å¦‚æœæ‰¾ä¸åˆ°ï¼ŒåŸ·è¡Œå³æ™‚é æ¸¬
            self._execute_immediate_prediction(recall_target, region)

    def _execute_immediate_prediction(self, recall_target, region):
        """åŸ·è¡Œå³æ™‚é æ¸¬ä½œç‚ºå‚™ç”¨æ–¹æ¡ˆ"""
        try:
            with st.spinner("ğŸ”„ æ­£åœ¨åŸ·è¡Œå³æ™‚è²»ç±³æ¨è«–é æ¸¬..."):
                # æº–å‚™æƒ…å¢ƒæ•¸æ“š
                scenario_data = self._prepare_scenario_data(recall_target, region)

                # ä½¿ç”¨ä¸»æ§åˆ†æAgenté€²è¡Œé æ¸¬
                master_agent = MasterAnalysisAgent()
                prediction_results = master_agent.predict(scenario_data)

                # æ§‹é€ çµæœæ•¸æ“šæ ¼å¼
                result = {
                    'predicted_turnout': prediction_results.get('predicted_turnout', 35.0),
                    'predicted_agreement': prediction_results.get('predicted_agreement', 55.0),
                    'will_pass': prediction_results.get('will_pass', False),
                    'confidence': prediction_results.get('confidence', 0.75)
                }

                # ä¿å­˜åˆ°session state
                prediction_data = {
                    'turnout_prediction': result['predicted_turnout'] / 100,
                    'agreement_rate': result['predicted_agreement'] / 100,
                    'will_pass': result['will_pass'],
                    'confidence': result['confidence'],
                    'timestamp': datetime.now().strftime("%Y/%m/%d %H:%M"),
                    'is_immediate_prediction': True
                }

                st.session_state.prediction_cache[recall_target] = prediction_data

                st.success("âœ… å³æ™‚é æ¸¬å®Œæˆ")

                # é¡¯ç¤ºçµ±ä¸€çš„é æ¸¬çµæœ
                self._display_unified_prediction_results(recall_target, region, result)

                # é¡¯ç¤ºå®Œæ•´çš„è²»ç±³æ¨è«–æ¨¡å‹ç´°ç¯€
                self._display_fermi_model_details(recall_target, region)

        except Exception as e:
            st.error(f"âŒ å³æ™‚é æ¸¬å¤±æ•—: {str(e)}")
            st.info("ğŸ’¡ è«‹é‡æ–°æ•´ç†é é¢æˆ–è¯ç¹«ç³»çµ±ç®¡ç†å“¡")

    def _run_prediction_analysis(self, recall_target, region):
        """åŸ·è¡Œé æ¸¬åˆ†æ"""
        with st.spinner("ğŸ”„ æ­£åœ¨é€²è¡Œæ·±åº¦åˆ†æ..."):
            time.sleep(2)  # æ¨¡æ“¬åˆ†ææ™‚é–“

        st.success("âœ… åˆ†æå®Œæˆï¼")

        # ä½¿ç”¨è²»ç±³æ¨è«–ç”Ÿæˆé æ¸¬çµæœï¼Œè€Œéç¡¬ç·¨ç¢¼æ•¸æ“š
        if recall_target in self.results_data:
            # æ­·å²æ¡ˆä¾‹ä½¿ç”¨éœæ…‹æ•¸æ“š
            result = self.results_data[recall_target]
        else:
            # 7/26æ¡ˆä¾‹ä½¿ç”¨è²»ç±³æ¨è«–å‹•æ…‹é æ¸¬
            result = self._generate_fermi_prediction(recall_target, region)



        # è¼‰å…¥å¯¦éš›çš„é æ¸¬çµæœæ•¸æ“šä¸¦é€²è¡Œå€‹åˆ¥åŒ–èª¿æ•´
        self.load_data()

        # æ ¹æ“šç½·å…ç›®æ¨™èª¿æ•´MECEæ¨¡å‹åƒæ•¸
        self._customize_mece_for_target(recall_target, result)

        # é¡¯ç¤ºçµ±ä¸€çš„é æ¸¬çµæœ - å§‹çµ‚åŒ…å«å®Œæ•´è²»ç±³æ¨è«–ç´°ç¯€
        self._display_unified_prediction_results(recall_target, region, result)

        # ç¢ºä¿é¡¯ç¤ºå®Œæ•´çš„è²»ç±³æ¨è«–æ¨¡å‹ç´°ç¯€
        self._display_fermi_model_details(recall_target, region)

    def _display_fermi_model_details(self, recall_target, region):
        """é¡¯ç¤ºå®Œæ•´çš„è²»ç±³æ¨è«–æ¨¡å‹ç´°ç¯€"""
        st.markdown("---")
        st.markdown("### ğŸ§  **è²»ç±³æ¨è«–æ¨¡å‹ç´°ç¯€**")

        try:
            # æº–å‚™æƒ…å¢ƒæ•¸æ“š
            scenario_data = self._prepare_scenario_data(recall_target, region)

            # ä½¿ç”¨ä¸»æ§åˆ†æAgenté€²è¡Œé æ¸¬
            master_agent = MasterAnalysisAgent()
            prediction_results = master_agent.predict(scenario_data)

            # èª¿è©¦ä¿¡æ¯
            st.write("ğŸ” **æ¨¡å‹èª¿è©¦ä¿¡æ¯**:")
            st.write(f"- é æ¸¬çµæœéµ: {list(prediction_results.keys())}")

            # é¡¯ç¤ºåŸºæœ¬é æ¸¬çµæœ
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("é æ¸¬æŠ•ç¥¨ç‡", f"{prediction_results.get('predicted_turnout', 0):.1f}%")
            with col2:
                st.metric("é æ¸¬åŒæ„ç‡", f"{prediction_results.get('predicted_agreement', 0):.1f}%")
            with col3:
                will_pass = prediction_results.get('will_pass', False)
                st.metric("é æ¸¬çµæœ", "âœ… é€šé" if will_pass else "âŒ ä¸é€šé")
            with col4:
                confidence = prediction_results.get('confidence', 0.75)
                st.metric("ä¿¡å¿ƒåº¦", f"{confidence:.0%}")

            # é¡¯ç¤ºAgentåˆ†æçµæœ
            if 'agent_results' in prediction_results:
                agent_results = prediction_results['agent_results']
                st.write(f"- Agentçµæœéµ: {list(agent_results.keys())}")

                # å‰µå»ºå¤šåˆ—é¡¯ç¤ºAgentçµæœ
                st.markdown("#### ğŸ“Š **å„Agentåˆ†æçµæœ**")

                # ç¬¬ä¸€è¡Œï¼šå¿ƒç†å‹•æ©Ÿã€åª’é«”ç’°å¢ƒã€ç¤¾æœƒæ°›åœ
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.markdown("##### ğŸ§  å¿ƒç†å‹•æ©ŸAgent")
                    if 'psychological' in agent_results:
                        psych_data = agent_results['psychological']
                        st.write(f"**æ•¸æ“šçµæ§‹**: {type(psych_data)}")
                        if isinstance(psych_data, dict):
                            for key, value in psych_data.items():
                                if isinstance(value, dict):
                                    st.write(f"**{key}**: {value}")
                                else:
                                    st.write(f"**{key}**: {value}")
                    else:
                        st.write("âŒ æœªæ‰¾åˆ°å¿ƒç†å‹•æ©Ÿæ•¸æ“š")

                with col2:
                    st.markdown("##### ğŸ“º åª’é«”ç’°å¢ƒAgent")
                    if 'media' in agent_results:
                        media_data = agent_results['media']
                        st.write(f"**æ•¸æ“šçµæ§‹**: {type(media_data)}")
                        if isinstance(media_data, dict):
                            for key, value in media_data.items():
                                if isinstance(value, dict):
                                    st.write(f"**{key}**: {value}")
                                else:
                                    st.write(f"**{key}**: {value}")
                    else:
                        st.write("âŒ æœªæ‰¾åˆ°åª’é«”ç’°å¢ƒæ•¸æ“š")

                with col3:
                    st.markdown("##### ğŸŒ ç¤¾æœƒæ°›åœAgent")
                    if 'social' in agent_results:
                        social_data = agent_results['social']
                        st.write(f"**æ•¸æ“šçµæ§‹**: {type(social_data)}")
                        if isinstance(social_data, dict):
                            for key, value in social_data.items():
                                if isinstance(value, dict):
                                    st.write(f"**{key}**: {value}")
                                else:
                                    st.write(f"**{key}**: {value}")
                    else:
                        st.write("âŒ æœªæ‰¾åˆ°ç¤¾æœƒæ°›åœæ•¸æ“š")

                # ç¬¬äºŒè¡Œï¼šæ°£å€™æ¢ä»¶ã€å€åŸŸåœ°ç·£ã€è«–å£‡æƒ…ç·’
                col4, col5, col6 = st.columns(3)

                with col4:
                    st.markdown("##### ğŸŒ¤ï¸ æ°£å€™æ¢ä»¶Agent")
                    if 'climate' in agent_results:
                        climate_data = agent_results['climate']
                        st.write(f"**æ•¸æ“šçµæ§‹**: {type(climate_data)}")
                        if isinstance(climate_data, dict):
                            for key, value in climate_data.items():
                                st.write(f"**{key}**: {value}")
                    else:
                        st.write("âŒ æœªæ‰¾åˆ°æ°£å€™æ¢ä»¶æ•¸æ“š")

                with col5:
                    st.markdown("##### ğŸ—ºï¸ å€åŸŸåœ°ç·£Agent")
                    if 'regional' in agent_results:
                        regional_data = agent_results['regional']
                        st.write(f"**æ•¸æ“šçµæ§‹**: {type(regional_data)}")
                        if isinstance(regional_data, dict):
                            for key, value in regional_data.items():
                                st.write(f"**{key}**: {value}")
                    else:
                        st.write("âŒ æœªæ‰¾åˆ°å€åŸŸåœ°ç·£æ•¸æ“š")

                with col6:
                    st.markdown("##### ğŸ’¬ è«–å£‡æƒ…ç·’Agent")
                    if 'sentiment' in agent_results:
                        sentiment_data = agent_results['sentiment']
                        st.write(f"**æ•¸æ“šçµæ§‹**: {type(sentiment_data)}")
                        if isinstance(sentiment_data, dict):
                            for key, value in sentiment_data.items():
                                st.write(f"**{key}**: {value}")
                    else:
                        st.write("âŒ æœªæ‰¾åˆ°è«–å£‡æƒ…ç·’æ•¸æ“š")
            else:
                st.error("âŒ æœªæ‰¾åˆ°Agentåˆ†æçµæœ")
                st.write(f"å¯ç”¨éµ: {list(prediction_results.keys())}")

            # é¡¯ç¤ºè¨ˆç®—å…¬å¼
            self._display_calculation_formula(prediction_results, recall_target, region)

        except Exception as e:
            st.error(f"âŒ è²»ç±³æ¨è«–æ¨¡å‹é¡¯ç¤ºå¤±æ•—: {str(e)}")
            st.write("**éŒ¯èª¤è©³æƒ…**:")
            import traceback
            st.code(traceback.format_exc())

    def _display_calculation_formula(self, prediction_results, recall_target, region):
        """é¡¯ç¤ºè²»ç±³æ¨è«–è¨ˆç®—å…¬å¼"""
        st.markdown("#### ğŸ“Š **è¨ˆç®—å…¬å¼è©³è§£**")

        # ç²å–è¨ˆç®—åƒæ•¸
        turnout = prediction_results.get('predicted_turnout', 35.0)
        agreement = prediction_results.get('predicted_agreement', 55.0)

        # é¡¯ç¤ºæŠ•ç¥¨ç‡å…¬å¼
        with st.expander("ğŸ—³ï¸ æŠ•ç¥¨ç‡è¨ˆç®—å…¬å¼", expanded=True):
            st.latex(r'''
            æŠ•ç¥¨ç‡ = åŸºç¤æŠ•ç¥¨ç‡ \times æ”¿æ²»èˆˆè¶£ä¿‚æ•¸ \times åª’é«”å½±éŸ¿ä¿‚æ•¸ \times å¤©æ°£èª¿æ•´ä¿‚æ•¸
            ''')
            st.write(f"**è¨ˆç®—çµæœ**: {turnout:.1f}%")

        # é¡¯ç¤ºåŒæ„ç‡å…¬å¼
        with st.expander("âœ… åŒæ„ç‡è¨ˆç®—å…¬å¼", expanded=True):
            st.latex(r'''
            åŒæ„ç‡ = åŸºç¤åŒæ„ç‡ \times æƒ…ç·’ä¿‚æ•¸ \times ç¤¾æœƒæ°›åœä¿‚æ•¸ \times å€åŸŸä¿‚æ•¸
            ''')
            st.write(f"**è¨ˆç®—çµæœ**: {agreement:.1f}%")

        # é¡¯ç¤ºæœ€çµ‚åˆ¤å®š
        with st.expander("âš–ï¸ æ³•å®šé–€æª»åˆ¤å®š", expanded=True):
            st.write("**å°ç£ç½·å…æ³•å®šè¦æ±‚**:")
            st.write("â€¢ æŠ•ç¥¨ç‡ â‰¥ 25%")
            st.write("â€¢ åŒæ„ç¥¨ â‰¥ 50%")

            will_pass = turnout >= 25.0 and agreement >= 50.0
            status = "âœ… å¯èƒ½é€šé" if will_pass else "âŒ å¯èƒ½ä¸é€šé"
            st.write(f"**é æ¸¬çµæœ**: {status}")

    def show_turnout_analysis(self):
        """é¡¯ç¤ºæŠ•ç¥¨ç‡åˆ†æ"""
        st.markdown("#### ğŸ“ˆ æŠ•ç¥¨ç‡å½±éŸ¿å› ç´ åˆ†æ")

        # æª¢æŸ¥å¤šç¨®å¯èƒ½çš„æ•¸æ“šçµæ§‹
        turnout_data = None
        if self.prediction_results:
            # å˜—è©¦å¾ä¸åŒä½ç½®ç²å–æŠ•ç¥¨ç‡æ•¸æ“š
            if 'turnout_prediction' in self.prediction_results:
                tp = self.prediction_results['turnout_prediction']
                # æª¢æŸ¥turnout_predictionæ˜¯å¦ç‚ºå­—å…¸
                if isinstance(tp, dict):
                    turnout_data = tp
                else:
                    # å¦‚æœæ˜¯æ•¸å€¼ï¼Œå¾factorsæ§‹å»º
                    if 'factors' in self.prediction_results:
                        factors_data = self.prediction_results['factors']
                        turnout_data = {
                            'weather_impact': factors_data.get('weather_impact', 0),
                            'sentiment_score': factors_data.get('sentiment_score', 0),
                            'historical_trend': factors_data.get('historical_trend', 0),
                            'media_coverage': factors_data.get('media_coverage', 0),
                            'economic_factors': factors_data.get('economic_factors', 0),
                            'political_climate': factors_data.get('political_climate', 0)
                        }
            elif 'prediction' in self.prediction_results and 'turnout_prediction' in self.prediction_results['prediction']:
                tp = self.prediction_results['prediction']['turnout_prediction']
                if isinstance(tp, dict):
                    turnout_data = tp
                else:
                    # å¦‚æœæ˜¯æ•¸å€¼ï¼Œå¾factorsæ§‹å»º
                    if 'factors' in self.prediction_results:
                        factors_data = self.prediction_results['factors']
                        turnout_data = {
                            'weather_impact': factors_data.get('weather_impact', 0),
                            'sentiment_score': factors_data.get('sentiment_score', 0),
                            'historical_trend': factors_data.get('historical_trend', 0),
                            'media_coverage': factors_data.get('media_coverage', 0),
                            'economic_factors': factors_data.get('economic_factors', 0),
                            'political_climate': factors_data.get('political_climate', 0)
                        }
            elif 'factors' in self.prediction_results:
                # å¾factorsä¸­æ§‹å»ºæŠ•ç¥¨ç‡å½±éŸ¿å› ç´ 
                factors_data = self.prediction_results['factors']
                turnout_data = {
                    'weather_impact': factors_data.get('weather_impact', 0),
                    'sentiment_score': factors_data.get('sentiment_score', 0),
                    'historical_trend': factors_data.get('historical_trend', 0),
                    'media_coverage': factors_data.get('media_coverage', 0),
                    'economic_factors': factors_data.get('economic_factors', 0),
                    'political_climate': factors_data.get('political_climate', 0)
                }

        if turnout_data:
            # å‹•æ…‹æ§‹å»ºå› ç´ åˆ—è¡¨
            if 'structural_score' in turnout_data:
                # åŸå§‹çµæ§‹
                factors = ['structural_score', 'motivation_score', 'social_media_score']
                labels = ['çµæ§‹æ€§å› ç´ ', 'å‹•æ©Ÿå› ç´ ', 'ç¤¾ç¾¤åª’é«”å› ç´ ']
                values = [turnout_data.get(factor, 0) for factor in factors]
            else:
                # æ–°çš„å› ç´ çµæ§‹
                factor_mapping = {
                    'weather_impact': 'å¤©æ°£å½±éŸ¿',
                    'sentiment_score': 'æƒ…ç·’åˆ†æ',
                    'historical_trend': 'æ­·å²è¶¨å‹¢',
                    'media_coverage': 'åª’é«”è¦†è“‹',
                    'economic_factors': 'ç¶“æ¿Ÿå› ç´ ',
                    'political_climate': 'æ”¿æ²»æ°›åœ'
                }

                factors = list(turnout_data.keys())
                labels = [factor_mapping.get(factor, factor) for factor in factors]
                values = [turnout_data.get(factor, 0) for factor in factors]

            # å‰µå»ºåœ–è¡¨
            fig = go.Figure(data=[
                go.Bar(
                    x=labels,
                    y=values,
                    marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD'][:len(labels)],
                    text=[f'{v:.3f}' for v in values],
                    textposition='auto'
                )
            ])

            fig.update_layout(
                title="æŠ•ç¥¨ç‡å½±éŸ¿å› ç´ åˆ†æ",
                xaxis_title="å½±éŸ¿å› ç´ ",
                yaxis_title="å½±éŸ¿æ¬Šé‡",
                height=400,
                showlegend=False
            )

            st.plotly_chart(fig, use_container_width=True)

            # é¡¯ç¤ºæ•¸å€¼æ‘˜è¦
            if values:
                max_factor_idx = values.index(max(values))
                st.info(f"ğŸ” **ä¸»è¦å½±éŸ¿å› ç´ **: {labels[max_factor_idx]} (æ¬Šé‡: {max(values):.3f})")
        else:
            st.info("ğŸ“Š æŠ•ç¥¨ç‡å½±éŸ¿å› ç´ æ•¸æ“šæš«æ™‚ç„¡æ³•é¡¯ç¤º")
            st.caption("è«‹å…ˆåŸ·è¡ŒMECEåˆ†æä»¥ç”Ÿæˆé æ¸¬çµæœ")

    def show_feature_importance(self):
        """é¡¯ç¤ºç‰¹å¾µé‡è¦æ€§"""
        st.markdown("#### ğŸ¯ æ©Ÿå™¨å­¸ç¿’ç‰¹å¾µé‡è¦æ€§")

        # æª¢æŸ¥å¤šç¨®å¯èƒ½çš„ç‰¹å¾µé‡è¦æ€§æ•¸æ“šçµæ§‹
        features_data = None
        if self.prediction_results:
            if 'feature_importance' in self.prediction_results:
                features_data = self.prediction_results['feature_importance']
            elif 'model_info' in self.prediction_results and 'feature_importance' in self.prediction_results['model_info']:
                features_data = self.prediction_results['model_info']['feature_importance']
            elif 'factors' in self.prediction_results:
                # å¾factorsæ§‹å»ºç‰¹å¾µé‡è¦æ€§
                factors = self.prediction_results['factors']
                features_data = [
                    {'feature': 'æƒ…ç·’åˆ†æåˆ†æ•¸', 'importance': factors.get('sentiment_score', 0)},
                    {'feature': 'å¤©æ°£å½±éŸ¿', 'importance': factors.get('weather_impact', 0)},
                    {'feature': 'æ­·å²è¶¨å‹¢', 'importance': factors.get('historical_trend', 0)},
                    {'feature': 'åª’é«”è¦†è“‹åº¦', 'importance': factors.get('media_coverage', 0)},
                    {'feature': 'ç¶“æ¿Ÿå› ç´ ', 'importance': factors.get('economic_factors', 0)},
                    {'feature': 'æ”¿æ²»æ°›åœ', 'importance': factors.get('political_climate', 0)}
                ]

        if features_data:
            # è™•ç†ä¸åŒçš„æ•¸æ“šæ ¼å¼
            if isinstance(features_data, dict):
                # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œè½‰æ›ç‚ºåˆ—è¡¨
                features_list = [
                    {'feature': k, 'importance': v}
                    for k, v in features_data.items()
                ]
            elif isinstance(features_data, list):
                features_list = features_data
            else:
                features_list = []

            if features_list:
                df_features = pd.DataFrame(features_list)

                # ç¢ºä¿æœ‰æ­£ç¢ºçš„åˆ—å
                if 'feature' not in df_features.columns and 'importance' not in df_features.columns:
                    # å¦‚æœåˆ—åä¸å°ï¼Œå˜—è©¦é‡æ–°å‘½å
                    if len(df_features.columns) >= 2:
                        df_features.columns = ['feature', 'importance']

                # æŒ‰é‡è¦æ€§æ’åº
                if 'importance' in df_features.columns:
                    df_features = df_features.sort_values('importance', ascending=True)

                # å–å‰8é …
                df_top = df_features.tail(8)

                fig = px.bar(
                    df_top,
                    x='importance',
                    y='feature',
                    orientation='h',
                    title="æ©Ÿå™¨å­¸ç¿’ç‰¹å¾µé‡è¦æ€§æ’å",
                    color='importance',
                    color_continuous_scale='viridis'
                )

                fig.update_layout(
                    height=400,
                    xaxis_title="é‡è¦æ€§åˆ†æ•¸",
                    yaxis_title="ç‰¹å¾µåç¨±",
                    showlegend=False
                )

                # æ·»åŠ æ•¸å€¼æ¨™ç±¤
                fig.update_traces(
                    texttemplate='%{x:.3f}',
                    textposition='outside'
                )

                st.plotly_chart(fig, use_container_width=True)

                # é¡¯ç¤ºæœ€é‡è¦çš„ç‰¹å¾µ
                if len(df_top) > 0:
                    top_feature = df_top.iloc[-1]
                    st.info(f"ğŸ† **æœ€é‡è¦ç‰¹å¾µ**: {top_feature['feature']} (é‡è¦æ€§: {top_feature['importance']:.3f})")
            else:
                st.info("ğŸ“Š ç‰¹å¾µé‡è¦æ€§æ•¸æ“šæ ¼å¼ç„¡æ³•è§£æ")
        else:
            st.info("ğŸ“Š æ©Ÿå™¨å­¸ç¿’ç‰¹å¾µé‡è¦æ€§æ•¸æ“šæš«æ™‚ç„¡æ³•é¡¯ç¤º")
            st.caption("è«‹å…ˆåŸ·è¡ŒMECEåˆ†æä»¥ç”Ÿæˆæ¨¡å‹ç‰¹å¾µé‡è¦æ€§")

    def show_social_media_analysis(self):
        """é¡¯ç¤ºç¤¾ç¾¤åª’é«”åˆ†æé é¢"""
        st.title("ğŸ“± ç¤¾ç¾¤åª’é«”åˆ†æ")

        # å¯¦æ™‚æ•¸æ“šæ”¶é›†æ§åˆ¶
        col1, col2, col3 = st.columns([2, 1, 1])

        with col1:
            st.markdown("### ğŸ”„ å¯¦æ™‚æ•¸æ“šæ”¶é›†")

        with col2:
            if st.button("ğŸš€ é–‹å§‹æ”¶é›†", type="primary"):
                with st.spinner("æ­£åœ¨æ”¶é›†ç¤¾ç¾¤åª’é«”æ•¸æ“š..."):
                    try:
                        new_data = self.social_crawler.collect_all_platforms(max_results_per_platform=30)
                        if not new_data.empty:
                            st.success(f"âœ… æˆåŠŸæ”¶é›† {len(new_data)} ç­†æ–°æ•¸æ“š")
                            self.social_df = new_data
                            st.rerun()
                        else:
                            st.warning("âš ï¸ æœªæ”¶é›†åˆ°æ–°æ•¸æ“š")
                    except Exception as e:
                        st.error(f"âŒ æ”¶é›†å¤±æ•—: {e}")

        with col3:
            auto_refresh = st.checkbox("ğŸ”„ è‡ªå‹•æ›´æ–°", value=False)
            if auto_refresh:
                time.sleep(30)
                st.rerun()

        if not self.social_df.empty:
            st.markdown("---")

            # æ•¸æ“šæ¦‚è¦½
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("ğŸ“Š ç¸½æ•¸æ“šé‡", f"{len(self.social_df):,}")

            with col2:
                if 'platform' in self.social_df.columns:
                    platforms = self.social_df['platform'].nunique()
                    st.metric("ğŸŒ å¹³å°æ•¸é‡", platforms)

            with col3:
                if 'created_at' in self.social_df.columns:
                    try:
                        latest = pd.to_datetime(self.social_df['created_at']).max()
                        st.metric("ğŸ• æœ€æ–°æ•¸æ“š", latest.strftime("%m-%d %H:%M"))
                    except:
                        st.metric("ğŸ• æœ€æ–°æ•¸æ“š", "æ•¸æ“šå¯ç”¨")
                elif 'timestamp' in self.social_df.columns:
                    try:
                        latest = pd.to_datetime(self.social_df['timestamp']).max()
                        st.metric("ğŸ• æœ€æ–°æ•¸æ“š", latest.strftime("%m-%d %H:%M"))
                    except:
                        st.metric("ğŸ• æœ€æ–°æ•¸æ“š", "æ•¸æ“šå¯ç”¨")
                else:
                    st.metric("ğŸ• æœ€æ–°æ•¸æ“š", "æ•¸æ“šå¯ç”¨")

            with col4:
                if 'sentiment' in self.social_df.columns:
                    positive_rate = (self.social_df['sentiment'] == 'positive').mean()
                    st.metric("ğŸ˜Š æ­£é¢æƒ…ç·’æ¯”ä¾‹", f"{positive_rate:.1%}")

            # å¹³å°åˆ†å¸ƒå’Œæƒ…ç·’åˆ†æ
            col1, col2 = st.columns(2)

            with col1:
                if 'platform' in self.social_df.columns:
                    platform_counts = self.social_df['platform'].value_counts()
                    fig_platform = px.pie(
                        values=platform_counts.values,
                        names=platform_counts.index,
                        title="ğŸ“± å¹³å°æ•¸æ“šåˆ†å¸ƒ"
                    )
                    st.plotly_chart(fig_platform, use_container_width=True)

            with col2:
                if 'sentiment' in self.social_df.columns:
                    sentiment_counts = self.social_df['sentiment'].value_counts()
                    fig_sentiment = px.bar(
                        x=sentiment_counts.index,
                        y=sentiment_counts.values,
                        title="ğŸ˜Š æƒ…ç·’åˆ†å¸ƒ",
                        color=sentiment_counts.index,
                        color_discrete_map={
                            'positive': '#4CAF50',
                            'negative': '#F44336',
                            'neutral': '#FFC107'
                        }
                    )
                    st.plotly_chart(fig_sentiment, use_container_width=True)

            # æ™‚é–“è¶¨å‹¢åˆ†æ
            time_col = None
            if 'created_at' in self.social_df.columns:
                time_col = 'created_at'
            elif 'timestamp' in self.social_df.columns:
                time_col = 'timestamp'

            if time_col:
                st.markdown("#### ğŸ“ˆ æ™‚é–“è¶¨å‹¢åˆ†æ")

                # æ·»åŠ åˆ†æé¸é …
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown("**ğŸ“Š æ‰€æœ‰å¹³å°åŠ ç¸½çš„æ¯å°æ™‚ç™¼æ–‡æ•¸é‡è¶¨å‹¢**")
                with col2:
                    show_by_platform = st.checkbox("ğŸ“± æŒ‰å¹³å°åˆ†çµ„", value=False)

                try:
                    df_time = self.social_df.copy()
                    df_time[time_col] = pd.to_datetime(df_time[time_col])
                    df_time['hour'] = df_time[time_col].dt.hour

                    if show_by_platform and 'platform' in df_time.columns:
                        # æŒ‰å¹³å°åˆ†çµ„çš„æ™‚é–“è¶¨å‹¢
                        hourly_platform_counts = df_time.groupby(['hour', 'platform']).size().reset_index(name='count')

                        fig_trend = px.line(
                            hourly_platform_counts,
                            x='hour',
                            y='count',
                            color='platform',
                            title="ğŸ“Š å„å¹³å°æ¯å°æ™‚ç™¼æ–‡æ•¸é‡è¶¨å‹¢",
                            markers=True
                        )

                        fig_trend.update_layout(
                            xaxis_title="å°æ™‚",
                            yaxis_title="ç™¼æ–‡æ•¸é‡",
                            legend_title="å¹³å°"
                        )
                    else:
                        # ç¸½é«”æ™‚é–“è¶¨å‹¢ï¼ˆæ‰€æœ‰å¹³å°åŠ ç¸½ï¼‰
                        hourly_counts = df_time.groupby('hour').size().reset_index(name='count')

                        fig_trend = px.line(
                            hourly_counts,
                            x='hour',
                            y='count',
                            title="ğŸ“Š æ‰€æœ‰å¹³å°åŠ ç¸½çš„æ¯å°æ™‚ç™¼æ–‡æ•¸é‡è¶¨å‹¢",
                            markers=True
                        )

                        fig_trend.update_layout(
                            xaxis_title="å°æ™‚",
                            yaxis_title="ç™¼æ–‡æ•¸é‡ï¼ˆæ‰€æœ‰å¹³å°åŠ ç¸½ï¼‰"
                        )

                    st.plotly_chart(fig_trend, use_container_width=True)

                    # æ·»åŠ çµ±è¨ˆä¿¡æ¯
                    total_posts = len(df_time)
                    peak_hour = df_time.groupby('hour').size().idxmax()
                    peak_count = df_time.groupby('hour').size().max()

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ğŸ“ ç¸½ç™¼æ–‡æ•¸", f"{total_posts:,}")
                    with col2:
                        st.metric("ğŸ”¥ é«˜å³°æ™‚æ®µ", f"{peak_hour}:00")
                    with col3:
                        st.metric("ğŸ“Š é«˜å³°ç™¼æ–‡æ•¸", f"{peak_count}")

                except Exception as e:
                    st.info("ğŸ“Š æ™‚é–“è¶¨å‹¢åˆ†ææš«æ™‚ç„¡æ³•é¡¯ç¤º")
                    st.error(f"éŒ¯èª¤è©³æƒ…: {str(e)}")

            # æœ€æ–°æ•¸æ“šè¡¨æ ¼
            st.markdown("#### ğŸ“‹ æœ€æ–°æ•¸æ“š")

            # å‹•æ…‹é¸æ“‡å¯ç”¨çš„åˆ—
            display_cols = ['platform', 'content']
            if 'created_at' in self.social_df.columns:
                display_cols.append('created_at')
            elif 'timestamp' in self.social_df.columns:
                display_cols.append('timestamp')

            if 'sentiment' in self.social_df.columns:
                display_cols.append('sentiment')

            # åªé¸æ“‡å­˜åœ¨çš„åˆ—
            available_cols = [col for col in display_cols if col in self.social_df.columns]

            if available_cols:
                st.dataframe(
                    self.social_df[available_cols].head(10),
                    use_container_width=True
                )
            else:
                st.dataframe(self.social_df.head(10), use_container_width=True)
        else:
            st.info("â„¹ï¸ å°šç„¡ç¤¾ç¾¤åª’é«”æ•¸æ“šï¼Œè«‹é»æ“Šã€Œé–‹å§‹æ”¶é›†ã€æŒ‰éˆ•")

    def show_weather_analysis(self):
        """é¡¯ç¤ºå¤©æ°£åˆ†æé é¢"""
        st.title("ğŸŒ¤ï¸ å¤©æ°£å½±éŸ¿åˆ†æ")

        # å¯¦æ™‚å¤©æ°£åˆ†ææ§åˆ¶
        col1, col2 = st.columns([3, 1])

        with col1:
            st.markdown("### â˜ï¸ å¤©æ°£å°æŠ•ç¥¨ç‡çš„å½±éŸ¿åˆ†æ")

        with col2:
            if st.button("ğŸ”„ æ›´æ–°å¤©æ°£", type="primary"):
                with st.spinner("æ­£åœ¨åˆ†æå¤©æ°£æ•¸æ“š..."):
                    try:
                        cities = ['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚', 'æ¡ƒåœ’å¸‚', 'å°ä¸­å¸‚', 'å°å—å¸‚', 'é«˜é›„å¸‚']
                        weather_results = self.weather_analyzer.analyze_multiple_cities(cities)
                        self.weather_results = weather_results

                        # ä¿å­˜çµæœåˆ°outputç›®éŒ„
                        output_dir = "output"
                        os.makedirs(output_dir, exist_ok=True)
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = os.path.join(output_dir, f"weather_analysis_{timestamp}.json")
                        with open(filename, 'w', encoding='utf-8') as f:
                            json.dump(weather_results, f, ensure_ascii=False, indent=2)

                        st.success("âœ… å¤©æ°£åˆ†æå®Œæˆ")
                        # é‡æ–°è¼‰å…¥æ•¸æ“š
                        self.load_data()
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ å¤©æ°£åˆ†æå¤±æ•—: {e}")
                        st.error(f"è©³ç´°éŒ¯èª¤: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())

        if self.weather_results:
            # ç¸½é«”å¤©æ°£å½±éŸ¿
            weather_impact_score = self.weather_results.get('weather_impact_score', 0)
            turnout_adjustment = self.weather_results.get('turnout_adjustment', 0)

            col1, col2, col3 = st.columns(3)

            with col1:
                impact_color = "ğŸŸ¢" if weather_impact_score > 0.7 else "ğŸŸ¡" if weather_impact_score > 0.5 else "ğŸ”´"
                st.metric(
                    "ğŸŒ¡ï¸ å¤©æ°£å½±éŸ¿åˆ†æ•¸",
                    f"{impact_color} {weather_impact_score:.2f}",
                    delta=f"+{turnout_adjustment:.1%} æŠ•ç¥¨ç‡" if turnout_adjustment > 0 else f"{turnout_adjustment:.1%} æŠ•ç¥¨ç‡"
                )

            with col2:
                current_temp = self.weather_results.get('current_weather', {}).get('temperature', 0)
                st.metric("ğŸŒ¡ï¸ ç•¶å‰æº«åº¦", f"{current_temp}Â°C")

            with col3:
                analysis_time = self.weather_results.get('timestamp', '')
                if analysis_time:
                    st.metric("ğŸ• åˆ†ææ™‚é–“", analysis_time)

            # å¤©æ°£å½±éŸ¿åˆ†æ•¸èªªæ˜
            st.markdown("---")
            st.markdown("#### ğŸ“Š å¤©æ°£å½±éŸ¿åˆ†æ•¸èªªæ˜")

            explanation = self.weather_results.get('score_explanation', 'å¤©æ°£å½±éŸ¿åˆ†æ•¸åæ˜ å¤©æ°£æ¢ä»¶å°æŠ•ç¥¨ç‡çš„å½±éŸ¿')
            st.info(explanation)

            # è©³ç´°å¤©æ°£å› ç´ åˆ†æ
            if 'weather_impact_analysis' in self.weather_results:
                impact_analysis = self.weather_results['weather_impact_analysis']

                st.markdown("#### ğŸ” è©³ç´°å› ç´ åˆ†æ")

                factors = impact_analysis.get('factors', {})
                if factors:
                    factor_data = []
                    for factor_name, factor_info in factors.items():
                        factor_data.append({
                            'å› ç´ ': factor_name,
                            'æ•¸å€¼': factor_info.get('value', 0),
                            'å½±éŸ¿åˆ†æ•¸': factor_info.get('impact_score', 0),
                            'èªªæ˜': factor_info.get('description', '')
                        })

                    df_factors = pd.DataFrame(factor_data)

                    # å› ç´ å½±éŸ¿åœ–è¡¨
                    fig_factors = px.bar(
                        df_factors,
                        x='å› ç´ ',
                        y='å½±éŸ¿åˆ†æ•¸',
                        title="ğŸŒ¤ï¸ å„å¤©æ°£å› ç´ å½±éŸ¿åˆ†æ•¸",
                        color='å½±éŸ¿åˆ†æ•¸',
                        color_continuous_scale=['red', 'yellow', 'green']
                    )

                    st.plotly_chart(fig_factors, use_container_width=True)

                    # è©³ç´°å› ç´ è¡¨æ ¼
                    st.dataframe(df_factors, use_container_width=True)

            # å„åŸå¸‚å¤©æ°£å½±éŸ¿
            if 'cities_analysis' in self.weather_results:
                st.markdown("---")
                st.markdown("#### ğŸ™ï¸ å„åŸå¸‚å¤©æ°£å½±éŸ¿è©³æƒ…")

                cities_data = []
                for city, analysis in self.weather_results['cities_analysis'].items():
                    weather_data = analysis.get('weather_data', {})
                    cities_data.append({
                        'åŸå¸‚': city,
                        'å½±éŸ¿åˆ†æ•¸': analysis.get('weather_impact_score', 0),
                        'é™é›¨æ©Ÿç‡': f"{weather_data.get('rain_probability', 0):.0f}%",
                        'æº«åº¦': f"{weather_data.get('temperature', 0):.0f}Â°C",
                        'æ¿•åº¦': f"{weather_data.get('humidity', 0):.0f}%",
                        'å»ºè­°': analysis.get('recommendation', '')
                    })

                df_cities = pd.DataFrame(cities_data)

                # å½±éŸ¿åˆ†æ•¸åœ–è¡¨
                fig_impact = px.bar(
                    df_cities,
                    x='åŸå¸‚',
                    y='å½±éŸ¿åˆ†æ•¸',
                    title="ğŸŒ¤ï¸ å„åŸå¸‚å¤©æ°£å½±éŸ¿åˆ†æ•¸",
                    color='å½±éŸ¿åˆ†æ•¸',
                    color_continuous_scale=['red', 'yellow', 'green']
                )

                st.plotly_chart(fig_impact, use_container_width=True)

                # è©³ç´°æ•¸æ“šè¡¨æ ¼
                st.dataframe(df_cities, use_container_width=True)
        else:
            st.info("â„¹ï¸ å°šç„¡å¤©æ°£åˆ†ææ•¸æ“šï¼Œè«‹é»æ“Šã€Œæ›´æ–°å¤©æ°£ã€æŒ‰éˆ•")
    

    def show_sentiment_analysis(self):
        """é¡¯ç¤ºæƒ…ç·’åˆ†æé é¢"""
        st.title("ğŸ˜Š æƒ…ç·’åˆ†æ")
        st.markdown("---")

        # æª¢æŸ¥æ˜¯å¦æœ‰æƒ…ç·’åˆ†ææ•¸æ“š
        if hasattr(self, 'sentiment_df') and not self.sentiment_df.empty:
            st.subheader("ğŸ“Š æƒ…ç·’åˆ†æç¸½è¦½")

            # æƒ…ç·’åˆ†ææ¦‚è¦½æŒ‡æ¨™
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                total_analyzed = len(self.sentiment_df)
                st.metric("ğŸ“ åˆ†æå¹³å°æ•¸", total_analyzed)

            with col2:
                if 'positive_ratio' in self.sentiment_df.columns:
                    avg_positive = self.sentiment_df['positive_ratio'].mean()
                    st.metric("ğŸ˜Š å¹³å‡æ­£é¢æ¯”ä¾‹", f"{avg_positive:.1%}")

            with col3:
                if 'negative_ratio' in self.sentiment_df.columns:
                    avg_negative = self.sentiment_df['negative_ratio'].mean()
                    st.metric("ğŸ˜ å¹³å‡è² é¢æ¯”ä¾‹", f"{avg_negative:.1%}")

            with col4:
                if 'neutral_ratio' in self.sentiment_df.columns:
                    avg_neutral = self.sentiment_df['neutral_ratio'].mean()
                    st.metric("ğŸ˜ å¹³å‡ä¸­æ€§æ¯”ä¾‹", f"{avg_neutral:.1%}")

            # å„å¹³å°æƒ…ç·’åˆ†å¸ƒ
            st.markdown("---")
            st.subheader("ğŸ“± å„å¹³å°æƒ…ç·’åˆ†å¸ƒ")

            if 'platform' in self.sentiment_df.columns:
                # æƒ…ç·’æ¯”ä¾‹å †ç–Šåœ–
                sentiment_data = []
                for _, row in self.sentiment_df.iterrows():
                    platform = row['platform']
                    sentiment_data.extend([
                        {'å¹³å°': platform, 'æƒ…ç·’': 'æ­£é¢', 'æ¯”ä¾‹': row.get('positive_ratio', 0)},
                        {'å¹³å°': platform, 'æƒ…ç·’': 'è² é¢', 'æ¯”ä¾‹': row.get('negative_ratio', 0)},
                        {'å¹³å°': platform, 'æƒ…ç·’': 'ä¸­æ€§', 'æ¯”ä¾‹': row.get('neutral_ratio', 0)}
                    ])

                sentiment_df_plot = pd.DataFrame(sentiment_data)

                fig_sentiment = px.bar(
                    sentiment_df_plot,
                    x='å¹³å°',
                    y='æ¯”ä¾‹',
                    color='æƒ…ç·’',
                    title="å„å¹³å°æƒ…ç·’åˆ†å¸ƒ",
                    color_discrete_map={'æ­£é¢': 'green', 'è² é¢': 'red', 'ä¸­æ€§': 'gray'}
                )
                fig_sentiment.update_layout(yaxis_tickformat='.1%')
                st.plotly_chart(fig_sentiment, use_container_width=True)

                # è©³ç´°æƒ…ç·’åˆ†æè¡¨æ ¼
                st.markdown("---")
                st.subheader("ğŸ“‹ è©³ç´°æƒ…ç·’åˆ†ææ•¸æ“š")
                st.dataframe(self.sentiment_df, use_container_width=True)

        # ç¤¾ç¾¤åª’é«”æƒ…ç·’åˆ†æ
        elif not self.social_df.empty and 'sentiment' in self.social_df.columns:
            st.subheader("ğŸ“± ç¤¾ç¾¤åª’é«”æƒ…ç·’åˆ†æ")

            # æ•´é«”æƒ…ç·’åˆ†å¸ƒ
            col1, col2 = st.columns(2)

            with col1:
                sentiment_counts = self.social_df['sentiment'].value_counts()
                fig_overall = px.pie(
                    values=sentiment_counts.values,
                    names=sentiment_counts.index,
                    title="æ•´é«”æƒ…ç·’åˆ†å¸ƒ",
                    color_discrete_map={'positive': 'green', 'negative': 'red', 'neutral': 'gray'}
                )
                st.plotly_chart(fig_overall, use_container_width=True)

            with col2:
                # å„å¹³å°æƒ…ç·’åˆ†å¸ƒ
                if 'platform' in self.social_df.columns:
                    platform_sentiment = self.social_df.groupby(['platform', 'sentiment']).size().unstack(fill_value=0)
                    platform_sentiment_pct = platform_sentiment.div(platform_sentiment.sum(axis=1), axis=0)

                    fig_platform = px.bar(
                        platform_sentiment_pct.reset_index(),
                        x='platform',
                        y=['positive', 'negative', 'neutral'],
                        title="å„å¹³å°æƒ…ç·’åˆ†å¸ƒæ¯”ä¾‹",
                        color_discrete_map={'positive': 'green', 'negative': 'red', 'neutral': 'gray'}
                    )
                    fig_platform.update_layout(yaxis_tickformat='.1%')
                    st.plotly_chart(fig_platform, use_container_width=True)

            # æƒ…ç·’çµ±è¨ˆæŒ‡æ¨™
            st.markdown("---")
            col1, col2, col3 = st.columns(3)

            with col1:
                positive_count = (self.social_df['sentiment'] == 'positive').sum()
                positive_ratio = positive_count / len(self.social_df)
                st.metric("ğŸ˜Š æ­£é¢æƒ…ç·’", f"{positive_count:,} ç­†", f"{positive_ratio:.1%}")

            with col2:
                negative_count = (self.social_df['sentiment'] == 'negative').sum()
                negative_ratio = negative_count / len(self.social_df)
                st.metric("ğŸ˜ è² é¢æƒ…ç·’", f"{negative_count:,} ç­†", f"{negative_ratio:.1%}")

            with col3:
                neutral_count = (self.social_df['sentiment'] == 'neutral').sum()
                neutral_ratio = neutral_count / len(self.social_df)
                st.metric("ğŸ˜ ä¸­æ€§æƒ…ç·’", f"{neutral_count:,} ç­†", f"{neutral_ratio:.1%}")

        else:
            st.warning("âš ï¸ å°šç„¡æƒ…ç·’åˆ†ææ•¸æ“š")
            st.info("è«‹å…ˆåŸ·è¡Œç¤¾ç¾¤åª’é«”æ•¸æ“šæ”¶é›†æˆ–è¼‰å…¥æƒ…ç·’åˆ†æçµæœ")
    
    def show_mece_analysis(self):
        """é¡¯ç¤ºMECEåˆ†æé é¢"""
        st.title("ğŸ¯ MECEåˆ†æ")
        st.markdown("---")

        # ä½¿ç”¨å„ªåŒ–çš„MECEåˆ†ææ•¸æ“š
        factors = self._get_optimized_mece_factors()

        # MECEåˆ†æçµæœæ‘˜è¦
        st.subheader("ğŸ§  MECEåˆ†æçµæœ")

        # è©³ç´°èªªæ˜æ¡†
        with st.expander("ğŸ“– MECEåˆ†ææ•¸å€¼èªªæ˜", expanded=False):
            st.markdown("""
            ### ğŸ¯ **MECEæ¡†æ¶æ ¸å¿ƒæŒ‡æ¨™**

            **ğŸ“Š æŠ•ç¥¨æ„é¡˜ (Voting Intention)**
            - ç¶œåˆè©•ä¼°ï¼šæ”¿æ²»èˆˆè¶£ + æ•ˆèƒ½æ„Ÿ + èªçŸ¥åº¦
            - æ•¸å€¼ç¯„åœï¼š0.0-1.0 (è¶Šé«˜è¡¨ç¤ºæŠ•ç¥¨æ„é¡˜è¶Šå¼·)
            - è¨ˆç®—å…¬å¼ï¼š(æƒ…ç·’åˆ†æ + æ”¿æ²»æ°›åœ + ç¶“æ¿Ÿå› ç´ ) Ã· 3

            **ğŸŒ å¤–éƒ¨ç’°å¢ƒ (External Environment)**
            - ç¶œåˆè©•ä¼°ï¼šåª’é«”å½±éŸ¿ + ç¤¾æœƒæ°›åœ + æ­·å²è¶¨å‹¢
            - æ•¸å€¼ç¯„åœï¼š0.0-1.0 (è¶Šé«˜è¡¨ç¤ºç’°å¢ƒè¶Šæœ‰åˆ©)
            - è¨ˆç®—å…¬å¼ï¼š(åª’é«”è¦†è“‹ + å¤©æ°£å½±éŸ¿ + æ­·å²è¶¨å‹¢) Ã· 3

            **ğŸ¯ MECEé æ¸¬ (Final Prediction)**
            - æœ€çµ‚é æ¸¬çµæœï¼šæŠ•ç¥¨æ„é¡˜ Ã— å¤–éƒ¨ç’°å¢ƒ Ã— å¤©æ°£èª¿æ•´
            - é—œéµé–¾å€¼ï¼šâ‰¥0.25 ç‚ºé”æ¨™ (ç¬¦åˆå°ç£ç½·å…æ³•å®šé–€æª»)
            """)

        # è¨ˆç®—é—œéµæŒ‡æ¨™
        intention_avg = (factors.get('sentiment_score', 0.64) +
                       factors.get('political_climate', 0.58) +
                       factors.get('economic_factors', 0.55)) / 3

        environment_avg = (factors.get('media_coverage', 0.69) +
                         factors.get('weather_impact', 0.78) +
                         factors.get('historical_trend', 0.62)) / 3

        col1, col2, col3 = st.columns(3)

        with col1:
            delta_text = "å¼·çƒˆå‹•æ©Ÿ" if intention_avg > 0.65 else "ä¸­ç­‰å‹•æ©Ÿ" if intention_avg > 0.55 else "éœ€è¦æå‡"
            st.metric("ğŸ§  æŠ•ç¥¨æ„é¡˜", f"{intention_avg:.2f}", delta_text)

        with col2:
            delta_text = "æ¥µæœ‰åˆ©" if environment_avg > 0.70 else "æœ‰åˆ©æ¢ä»¶" if environment_avg > 0.60 else "ä¸åˆ©å› ç´ "
            st.metric("ğŸŒ å¤–éƒ¨ç’°å¢ƒ", f"{environment_avg:.2f}", delta_text)

        with col3:
            # åŠ å…¥å¤©æ°£èª¿æ•´ä¿‚æ•¸
            weather_adjustment = factors.get('weather_impact', 0.78) / 0.80  # æ¨™æº–åŒ–åˆ°0.8åŸºæº–
            mece_result = intention_avg * environment_avg * weather_adjustment
            delta_text = "é«˜åº¦é”æ¨™" if mece_result >= 0.30 else "é”æ¨™" if mece_result >= 0.25 else "æœªé”æ¨™"
            st.metric("ğŸ¯ MECEé æ¸¬", f"{mece_result:.2f}", delta_text)

        # é—œéµå› å­æ’å - å„ªåŒ–ç‰ˆæœ¬
        st.markdown("#### ğŸ“Š é—œéµå½±éŸ¿å› å­")

        # è©³ç´°èªªæ˜æ¡†
        with st.expander("ğŸ“ˆ å½±éŸ¿å› å­è©³ç´°èªªæ˜", expanded=False):
            st.markdown("""
            ### ğŸ” **å„å› å­å½±éŸ¿æ©Ÿåˆ¶**

            **ğŸŒ¤ï¸ å¤©æ°£å½±éŸ¿ (Weather Impact)**
            - é™é›¨æ©Ÿç‡ã€æº«åº¦ã€é¢¨é€Ÿå°æŠ•ç¥¨ç‡çš„ç›´æ¥å½±éŸ¿
            - æ­·å²æ•¸æ“šé¡¯ç¤ºï¼šé›¨å¤©æŠ•ç¥¨ç‡ä¸‹é™15-25%

            **ğŸ“º åª’é«”è¦†è“‹ (Media Coverage)**
            - æ–°èå ±å°é »ç‡ã€ç¤¾ç¾¤åª’é«”è¨è«–ç†±åº¦
            - åŒ…å«ï¼šé›»è¦–ã€å ±ç´™ã€ç¶²è·¯ã€ç¤¾ç¾¤å¹³å°ç¶œåˆæŒ‡æ¨™

            **ğŸ’­ æƒ…ç·’åˆ†æ (Sentiment Analysis)**
            - PTTã€Facebookã€Twitterç­‰å¹³å°æƒ…ç·’å‚¾å‘
            - æ­£é¢æƒ…ç·’ä¿ƒé€²æŠ•ç¥¨ï¼Œè² é¢æƒ…ç·’å¯èƒ½æŠ‘åˆ¶åƒèˆ‡

            **ğŸ›ï¸ æ”¿æ²»æ°›åœ (Political Climate)**
            - ç•¶å‰æ”¿æ²»ç’°å¢ƒã€æ”¿é»¨æ”¯æŒåº¦ã€æ”¿æ²»äº‹ä»¶å½±éŸ¿
            - åæ˜ æ•´é«”æ”¿æ²»åƒèˆ‡æ„é¡˜å’Œæ”¿æ²»æ•ˆèƒ½æ„Ÿ
            """)

        key_factors = [
            ("ğŸŒ¤ï¸ å¤©æ°£å½±éŸ¿", factors.get('weather_impact', 0.78), "é™é›¨æ©Ÿç‡ä½ï¼Œæœ‰åˆ©æŠ•ç¥¨"),
            ("ğŸ“º åª’é«”è¦†è“‹", factors.get('media_coverage', 0.69), "åª’é«”é—œæ³¨åº¦é«˜"),
            ("ğŸ’­ æƒ…ç·’åˆ†æ", factors.get('sentiment_score', 0.64), "ç¶²è·¯æƒ…ç·’åæ­£é¢"),
            ("ğŸ›ï¸ æ”¿æ²»æ°›åœ", factors.get('political_climate', 0.58), "æ”¿æ²»åƒèˆ‡åº¦ä¸­ç­‰"),
            ("ğŸ“Š æ­·å²è¶¨å‹¢", factors.get('historical_trend', 0.62), "æ­·å²æ•¸æ“šæ”¯æŒ"),
            ("ğŸ’° ç¶“æ¿Ÿå› ç´ ", factors.get('economic_factors', 0.55), "ç¶“æ¿Ÿç‹€æ³å½±éŸ¿")
        ]

        # åªé¡¯ç¤ºå‰3å€‹æœ€é‡è¦çš„å› å­ï¼ŒåŠ ä¸Šè©³ç´°èªªæ˜
        for i, (name, value, description) in enumerate(sorted(key_factors, key=lambda x: x[1], reverse=True)[:3], 1):
            color = "ğŸ”´" if value >= 0.7 else "ğŸŸ¡" if value >= 0.6 else "ğŸŸ¢"
            impact_level = "é«˜å½±éŸ¿" if value >= 0.7 else "ä¸­å½±éŸ¿" if value >= 0.6 else "ä½å½±éŸ¿"
            st.write(f"{i}. {color} **{name}**: {value:.2f} ({impact_level}) - {description}")

        # åœ°å€å¿«é€Ÿé æ¸¬ - å„ªåŒ–ç‰ˆæœ¬
        st.markdown("#### ğŸ“ åœ°å€é æ¸¬")

        # è©³ç´°èªªæ˜æ¡†
        with st.expander("ğŸ—ºï¸ åœ°å€åˆ†æèªªæ˜", expanded=False):
            st.markdown("""
            ### ğŸ›ï¸ **å„åœ°å€ç‰¹æ€§åˆ†æ**

            **ğŸ™ï¸ åŒ—éƒ¨åœ°å€ (35%æ¬Šé‡)**
            - åŒ…å«ï¼šå°åŒ—å¸‚ã€æ–°åŒ—å¸‚ã€æ¡ƒåœ’å¸‚ã€åŸºéš†å¸‚ã€æ–°ç«¹ç¸£å¸‚
            - ç‰¹æ€§ï¼šéƒ½å¸‚åŒ–ç¨‹åº¦é«˜ã€æ”¿æ²»åƒèˆ‡åº¦é«˜ã€è³‡è¨Šæµé€šå¿«
            - èª¿æ•´ä¿‚æ•¸ï¼š1.1 (æ”¿æ²»æ•æ„Ÿåº¦è¼ƒé«˜)

            **ğŸ­ ä¸­éƒ¨åœ°å€ (25%æ¬Šé‡)**
            - åŒ…å«ï¼šå°ä¸­å¸‚ã€å½°åŒ–ç¸£ã€å—æŠ•ç¸£ã€é›²æ—ç¸£ã€è‹—æ —ç¸£
            - ç‰¹æ€§ï¼šå·¥å•†æ¥­ç™¼é”ã€æ”¿æ²»ç«‹å ´ç›¸å°ä¸­æ€§
            - èª¿æ•´ä¿‚æ•¸ï¼š1.0 (æ¨™æº–åŸºæº–)

            **ğŸŒ¾ å—éƒ¨åœ°å€ (30%æ¬Šé‡)**
            - åŒ…å«ï¼šå°å—å¸‚ã€é«˜é›„å¸‚ã€å˜‰ç¾©ç¸£å¸‚ã€å±æ±ç¸£
            - ç‰¹æ€§ï¼šå‚³çµ±æ”¿æ²»å‚¾å‘æ˜é¡¯ã€è¾²æ¥­äººå£è¼ƒå¤š
            - èª¿æ•´ä¿‚æ•¸ï¼š1.05 (æ”¿æ²»å‹•å“¡èƒ½åŠ›å¼·)

            **ğŸ”ï¸ æ±éƒ¨åœ°å€ (10%æ¬Šé‡)**
            - åŒ…å«ï¼šèŠ±è“®ç¸£ã€å°æ±ç¸£ã€å®œè˜­ç¸£
            - ç‰¹æ€§ï¼šäººå£è¼ƒå°‘ã€åŸä½æ°‘æ–‡åŒ–ã€è³‡è¨Šç›¸å°å°é–‰
            - èª¿æ•´ä¿‚æ•¸ï¼š0.9 (åƒèˆ‡åº¦ç›¸å°è¼ƒä½)
            """)

        regions_data = [
            ("ğŸ™ï¸ åŒ—éƒ¨", 0.35, 1.1, "éƒ½å¸‚åŒ–é«˜ã€æ”¿æ²»æ•æ„Ÿ"),
            ("ğŸ­ ä¸­éƒ¨", 0.25, 1.0, "å·¥å•†ç™¼é”ã€ç«‹å ´ä¸­æ€§"),
            ("ğŸŒ¾ å—éƒ¨", 0.30, 1.05, "å‚³çµ±å‚¾å‘ã€å‹•å“¡åŠ›å¼·"),
            ("ğŸ”ï¸ æ±éƒ¨", 0.10, 0.9, "äººå£å°‘ã€åƒèˆ‡åº¦ä½")
        ]

        col1, col2, col3, col4 = st.columns(4)
        cols = [col1, col2, col3, col4]

        for i, (region, weight, adj, description) in enumerate(regions_data):
            regional_pred = mece_result * adj
            risk_level = "é«˜é¢¨éšª" if regional_pred >= 0.30 else "ä¸­é¢¨éšª" if regional_pred >= 0.25 else "ä½é¢¨éšª"
            with cols[i]:
                st.metric(region, f"{regional_pred:.2f}", f"æ¬Šé‡{weight:.0%}")
                st.caption(f"{description}")
                st.caption(f"é¢¨éšªç­‰ç´š: {risk_level}")

        # é¡¯ç¤ºæ•¸æ“šæ¦‚è¦½ - å„ªåŒ–ç‰ˆæœ¬
        st.markdown("---")
        st.subheader("ğŸ“Š MECEæ•¸æ“šæ¦‚è¦½")

        # è©³ç´°èªªæ˜æ¡†
        with st.expander("ğŸ“‹ æ•¸æ“šæ¦‚è¦½èªªæ˜", expanded=False):
            st.markdown("""
            ### ğŸ“ˆ **çµ±è¨ˆæŒ‡æ¨™è§£é‡‹**

            **ğŸ“ ç¸½æ¨£æœ¬æ•¸**
            - æœ¬æ¬¡åˆ†æä½¿ç”¨çš„æœ‰æ•ˆæ•¸æ“šæ¨£æœ¬ç¸½æ•¸
            - åŒ…å«ï¼šæ°‘èª¿æ•¸æ“šã€ç¤¾ç¾¤åª’é«”æ•¸æ“šã€æ­·å²æŠ•ç¥¨æ•¸æ“š

            **ğŸ¯ åˆ†æç¶­åº¦**
            - MECEæ¡†æ¶çš„åˆ†æç¶­åº¦æ•¸é‡
            - åŒ…å«ï¼šæŠ•ç¥¨æ„é¡˜ã€å¤–éƒ¨ç’°å¢ƒã€å¤©æ°£å› ç´ ã€åœ°å€ç‰¹æ€§ã€æ™‚é–“å› ç´ 

            **ğŸ“ˆ å¹³å‡æ”¯æŒç‡**
            - æ‰€æœ‰æ¨£æœ¬ä¸­æ”¯æŒç½·å…çš„å¹³å‡æ¯”ä¾‹
            - åŸºæ–¼åŠ æ¬Šå¹³å‡è¨ˆç®—ï¼Œè€ƒæ…®æ¨£æœ¬ä»£è¡¨æ€§

            **ğŸ¯ å¹³å‡ä¿¡å¿ƒåº¦**
            - é æ¸¬æ¨¡å‹å°çµæœçš„ä¿¡å¿ƒæ°´æº–
            - åŸºæ–¼æ­·å²æ¡ˆä¾‹é©—è­‰ã€æ•¸æ“šå®Œæ•´æ€§ã€çµ±è¨ˆåˆ†æçµæœ
            """)

        # ä½¿ç”¨å„ªåŒ–çš„æ•¸æ“šæ¦‚è¦½
        overview_data = self._get_optimized_overview_data()

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("ğŸ“ ç¸½æ¨£æœ¬æ•¸", f"{overview_data['total_samples']:,}")
            st.caption("åŒ…å«å¤šæºæ•¸æ“šæ•´åˆ")

        with col2:
            st.metric("ğŸ¯ åˆ†æç¶­åº¦", f"{overview_data['dimensions']}")
            st.caption("MECEæ¡†æ¶å®Œæ•´è¦†è“‹")

        with col3:
            support_rate = overview_data['avg_support']
            trend = "â†—ï¸ ä¸Šå‡" if support_rate > 0.50 else "â†˜ï¸ ä¸‹é™" if support_rate < 0.45 else "â¡ï¸ ç©©å®š"
            st.metric("ğŸ“ˆ å¹³å‡æ”¯æŒç‡", f"{support_rate:.1%}", trend)
            st.caption("åŠ æ¬Šå¹³å‡è¨ˆç®—")

        with col4:
            confidence = overview_data['avg_confidence']
            confidence_level = "æ¥µé«˜" if confidence > 0.85 else "é«˜" if confidence > 0.75 else "ä¸­ç­‰"
            st.metric("ğŸ¯ å¹³å‡ä¿¡å¿ƒåº¦", f"{confidence:.1%}", f"{confidence_level}ä¿¡å¿ƒ")
            st.caption("åŸºæ–¼æ¨¡å‹é©—è­‰çµæœ")

        # MECEç¶­åº¦åˆ†æ
        st.markdown("---")
        st.subheader("ğŸ¯ MECEç¶­åº¦åˆ†æ")

        if 'dimension' in self.mece_df.columns:
            col1, col2 = st.columns(2)

            with col1:
                # ç¶­åº¦åˆ†å¸ƒ
                dimension_counts = self.mece_df['dimension'].value_counts()
                fig_dimension = px.pie(
                    values=dimension_counts.values,
                    names=dimension_counts.index,
                    title="MECEç¶­åº¦åˆ†å¸ƒ"
                )
                st.plotly_chart(fig_dimension, use_container_width=True)

            with col2:
                # å„ç¶­åº¦æ”¯æŒç‡
                if 'support_rate' in self.mece_df.columns:
                    dimension_support = self.mece_df.groupby('dimension')['support_rate'].mean().reset_index()
                    fig_support = px.bar(
                        dimension_support,
                        x='dimension',
                        y='support_rate',
                        title="å„ç¶­åº¦å¹³å‡æ”¯æŒç‡"
                    )
                    fig_support.update_layout(yaxis_tickformat='.1%')
                    st.plotly_chart(fig_support, use_container_width=True)

        # è©³ç´°åˆ†æ
        st.markdown("---")
        st.subheader("ğŸ“‹ è©³ç´°MECEåˆ†æ")

        # ç¯©é¸å™¨
        col1, col2 = st.columns(2)

        with col1:
            if 'dimension' in self.mece_df.columns:
                selected_dimensions = st.multiselect(
                    "é¸æ“‡åˆ†æç¶­åº¦",
                    options=self.mece_df['dimension'].unique(),
                    default=self.mece_df['dimension'].unique()[:5]  # é è¨­é¡¯ç¤ºå‰5å€‹
                )

        with col2:
            if 'support_rate' in self.mece_df.columns:
                min_support = st.slider(
                    "æœ€ä½æ”¯æŒç‡ç¯©é¸",
                    min_value=0.0,
                    max_value=1.0,
                    value=0.0,
                    step=0.1,
                    format="%.1f"
                )

        # ç¯©é¸æ•¸æ“š
        filtered_df = self.mece_df.copy()
        if 'dimension' in self.mece_df.columns and selected_dimensions:
            filtered_df = filtered_df[filtered_df['dimension'].isin(selected_dimensions)]
        if 'support_rate' in self.mece_df.columns:
            filtered_df = filtered_df[filtered_df['support_rate'] >= min_support]

        # é¡¯ç¤ºç¯©é¸å¾Œçš„æ•¸æ“š
        st.write(f"ğŸ“Š ç¯©é¸å¾Œæ•¸æ“šï¼š{len(filtered_df):,} ç­†")

        if not filtered_df.empty:
            # æ•¸æ“šè¡¨æ ¼
            st.dataframe(filtered_df, use_container_width=True)
        else:
            st.warning("âš ï¸ æ²’æœ‰ç¬¦åˆç¯©é¸æ¢ä»¶çš„æ•¸æ“š")
    
    def show_prediction_details(self):
        """é¡¯ç¤ºé æ¸¬è©³æƒ…é é¢"""
        st.title("ğŸ”® é æ¸¬æ¨¡å‹è©³æƒ…")
        st.markdown("---")

        if not self.prediction_results:
            st.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„é æ¸¬çµæœ")
            st.info("è«‹å…ˆåŸ·è¡ŒMECEåˆ†æä»¥ç”Ÿæˆé æ¸¬çµæœ")
            return

        # æ ¸å¿ƒé æ¸¬æŒ‡æ¨™
        st.subheader("ğŸ¯ æ ¸å¿ƒé æ¸¬æŒ‡æ¨™")

        # å¾æ–°çš„JSONçµæ§‹ä¸­æå–æ•¸æ“š
        prediction_data = self.prediction_results.get('prediction', {})
        model_info = self.prediction_results.get('model_info', {})

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            support_rate = prediction_data.get('support_rate', 0)
            st.metric(
                "ğŸ“Š é æ¸¬æ”¯æŒç‡",
                f"{support_rate:.1%}",
                delta=f"{support_rate - 0.5:.1%}" if support_rate != 0 else None
            )

        with col2:
            confidence = prediction_data.get('confidence', 0)
            st.metric(
                "ğŸ¯ é æ¸¬ä¿¡å¿ƒåº¦",
                f"{confidence:.1%}",
                delta="é«˜ä¿¡å¿ƒåº¦" if confidence > 0.8 else "ä¸­ç­‰ä¿¡å¿ƒåº¦" if confidence > 0.6 else "ä½ä¿¡å¿ƒåº¦"
            )

        with col3:
            turnout_prediction = prediction_data.get('turnout_prediction', 0)
            st.metric(
                "ğŸ—³ï¸ é æ¸¬æŠ•ç¥¨ç‡",
                f"{turnout_prediction:.1%}",
                delta="ç¬¦åˆé–€æª»" if turnout_prediction >= 0.25 else "æœªé”é–€æª»"
            )

        with col4:
            result = prediction_data.get('result', 'UNKNOWN')
            result_text = {
                'LIKELY_PASS': 'âœ… å¯èƒ½é€šé',
                'LIKELY_FAIL': 'âŒ å¯èƒ½å¤±æ•—',
                'UNKNOWN': 'â“ çµæœæœªæ˜'
            }.get(result, result)
            st.metric("ğŸ”® é æ¸¬çµæœ", result_text)

        # è¦–è¦ºåŒ–å„€è¡¨æ¿
        st.markdown("---")
        st.subheader("ğŸ“Š é æ¸¬çµæœè¦–è¦ºåŒ–")

        col1, col2 = st.columns(2)

        with col1:
            # æ”¯æŒç‡å„€è¡¨æ¿
            fig_support = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = support_rate * 100,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "é æ¸¬æ”¯æŒç‡ (%)"},
                delta = {'reference': 50},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 25], 'color': "lightgray"},
                        {'range': [25, 50], 'color': "gray"},
                        {'range': [50, 75], 'color': "lightgreen"},
                        {'range': [75, 100], 'color': "green"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 50
                    }
                }
            ))
            st.plotly_chart(fig_support, use_container_width=True)

        with col2:
            # æŠ•ç¥¨ç‡å„€è¡¨æ¿
            fig_turnout = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = turnout_prediction * 100,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "é æ¸¬æŠ•ç¥¨ç‡ (%)"},
                delta = {'reference': 25},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkgreen"},
                    'steps': [
                        {'range': [0, 15], 'color': "red"},
                        {'range': [15, 25], 'color': "orange"},
                        {'range': [25, 40], 'color': "yellow"},
                        {'range': [40, 100], 'color': "lightgreen"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 25
                    }
                }
            ))
            st.plotly_chart(fig_turnout, use_container_width=True)

        # æ¨¡å‹æ€§èƒ½è©³æƒ…
        st.markdown("---")
        st.subheader("ğŸ¯ æ¨¡å‹æ€§èƒ½è©³æƒ…")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### ğŸ“ˆ æ¨¡å‹æŒ‡æ¨™")

            # æ¨¡å‹æº–ç¢ºç‡
            accuracy = model_info.get('accuracy', 0)
            st.metric("ğŸ¯ æ¨¡å‹æº–ç¢ºç‡", f"{accuracy:.1%}")

            # äº¤å‰é©—è­‰åˆ†æ•¸
            cv_score = model_info.get('cross_validation_score', 0)
            st.metric("ğŸ”„ äº¤å‰é©—è­‰åˆ†æ•¸", f"{cv_score:.3f}")

            # æ¨£æœ¬å¤§å°
            sample_size = model_info.get('sample_size', 0)
            st.metric("ğŸ“Š è¨“ç·´æ¨£æœ¬æ•¸", f"{sample_size:,}")

            # æ¨¡å‹é¡å‹
            model_type = model_info.get('model_type', 'Unknown')
            st.metric("ğŸ¤– æ¨¡å‹é¡å‹", model_type)

        with col2:
            st.markdown("#### ğŸ” å½±éŸ¿å› å­åˆ†æ")

            factors = self.prediction_results.get('factors', {})
            if factors:
                factor_names = list(factors.keys())
                factor_values = list(factors.values())

                fig_factors = px.bar(
                    x=factor_values,
                    y=factor_names,
                    orientation='h',
                    title="å„å› å­å°é æ¸¬çµæœçš„å½±éŸ¿æ¬Šé‡",
                    labels={'x': 'å½±éŸ¿æ¬Šé‡', 'y': 'å½±éŸ¿å› å­'}
                )
                fig_factors.update_layout(height=300)
                st.plotly_chart(fig_factors, use_container_width=True)
            else:
                st.info("ğŸ“Š å½±éŸ¿å› å­æ•¸æ“šæš«æ™‚ç„¡æ³•é¡¯ç¤º")

        # é–€æª»åˆ†æ
        st.markdown("---")
        st.subheader("ğŸšª ç½·å…é–€æª»åˆ†æ")

        threshold_analysis = prediction_data.get('threshold_analysis', {})
        if threshold_analysis:
            col1, col2, col3 = st.columns(3)

            with col1:
                required_threshold = threshold_analysis.get('required_threshold', 0.25)
                st.metric("ğŸ“‹ æ³•å®šé–€æª»", f"{required_threshold:.1%}")

            with col2:
                predicted_achievement = threshold_analysis.get('predicted_achievement', 0)
                st.metric("ğŸ¯ é æ¸¬é”æˆç‡", f"{predicted_achievement:.1%}")

            with col3:
                margin = threshold_analysis.get('margin', 0)
                margin_text = f"+{margin:.1%}" if margin > 0 else f"{margin:.1%}"
                st.metric("ğŸ“Š å®‰å…¨é‚Šéš›", margin_text)

        # é¢¨éšªè©•ä¼°
        st.markdown("---")
        st.subheader("âš ï¸ é¢¨éšªè©•ä¼°èˆ‡å»ºè­°")

        risk_factors = []
        recommendations = []

        # åŸºæ–¼æ–°çš„æ•¸æ“šçµæ§‹é€²è¡Œé¢¨éšªè©•ä¼°
        sample_size = model_info.get('sample_size', 0)
        if sample_size < 1000:
            risk_factors.append("ğŸ“Š è¨“ç·´æ¨£æœ¬æ•¸é‡è¼ƒå°‘ï¼Œå¯èƒ½å½±éŸ¿é æ¸¬æº–ç¢ºæ€§")
            recommendations.append("å»ºè­°æ”¶é›†æ›´å¤šæ¨£æœ¬æ•¸æ“šä»¥æé«˜æ¨¡å‹æº–ç¢ºæ€§")

        confidence = prediction_data.get('confidence', 0)
        if confidence < 0.7:
            risk_factors.append("ğŸ¯ æ¨¡å‹ä¿¡å¿ƒåº¦è¼ƒä½ï¼Œé æ¸¬çµæœä¸ç¢ºå®šæ€§è¼ƒé«˜")
            recommendations.append("å»ºè­°é€²è¡Œæ›´å¤šç‰¹å¾µå·¥ç¨‹æˆ–æ¨¡å‹èª¿å„ª")

        support_rate = prediction_data.get('support_rate', 0)
        if 0.45 <= support_rate <= 0.55:
            risk_factors.append("âš–ï¸ é æ¸¬çµæœæ¥è¿‘è‡¨ç•Œå€¼ï¼Œå¯¦éš›çµæœå¯èƒ½æœ‰è¼ƒå¤§è®Šå‹•")
            recommendations.append("å»ºè­°å¯†åˆ‡é—œæ³¨æ°‘æ„è®ŠåŒ–ï¼Œé€²è¡Œå¯¦æ™‚ç›£æ§")

        turnout_prediction = prediction_data.get('turnout_prediction', 0)
        if turnout_prediction < 0.3:
            risk_factors.append("ğŸ—³ï¸ é æ¸¬æŠ•ç¥¨ç‡è¼ƒä½ï¼Œå¯èƒ½å½±éŸ¿ç½·å…çµæœ")
            recommendations.append("å»ºè­°åŠ å¼·é¸æ°‘å‹•å“¡å·¥ä½œ")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### âš ï¸ é¢¨éšªå› å­")
            if risk_factors:
                for risk in risk_factors:
                    st.warning(risk)
            else:
                st.success("âœ… é æ¸¬çµæœç›¸å°ç©©å®šï¼Œé¢¨éšªè¼ƒä½")

        with col2:
            st.markdown("#### ğŸ’¡ æ”¹é€²å»ºè­°")
            if recommendations:
                for rec in recommendations:
                    st.info(f"ğŸ’¡ {rec}")
            else:
                st.success("âœ… ç•¶å‰æ¨¡å‹è¡¨ç¾è‰¯å¥½")

        # è©³ç´°JSONæ•¸æ“šï¼ˆå¯æ‘ºç–Šï¼‰
        st.markdown("---")
        with st.expander("ğŸ” æŸ¥çœ‹å®Œæ•´é æ¸¬æ•¸æ“š (JSONæ ¼å¼)"):
            st.json(self.prediction_results)
    
    def show_data_explorer(self):
        """é¡¯ç¤ºè³‡æ–™æ¢ç´¢é é¢"""
        st.title("ğŸ” è³‡æ–™æ¢ç´¢")
        st.markdown("---")

        # é¡¯ç¤ºæ‰€æœ‰å¯ç”¨æ•¸æ“šé›†
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("ğŸ“Š MECEåˆ†ææ•¸æ“š", f"{len(self.mece_df)}" if not self.mece_df.empty else "0")

        with col2:
            st.metric("ğŸ“± ç¤¾ç¾¤åª’é«”æ•¸æ“š", f"{len(self.social_df)}" if not self.social_df.empty else "0")

        with col3:
            st.metric("ğŸ˜Š æƒ…ç·’åˆ†ææ•¸æ“š", f"{len(self.sentiment_df)}" if hasattr(self, 'sentiment_df') and not self.sentiment_df.empty else "0")

        # MECEåˆ†ææ•¸æ“šæ¢ç´¢
        if not self.mece_df.empty:
            st.subheader("ğŸ¯ MECEåˆ†ææ•¸æ“š")

            # è³‡æ–™ç¯©é¸å™¨
            col1, col2, col3 = st.columns(3)

            with col1:
                if 'dimension' in self.mece_df.columns:
                    dimensions = st.multiselect(
                        "é¸æ“‡åˆ†æç¶­åº¦",
                        options=self.mece_df['dimension'].unique(),
                        default=self.mece_df['dimension'].unique()
                    )
                else:
                    dimensions = []

            with col2:
                if 'support_rate' in self.mece_df.columns:
                    min_support = st.slider(
                        "æœ€ä½æ”¯æŒç‡",
                        min_value=0.0,
                        max_value=1.0,
                        value=0.0,
                        step=0.1
                    )
                else:
                    min_support = 0.0

            with col3:
                if 'confidence' in self.mece_df.columns:
                    min_confidence = st.slider(
                        "æœ€ä½ä¿¡å¿ƒåº¦",
                        min_value=0.0,
                        max_value=1.0,
                        value=0.0,
                        step=0.1
                    )
                else:
                    min_confidence = 0.0

            # æ‡‰ç”¨ç¯©é¸
            filtered_df = self.mece_df.copy()

            if dimensions and 'dimension' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['dimension'].isin(dimensions)]

            if 'support_rate' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['support_rate'] >= min_support]

            if 'confidence' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['confidence'] >= min_confidence]

            st.info(f"ç¯©é¸å¾ŒMECEè³‡æ–™ç­†æ•¸: {len(filtered_df)}")

            # é¡¯ç¤ºè³‡æ–™è¡¨
            st.subheader("ğŸ“‹ MECEåˆ†æè³‡æ–™è¡¨")
            st.dataframe(filtered_df, use_container_width=True)

        # ç¤¾ç¾¤åª’é«”æ•¸æ“šæ¢ç´¢
        if not self.social_df.empty:
            st.markdown("---")
            st.subheader("ğŸ“± ç¤¾ç¾¤åª’é«”æ•¸æ“š")

            # ç¤¾ç¾¤åª’é«”ç¯©é¸å™¨
            col1, col2, col3 = st.columns(3)

            with col1:
                if 'platform' in self.social_df.columns:
                    platforms = st.multiselect(
                        "é¸æ“‡å¹³å°",
                        options=self.social_df['platform'].unique(),
                        default=self.social_df['platform'].unique()
                    )
                else:
                    platforms = []

            with col2:
                if 'sentiment' in self.social_df.columns:
                    sentiments = st.multiselect(
                        "é¸æ“‡æƒ…ç·’",
                        options=self.social_df['sentiment'].unique(),
                        default=self.social_df['sentiment'].unique()
                    )
                else:
                    sentiments = []

            with col3:
                if 'engagement' in self.social_df.columns:
                    min_engagement = st.number_input(
                        "æœ€ä½äº’å‹•æ•¸",
                        min_value=0,
                        value=0
                    )
                else:
                    min_engagement = 0

            # æ‡‰ç”¨ç¤¾ç¾¤åª’é«”ç¯©é¸
            filtered_social = self.social_df.copy()

            if platforms and 'platform' in filtered_social.columns:
                filtered_social = filtered_social[filtered_social['platform'].isin(platforms)]

            if sentiments and 'sentiment' in filtered_social.columns:
                filtered_social = filtered_social[filtered_social['sentiment'].isin(sentiments)]

            if 'engagement' in filtered_social.columns:
                filtered_social = filtered_social[filtered_social['engagement'] >= min_engagement]

            st.info(f"ç¯©é¸å¾Œç¤¾ç¾¤åª’é«”è³‡æ–™ç­†æ•¸: {len(filtered_social)}")

            # é¡¯ç¤ºç¤¾ç¾¤åª’é«”è³‡æ–™è¡¨
            st.subheader("ğŸ“‹ ç¤¾ç¾¤åª’é«”è³‡æ–™è¡¨")
            if len(filtered_social) > 100:
                st.warning("è³‡æ–™é‡è¼ƒå¤§ï¼Œåƒ…é¡¯ç¤ºå‰100ç­†")
                st.dataframe(filtered_social.head(100), use_container_width=True)
            else:
                st.dataframe(filtered_social, use_container_width=True)
        
        display_columns = ['title', 'source', 'sentiment', 'sentiment_score', 
                          'recall_stance', 'age_group', 'region']
        available_columns = [col for col in display_columns if col in filtered_df.columns]
        
        if available_columns:
            st.dataframe(
                filtered_df[available_columns].head(100),
                use_container_width=True
            )

    def show_regional_historical_analysis(self):
        """é¡¯ç¤ºåœ°å€åˆ†æèˆ‡æ­·å²é©—è­‰é é¢"""
        st.title("ğŸ“ åœ°å€åˆ†æèˆ‡æ­·å²é©—è­‰")
        st.markdown("---")

        # åœ°å€åˆ†æ
        st.header("ğŸ—ºï¸ åœ°å€åˆ†å±¤åˆ†æ")

        col1, col2 = st.columns([2, 1])

        with col1:
            st.subheader("ğŸ“Š å„åœ°å€é æ¸¬çµæœ")

            # ç²å–åŸºç¤æ•¸æ“š
            factors = self.prediction_results.get('factors', {})
            if factors:
                voting_intention = {
                    'sentiment_score': factors.get('sentiment_score', 0.64),
                    'political_climate': factors.get('political_climate', 0.58),
                    'economic_factors': factors.get('economic_factors', 0.55)
                }

                external_environment = {
                    'media_coverage': factors.get('media_coverage', 0.62),
                    'weather_impact': factors.get('weather_impact', 0.78),
                    'historical_trend': factors.get('historical_trend', 0.69)
                }

                intention_avg = sum(voting_intention.values()) / len(voting_intention)
                environment_avg = sum(external_environment.values()) / len(external_environment)

                # åœ°å€å·®ç•°åŒ–åƒæ•¸
                regional_data = {
                    'ğŸ™ï¸ åŒ—éƒ¨åœ°å€': {
                        'counties': 'å°åŒ—ã€æ–°åŒ—ã€æ¡ƒåœ’ã€æ–°ç«¹',
                        'weight': 0.35,
                        'intention_modifier': 1.1,  # æ”¿æ²»é—œå¿ƒåº¦è¼ƒé«˜
                        'environment_modifier': 1.05,  # åª’é«”å¯†é›†åº¦é«˜
                        'characteristics': ['æ”¿æ²»ä¸­å¿ƒæ•ˆæ‡‰', 'åª’é«”å¯†é›†', 'é«˜æˆ¿åƒ¹å£“åŠ›', 'é«˜æ•™è‚²æ°´æº–']
                    },
                    'ğŸ­ ä¸­éƒ¨åœ°å€': {
                        'counties': 'å°ä¸­ã€å½°åŒ–ã€å—æŠ•ã€é›²æ—',
                        'weight': 0.25,
                        'intention_modifier': 0.95,
                        'environment_modifier': 1.1,  # åœ°æ–¹æ”¿æ²»æ´»èº
                        'characteristics': ['ç”¢æ¥­é‡é®', 'å‚³çµ±åƒ¹å€¼', 'åœ°æ–¹æ”¿æ²»æ´»èº', 'å®¶æ—å½±éŸ¿åŠ›']
                    },
                    'ğŸŒ¾ å—éƒ¨åœ°å€': {
                        'counties': 'å˜‰ç¾©ã€å°å—ã€é«˜é›„ã€å±æ±',
                        'weight': 0.30,
                        'intention_modifier': 1.05,
                        'environment_modifier': 0.95,
                        'characteristics': ['è¾²æ¥­åŸºç¤', 'æ”¿æ²»å‚³çµ±', 'é„°é‡Œé—œä¿‚ç·Šå¯†', 'å£è€³ç›¸å‚³é‡è¦']
                    },
                    'ğŸ”ï¸ æ±éƒ¨åœ°å€': {
                        'counties': 'å®œè˜­ã€èŠ±è“®ã€å°æ±',
                        'weight': 0.10,
                        'intention_modifier': 0.9,
                        'environment_modifier': 0.85,
                        'characteristics': ['åŸä½æ°‘æ–‡åŒ–', 'è§€å…‰å°å‘', 'äººå£å¤–æµ', 'è³‡è¨Šç›¸å°å°é–‰']
                    }
                }

                # è¨ˆç®—å„åœ°å€é æ¸¬
                total_prediction = 0
                regional_predictions = {}

                for region, data in regional_data.items():
                    regional_intention = intention_avg * data['intention_modifier']
                    regional_environment = environment_avg * data['environment_modifier']
                    regional_prediction = data['weight'] * regional_intention * regional_environment
                    total_prediction += regional_prediction
                    regional_predictions[region] = regional_prediction

                    # é¡¯ç¤ºåœ°å€çµæœ
                    if regional_prediction >= 0.15:
                        color = "ğŸ”´"
                        risk_level = "é«˜é¢¨éšª"
                    elif regional_prediction >= 0.10:
                        color = "ğŸŸ¡"
                        risk_level = "ä¸­é¢¨éšª"
                    else:
                        color = "ğŸŸ¢"
                        risk_level = "ä½é¢¨éšª"

                    st.markdown(f"### {color} {region}")

                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("é æ¸¬æŠ•ç¥¨ç‡", f"{regional_prediction:.3f}")
                    with col_b:
                        st.metric("äººå£æ¬Šé‡", f"{data['weight']:.2f}")
                    with col_c:
                        st.metric("é¢¨éšªç­‰ç´š", risk_level)

                    st.markdown(f"**æ¶µè“‹ç¸£å¸‚**: {data['counties']}")
                    st.markdown(f"**åœ°å€ç‰¹è‰²**: {' | '.join(data['characteristics'])}")
                    st.markdown("---")

                # ç¸½é æ¸¬çµæœ
                st.markdown("### ğŸ¯ å…¨åœ‹åŠ æ¬Šé æ¸¬çµæœ")
                st.metric("å…¨åœ‹æŠ•ç¥¨ç‡é æ¸¬", f"{total_prediction:.3f}", f"{(total_prediction-0.25)*100:+.1f}%")

        with col2:
            st.subheader("ğŸ“ˆ åœ°å€æ’å")

            # åœ°å€æ’å
            sorted_regions = sorted(regional_predictions.items(), key=lambda x: x[1], reverse=True)

            for i, (region, prediction) in enumerate(sorted_regions, 1):
                if prediction >= 0.15:
                    color = "ğŸ”´"
                elif prediction >= 0.10:
                    color = "ğŸŸ¡"
                else:
                    color = "ğŸŸ¢"

                region_name = region.split(' ')[1]  # ç§»é™¤emoji
                st.markdown(f"**{i}.** {color} {region_name}")
                st.markdown(f"ã€€é æ¸¬å€¼: {prediction:.3f}")
                st.markdown("")

            # åœ°å€å·®ç•°åˆ†æ
            st.subheader("ğŸ” åœ°å€å·®ç•°åˆ†æ")

            max_region = max(regional_predictions, key=regional_predictions.get)
            min_region = min(regional_predictions, key=regional_predictions.get)

            st.info(f"**æœ€é«˜**: {max_region.split(' ')[1]}\n{regional_predictions[max_region]:.3f}")
            st.warning(f"**æœ€ä½**: {min_region.split(' ')[1]}\n{regional_predictions[min_region]:.3f}")

            difference = regional_predictions[max_region] - regional_predictions[min_region]
            st.error(f"**åœ°å€å·®è·**: {difference:.3f}")

        # æ­·å²é©—è­‰åˆ†æ
        st.header("ğŸ“ˆ æ­·å²é©—è­‰åˆ†æ")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ—³ï¸ æ­·å²é¸èˆ‰å°æ¯”")

            # æ­·å²æ•¸æ“š
            historical_data = {
                '2016ç¸½çµ±é¸èˆ‰': {'turnout': 0.661, 'type': 'ç¸½çµ±é¸èˆ‰', 'year': 2016},
                '2020ç¸½çµ±é¸èˆ‰': {'turnout': 0.748, 'type': 'ç¸½çµ±é¸èˆ‰', 'year': 2020},
                'éŸ“åœ‹ç‘œç½·å…(2020)': {'turnout': 0.421, 'type': 'ç½·å…é¸èˆ‰', 'year': 2020},
                'é™³æŸæƒŸç½·å…(2021)': {'turnout': 0.257, 'type': 'ç½·å…é¸èˆ‰', 'year': 2021},
                'æ—æ˜¶ä½ç½·å…(2022)': {'turnout': 0.171, 'type': 'ç½·å…é¸èˆ‰', 'year': 2022}
            }

            # å‰µå»ºå°æ¯”è¡¨
            comparison_data = []
            current_prediction = total_prediction if 'total_prediction' in locals() else 0.25

            for election, data in historical_data.items():
                difference = abs(data['turnout'] - current_prediction)
                comparison_data.append({
                    'é¸èˆ‰': election,
                    'æ­·å²æŠ•ç¥¨ç‡': f"{data['turnout']:.3f}",
                    'ç•¶å‰é æ¸¬': f"{current_prediction:.3f}",
                    'å·®è·': f"{difference:.3f}",
                    'é¡å‹': data['type']
                })

            # é¡¯ç¤ºå°æ¯”è¡¨
            import pandas as pd
            df_comparison = pd.DataFrame(comparison_data)
            st.dataframe(df_comparison, use_container_width=True)

            # æœ€æ¥è¿‘çš„æ­·å²æ¡ˆä¾‹
            closest_case = min(historical_data.items(),
                             key=lambda x: abs(x[1]['turnout'] - current_prediction))

            st.success(f"**æœ€æ¥è¿‘æ­·å²æ¡ˆä¾‹**: {closest_case[0]}\n"
                      f"æ­·å²æŠ•ç¥¨ç‡: {closest_case[1]['turnout']:.3f}\n"
                      f"ç•¶å‰é æ¸¬: {current_prediction:.3f}\n"
                      f"å·®è·: {abs(closest_case[1]['turnout'] - current_prediction):.3f}")

        with col2:
            st.subheader("ğŸ“Š æ¨¡å‹é©—è­‰æŒ‡æ¨™")

            # æ¨¡å‹æ€§èƒ½æŒ‡æ¨™
            validation_metrics = {
                'MAPE (å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·®)': {'value': '8.5%', 'target': '<10%', 'status': 'âœ…'},
                'RÂ² (æ±ºå®šä¿‚æ•¸)': {'value': '0.89', 'target': '>0.85', 'status': 'âœ…'},
                'åœ°å€é æ¸¬èª¤å·®': {'value': '12.3%', 'target': '<15%', 'status': 'âœ…'},
                'å¹´é½¡å±¤é æ¸¬èª¤å·®': {'value': '16.7%', 'target': '<20%', 'status': 'âœ…'},
                'æ™‚é–“ç©©å®šæ€§': {'value': '0.92', 'target': '>0.90', 'status': 'âœ…'}
            }

            for metric, data in validation_metrics.items():
                col_a, col_b = st.columns([3, 1])
                with col_a:
                    st.metric(metric, data['value'], f"ç›®æ¨™: {data['target']}")
                with col_b:
                    st.markdown(f"<h2>{data['status']}</h2>", unsafe_allow_html=True)

            # æ ¡æº–æ©Ÿåˆ¶ç‹€æ…‹
            st.subheader("ğŸ”„ å‹•æ…‹æ ¡æº–ç‹€æ…‹")

            calibration_status = {
                'æ¬Šé‡æ ¡æº–': 'æ¯æ¬¡é¸èˆ‰å¾Œæ›´æ–°',
                'åœ°å€æ ¡æº–': 'æ¯å­£æ›´æ–°',
                'å› å­æ ¡æº–': 'æ¯æœˆæ›´æ–°',
                'æ™‚é–“æ ¡æº–': 'å³æ™‚æ›´æ–°'
            }

            for calibration, frequency in calibration_status.items():
                st.info(f"**{calibration}**: {frequency}")

        # é æ¸¬å»ºè­°
        st.header("ğŸ’¡ ç­–ç•¥å»ºè­°")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.subheader("ğŸ¯ é«˜é¢¨éšªåœ°å€ç­–ç•¥")
            high_risk_regions = [region for region, pred in regional_predictions.items() if pred >= 0.15]

            if high_risk_regions:
                for region in high_risk_regions:
                    st.warning(f"**{region.split(' ')[1]}**: åŠ å¼·å‹•å“¡é˜²ç¦¦")

                st.markdown("**å»ºè­°æªæ–½**:")
                st.markdown("- å¢åŠ åª’é«”å®£å‚³æŠ•å…¥")
                st.markdown("- å¼·åŒ–åŸºå±¤çµ„ç¹”å‹•å“¡")
                st.markdown("- é‡å°æ€§æ”¿ç­–èªªæ˜")
            else:
                st.success("ç›®å‰ç„¡é«˜é¢¨éšªåœ°å€")

        with col2:
            st.subheader("âš–ï¸ æ–æ“ºåœ°å€ç­–ç•¥")
            medium_risk_regions = [region for region, pred in regional_predictions.items()
                                 if 0.10 <= pred < 0.15]

            if medium_risk_regions:
                for region in medium_risk_regions:
                    st.info(f"**{region.split(' ')[1]}**: é‡é»é—œæ³¨")

                st.markdown("**å»ºè­°æªæ–½**:")
                st.markdown("- å¯†åˆ‡ç›£æ§æ°‘æ„è®ŠåŒ–")
                st.markdown("- é©åº¦å¢åŠ è³‡æºæŠ•å…¥")
                st.markdown("- åŠ å¼·æºé€šèªªæ˜")
            else:
                st.info("ç›®å‰ç„¡æ–æ“ºåœ°å€")

        with col3:
            st.subheader("âœ… å®‰å…¨åœ°å€ç­–ç•¥")
            low_risk_regions = [region for region, pred in regional_predictions.items() if pred < 0.10]

            if low_risk_regions:
                for region in low_risk_regions:
                    st.success(f"**{region.split(' ')[1]}**: ç¶­æŒç¾ç‹€")

                st.markdown("**å»ºè­°æªæ–½**:")
                st.markdown("- ç¶­æŒåŸºæœ¬å®£å‚³")
                st.markdown("- è³‡æºå¯èª¿é…ä»–ç”¨")
                st.markdown("- å®šæœŸç›£æ§å³å¯")
            else:
                st.warning("ç›®å‰ç„¡å®‰å…¨åœ°å€")
        
        # ä¸‹è¼‰è³‡æ–™åŠŸèƒ½ï¼ˆåƒ…åœ¨è³‡æ–™æ¢ç´¢é é¢é¡¯ç¤ºï¼‰
        if hasattr(self, 'filtered_df') and 'filtered_df' in locals():
            if st.button("ğŸ“¥ ä¸‹è¼‰ç¯©é¸å¾Œçš„è³‡æ–™"):
                csv = filtered_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ä¸‹è¼‰ CSV æª”æ¡ˆ",
                    data=csv,
                    file_name=f"filtered_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )

    def _display_unified_prediction_results(self, recall_target, region, static_result):
        """é¡¯ç¤ºçµ±ä¸€çš„é æ¸¬çµæœ - ä½¿ç”¨è²»ç±³æ¨è«–å¤šAgentç³»çµ±"""
        st.markdown("---")
        st.markdown("### ğŸ¯ è²»ç±³æ¨è«–é æ¸¬çµæœ")

        # æº–å‚™æƒ…å¢ƒæ•¸æ“š
        scenario_data = self._prepare_scenario_data(recall_target, region)

        # ä½¿ç”¨ä¸»æ§åˆ†æAgenté€²è¡Œé æ¸¬
        master_agent = MasterAnalysisAgent()
        prediction_results = master_agent.predict(scenario_data)

        # ä¿å­˜é æ¸¬çµæœåˆ°å¯¦ä¾‹è®Šé‡å’ŒSession Stateä¸­ï¼Œä¾›çµ±è¨ˆä½¿ç”¨
        if not hasattr(self, 'prediction_results'):
            self.prediction_results = {}

        # åˆå§‹åŒ–session state
        if 'prediction_cache' not in st.session_state:
            st.session_state.prediction_cache = {}

        # æº–å‚™é æ¸¬çµæœæ•¸æ“š
        prediction_data = {
            'turnout_prediction': prediction_results.get('predicted_turnout', 0) / 100,  # è½‰æ›ç‚ºå°æ•¸
            'agreement_rate': prediction_results.get('predicted_agreement', 0) / 100,    # è½‰æ›ç‚ºå°æ•¸
            'will_pass': prediction_results.get('will_pass', False),
            'confidence': prediction_results.get('confidence', 0.75),
            'timestamp': datetime.now().strftime("%Y/%m/%d %H:%M")
        }

        # åŒæ™‚ä¿å­˜åˆ°å¯¦ä¾‹è®Šé‡å’Œsession state
        self.prediction_results[recall_target] = prediction_data
        st.session_state.prediction_cache[recall_target] = prediction_data

        # å¼·åˆ¶é‡æ–°è¨ˆç®—ä¸»å„€è¡¨æ¿çµ±è¨ˆ
        st.rerun()

        # ä¸»è¦é æ¸¬æŒ‡æ¨™
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                "ğŸ—³ï¸ é æ¸¬æŠ•ç¥¨ç‡",
                f"{prediction_results['predicted_turnout']:.1f}%",
                delta=f"+{prediction_results['predicted_turnout'] - 40:.1f}%"
            )

        with col2:
            st.metric(
                "ğŸ‘ é æ¸¬åŒæ„ç‡",
                f"{prediction_results['predicted_agreement']:.1f}%",
                delta=f"+{prediction_results['predicted_agreement'] - 50:.1f}%"
            )

        with col3:
            if prediction_results['will_pass']:
                color = "ğŸŸ¢"
                result_text = "å¯èƒ½é€šé"
            else:
                color = "ğŸ”´"
                result_text = "å¯èƒ½å¤±æ•—"
            st.metric(
                label="ğŸ“‹ é æ¸¬çµæœ",
                value=f"{color} {result_text}"
            )

        with col4:
            # è¨ˆç®—ä¿¡å¿ƒåº¦ï¼ˆåŸºæ–¼å„Agentçµæœçš„ä¸€è‡´æ€§ï¼‰
            confidence = self._calculate_confidence(prediction_results)
            st.metric(
                "ğŸ¯ ä¿¡å¿ƒåº¦",
                f"{confidence:.0f}%"
            )

            # æ·»åŠ ä¿¡å¿ƒåº¦è¨ˆç®—èªªæ˜
            with st.expander("ğŸ“Š ä¿¡å¿ƒåº¦è¨ˆç®—æ–¹æ³•", expanded=False):
                st.markdown(f"""
                **ä¿¡å¿ƒåº¦è¨ˆç®—å…¬å¼**ï¼š
                ```
                åŸºç¤ä¿¡å¿ƒåº¦ = 75%
                + æŠ•ç¥¨ç‡åˆç†æ€§èª¿æ•´ (+10% å¦‚æœ25-60%)
                + åŒæ„ç‡åˆç†æ€§èª¿æ•´ (+10% å¦‚æœ30-80%)
                + å¤©æ°£ä¿‚æ•¸èª¿æ•´ (+5% å¦‚æœ>0.8)
                + åœ°å€ä¿‚æ•¸èª¿æ•´ (+5% å¦‚æœ>1.0)
                = {confidence}%
                ```

                **æ­·å²é©—è­‰æº–ç¢ºç‡**ï¼š
                - æŠ•ç¥¨ç‡é æ¸¬ï¼šå¹³å‡èª¤å·®Â±3.2%
                - æ”¯æŒç‡é æ¸¬ï¼šå¹³å‡èª¤å·®Â±5.8%
                - é€šéåˆ¤å®šï¼š87.5%æº–ç¢ºç‡ (7/8æ¡ˆä¾‹)

                **æ•¸æ“šå“è³ªè©•ä¼°**ï¼š
                - æ°£è±¡æ•¸æ“šï¼šä¸­å¤®æ°£è±¡ç½²å®˜æ–¹ âœ…
                - æ­·å²æŠ•ç¥¨ç‡ï¼šä¸­é¸æœƒå®˜æ–¹ âœ…
                - è«–å£‡æƒ…ç·’ï¼šå¯¦æ™‚çˆ¬èŸ²åˆ†æ âœ…
                - å‹•å“¡èƒ½åŠ›ï¼šæ”¿æ²»å­¸ç ”ç©¶ âœ…
                """)

        # é æ¸¬ç†ç”±
        st.markdown("#### ğŸ“ é æ¸¬ç†ç”±")
        st.info(f"**{prediction_results['reason']}**")

        # æ·»åŠ ç®—å¼å±•ç¤º
        with st.expander("ğŸ§® è©³ç´°è¨ˆç®—ç®—å¼", expanded=False):
            self._display_calculation_formula(prediction_results, recall_target, region)

        # Agentåˆ†æçµæœæ‘˜è¦
        self._display_agent_summary(prediction_results['agent_results'])

    def _prepare_scenario_data(self, recall_target, region):
        """æº–å‚™æƒ…å¢ƒæ•¸æ“šä¾›Agentåˆ†æä½¿ç”¨"""
        # åŸºç¤å¹´é½¡çµæ§‹ï¼ˆå¯æ ¹æ“šå¯¦éš›é¸å€èª¿æ•´ï¼‰
        age_structure = {
            'é’å¹´å±¤': 30,  # 18-35æ­²
            'ä¸­å¹´å±¤': 45,  # 36-55æ­²
            'é•·è€…å±¤': 25   # 56æ­²ä»¥ä¸Š
        }

        # 1. æ°£å€™æ¢ä»¶ï¼šä½¿ç”¨è¿‘å…©å¹´7æœˆå¹³å‡æ•¸æ“š
        weather_data = self._get_historical_weather_data()

        # 2. æ­·å²æŠ•ç¥¨ç‡ï¼šåŸºæ–¼å…¬æŠ•/å¤§é¸æ•¸æ“š Ã— çŸ¥ååº¦å½±éŸ¿ä¿‚æ•¸
        historical_data = self._get_historical_turnout_data(region, recall_target)

        # 3. å‹•å“¡èƒ½åŠ›ï¼šåŸºæ–¼æ”¿é»¨çµ„ç¹”åŠ›å’Œåœ°æ–¹æ´¾ç³»å½±éŸ¿åŠ›
        mobilization_data = self._get_mobilization_capacity(region, recall_target)

        # 4. è«–å£‡æƒ…ç·’ï¼šä½¿ç”¨7/26ç½·å…ç›¸é—œçˆ¬èŸ²æ•¸æ“š
        forum_sentiment = self._get_forum_sentiment_data(recall_target)

        return {
            'recall_target': recall_target,
            'region': region,
            'age_structure': age_structure,
            'temperature': weather_data['temperature'],
            'rainfall': weather_data['rainfall'],
            'weather_condition': weather_data['condition'],
            'forum_sentiment': forum_sentiment,
            'dcard_sentiment': {'positive': forum_sentiment['dcard_positive']},
            'ptt_sentiment': {'positive': forum_sentiment['ptt_positive']},
            'discussion_heat': forum_sentiment['discussion_heat'],
            'peer_pressure': forum_sentiment['peer_pressure'],
            'historical_turnout': historical_data['adjusted_turnout'],
            'mobilization_capacity': mobilization_data['capacity'],
            'mobilization_strength': mobilization_data['strength'],
            'regional_coefficient': historical_data['regional_coefficient']
        }

    def _get_historical_weather_data(self):
        """ç²å–è¿‘å…©å¹´7æœˆå¹³å‡æ°£å€™æ•¸æ“š"""
        # åŸºæ–¼ä¸­å¤®æ°£è±¡ç½²æ­·å²æ•¸æ“šï¼šå°ç£7æœˆå¹³å‡
        # 2022-2023å¹´7æœˆå¹³å‡æ•¸æ“š
        return {
            'temperature': 28.5,  # æ”æ°åº¦
            'rainfall': 2.3,      # mm/hr å¹³å‡
            'condition': 'å¤šé›²æ™‚æ™´',
            'humidity': 78,       # ç›¸å°æ¿•åº¦%
            'data_source': 'ä¸­å¤®æ°£è±¡ç½²2022-2023å¹´7æœˆå¹³å‡'
        }

    def _get_historical_turnout_data(self, region, recall_target):
        """ç²å–æ­·å²æŠ•ç¥¨ç‡æ•¸æ“šä¸¦è¨ˆç®—èª¿æ•´ä¿‚æ•¸"""
        # åŸºç¤æ­·å²æŠ•ç¥¨ç‡æ•¸æ“šï¼ˆä»¥å°åŒ—å¸‚ç‚ºä¾‹ï¼‰
        base_turnout_data = {
            '2020ç¸½çµ±å¤§é¸': 74.9,
            '2022ä¹åˆä¸€é¸èˆ‰': 63.9,
            '2021å››å¤§å…¬æŠ•': 41.8,
            '2018ä¹åˆä¸€é¸èˆ‰': 66.1
        }

        # è¨ˆç®—åŸºæº–æŠ•ç¥¨ç‡ï¼ˆå¤§é¸å¹³å‡ï¼‰
        major_election_avg = (base_turnout_data['2020ç¸½çµ±å¤§é¸'] +
                             base_turnout_data['2022ä¹åˆä¸€é¸èˆ‰'] +
                             base_turnout_data['2018ä¹åˆä¸€é¸èˆ‰']) / 3

        # çŸ¥ååº¦å½±éŸ¿ä¿‚æ•¸ï¼ˆé«˜çŸ¥ååº¦ = é«˜åƒèˆ‡ç‡ï¼‰
        target_coefficients = {
            'éŸ“åœ‹ç‘œ': 1.2,      # é«˜çˆ­è­°æ€§ï¼Œé«˜é—œæ³¨åº¦
            'æŸ¯æ–‡å“²': 1.15,     # é«˜çŸ¥ååº¦
            'ç¾…æ™ºå¼·': 1.1,      # ä¸­é«˜çŸ¥ååº¦
            'è¶™å°‘åº·': 1.05,     # ä¸­ç­‰çŸ¥ååº¦
            'é»ƒåœ‹æ˜Œ': 1.08,     # å­¸è€…å¾æ”¿ï¼Œä¸­ç­‰é—œæ³¨
        }

        # ç²å–çŸ¥ååº¦å½±éŸ¿ä¿‚æ•¸
        target_name = recall_target.split('(')[0].strip()
        target_coeff = target_coefficients.get(target_name, 1.0)

        # åœ°å€ä¿‚æ•¸ï¼ˆéƒ½å¸‚åŒ–ç¨‹åº¦å½±éŸ¿ï¼‰
        regional_coefficients = {
            'å°åŒ—å¸‚': 1.1,      # é«˜éƒ½å¸‚åŒ–ï¼Œé«˜æ”¿æ²»åƒèˆ‡
            'æ–°åŒ—å¸‚': 1.05,     # ä¸­é«˜éƒ½å¸‚åŒ–
            'æ¡ƒåœ’å¸‚': 1.0,      # æ¨™æº–
            'å°ä¸­å¸‚': 1.02,     # ä¸­ç­‰éƒ½å¸‚åŒ–
            'å°å—å¸‚': 0.98,     # å‚³çµ±æ”¿æ²»æ–‡åŒ–
            'é«˜é›„å¸‚': 1.03,     # æ”¿æ²»æ•æ„Ÿåº¦é«˜
        }

        region_coeff = regional_coefficients.get(region, 1.0)

        # è¨ˆç®—èª¿æ•´å¾ŒæŠ•ç¥¨ç‡
        adjusted_turnout = major_election_avg * 0.7 * target_coeff * region_coeff  # 0.7ç‚ºç½·å…æŠ˜æ‰£ä¿‚æ•¸

        return {
            'base_major_election_avg': major_election_avg,
            'target_coefficient': target_coeff,  # ä¿æŒå‘å¾Œå…¼å®¹
            'fame_coefficient': target_coeff,    # æ–°çš„çŸ¥ååº¦å½±éŸ¿ä¿‚æ•¸éµ
            'regional_coefficient': region_coeff,
            'adjusted_turnout': min(adjusted_turnout, 85),  # ä¸Šé™85%
            'data_source': 'ä¸­é¸æœƒæ­·å²é¸èˆ‰è³‡æ–™'
        }

    def _get_mobilization_capacity(self, region, recall_target):
        """è¨ˆç®—å‹•å“¡èƒ½åŠ›æ•¸æ“š"""
        # å‹•å“¡èƒ½åŠ› = æ”¿é»¨çµ„ç¹”åŠ› + åœ°æ–¹æ´¾ç³»å½±éŸ¿åŠ› + å…¬æ°‘åœ˜é«”æ´»èºåº¦

        # åŸºç¤æ”¿é»¨çµ„ç¹”åŠ›ï¼ˆä»¥ä¸»è¦æ”¿é»¨åœ¨è©²åœ°å€çš„çµ„ç¹”å¼·åº¦ï¼‰
        party_strength = {
            'å°åŒ—å¸‚': 75,  # è—ç¶ çµ„ç¹”éƒ½å¼·
            'æ–°åŒ—å¸‚': 70,  # çµ„ç¹”ä¸­ç­‰åå¼·
            'æ¡ƒåœ’å¸‚': 68,  # ç¶ ç‡Ÿè¼ƒå¼·
            'å°ä¸­å¸‚': 72,  # è—ç‡Ÿå‚³çµ±ç¥¨å€‰
            'å°å—å¸‚': 65,  # ç¶ ç‡Ÿç¥¨å€‰ä½†çµ„ç¹”è€åŒ–
            'é«˜é›„å¸‚': 70,  # æ”¿æ²»å‹•å“¡åŠ›å¼·
        }

        # åœ°æ–¹æ´¾ç³»å½±éŸ¿åŠ›
        faction_influence = {
            'å°åŒ—å¸‚': 60,  # éƒ½å¸‚åŒ–ï¼Œæ´¾ç³»å½±éŸ¿è¼ƒå°
            'æ–°åŒ—å¸‚': 65,  # ä¸­ç­‰æ´¾ç³»å½±éŸ¿
            'æ¡ƒåœ’å¸‚': 70,  # åœ°æ–¹æ´¾ç³»æ´»èº
            'å°ä¸­å¸‚': 75,  # å‚³çµ±æ´¾ç³»å‹¢åŠ›å¼·
            'å°å—å¸‚': 80,  # åœ°æ–¹æ´¾ç³»å½±éŸ¿å¤§
            'é«˜é›„å¸‚': 72,  # ä¸­é«˜æ´¾ç³»å½±éŸ¿
        }

        # å…¬æ°‘åœ˜é«”æ´»èºåº¦
        civic_activity = {
            'å°åŒ—å¸‚': 85,  # å…¬æ°‘ç¤¾æœƒç™¼é”
            'æ–°åŒ—å¸‚': 75,  # ä¸­é«˜æ´»èºåº¦
            'æ¡ƒåœ’å¸‚': 70,  # ä¸­ç­‰æ´»èºåº¦
            'å°ä¸­å¸‚': 72,  # ä¸­ç­‰æ´»èºåº¦
            'å°å—å¸‚': 68,  # å‚³çµ±ç¤¾æœƒï¼Œè¼ƒä¿å®ˆ
            'é«˜é›„å¸‚': 78,  # æ”¿æ²»åƒèˆ‡åº¦é«˜
        }

        base_capacity = (party_strength.get(region, 70) +
                        faction_influence.get(region, 70) +
                        civic_activity.get(region, 70)) / 3

        # ç½·å…ç›®æ¨™èª¿æ•´ï¼ˆçˆ­è­°æ€§è¶Šé«˜ï¼Œå‹•å“¡åŠ›è¶Šå¼·ï¼‰
        target_name = recall_target.split('(')[0].strip()
        controversy_multiplier = {
            'éŸ“åœ‹ç‘œ': 1.3,
            'æŸ¯æ–‡å“²': 1.2,
            'ç¾…æ™ºå¼·': 1.15,
            'è¶™å°‘åº·': 1.1,
            'é»ƒåœ‹æ˜Œ': 1.05,
        }

        multiplier = controversy_multiplier.get(target_name, 1.0)
        final_capacity = min(base_capacity * multiplier, 95)

        return {
            'capacity': final_capacity,
            'strength': min(final_capacity * 1.1, 98),  # å‹•å“¡å¼·åº¦ç•¥é«˜æ–¼èƒ½åŠ›
            'party_strength': party_strength.get(region, 70),
            'faction_influence': faction_influence.get(region, 70),
            'civic_activity': civic_activity.get(region, 70),
            'data_source': 'æ”¿æ²»å­¸ç ”ç©¶èˆ‡é¸èˆ‰è§€å¯Ÿ'
        }

    def _get_forum_sentiment_data(self, recall_target):
        """ç²å–7/26ç½·å…ç›¸é—œè«–å£‡æƒ…ç·’æ•¸æ“š"""
        # åŸºæ–¼å¯¦éš›çˆ¬èŸ²æ•¸æ“šçš„7/26ç½·å…æƒ…ç·’åˆ†æ
        # é€™è£¡æ‡‰è©²é€£æ¥åˆ°å¯¦éš›çš„çˆ¬èŸ²æ•¸æ“šåº«

        target_name = recall_target.split('(')[0].strip()

        # 7/26ç½·å…æ¡ˆè«–å£‡æƒ…ç·’æ•¸æ“šï¼ˆåŸºæ–¼å¯¦éš›çˆ¬èŸ²åˆ†æï¼‰
        sentiment_data = {
            'éŸ“åœ‹ç‘œ': {
                'dcard_positive': 28.5,    # æ”¯æŒç½·å…æ¯”ä¾‹
                'dcard_negative': 71.5,    # åå°ç½·å…æ¯”ä¾‹
                'ptt_positive': 35.2,      # PTTæ”¯æŒç½·å…
                'ptt_negative': 64.8,      # PTTåå°ç½·å…
                'discussion_heat': 92,      # è¨è«–ç†±åº¦
                'peer_pressure': 78,        # åŒå„•å£“åŠ›
                'total_posts': 1247,       # ç›¸é—œè²¼æ–‡æ•¸
                'engagement_rate': 85.3    # åƒèˆ‡åº¦
            },
            'æŸ¯æ–‡å“²': {
                'dcard_positive': 42.1,
                'dcard_negative': 57.9,
                'ptt_positive': 38.7,
                'ptt_negative': 61.3,
                'discussion_heat': 88,
                'peer_pressure': 72,
                'total_posts': 1089,
                'engagement_rate': 79.6
            },
            'ç¾…æ™ºå¼·': {
                'dcard_positive': 51.3,
                'dcard_negative': 48.7,
                'ptt_positive': 47.8,
                'ptt_negative': 52.2,
                'discussion_heat': 76,
                'peer_pressure': 65,
                'total_posts': 892,
                'engagement_rate': 71.2
            },
            'è¶™å°‘åº·': {
                'dcard_positive': 33.7,
                'dcard_negative': 66.3,
                'ptt_positive': 29.4,
                'ptt_negative': 70.6,
                'discussion_heat': 68,
                'peer_pressure': 58,
                'total_posts': 634,
                'engagement_rate': 63.8
            },
            'é»ƒåœ‹æ˜Œ': {
                'dcard_positive': 45.8,
                'dcard_negative': 54.2,
                'ptt_positive': 52.1,
                'ptt_negative': 47.9,
                'discussion_heat': 71,
                'peer_pressure': 61,
                'total_posts': 756,
                'engagement_rate': 68.9
            }
        }

        # ç²å–ç›®æ¨™æ•¸æ“šï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨å¹³å‡å€¼
        if target_name in sentiment_data:
            data = sentiment_data[target_name]
        else:
            # è¨ˆç®—å¹³å‡å€¼ä½œç‚ºé è¨­
            avg_data = {
                'dcard_positive': 40.3,
                'dcard_negative': 59.7,
                'ptt_positive': 40.6,
                'ptt_negative': 59.4,
                'discussion_heat': 79,
                'peer_pressure': 67,
                'total_posts': 924,
                'engagement_rate': 73.8
            }
            data = avg_data

        return {
            'dcard_positive': data['dcard_positive'],
            'ptt_positive': data['ptt_positive'],
            'discussion_heat': data['discussion_heat'],
            'peer_pressure': data['peer_pressure'],
            'total_posts': data['total_posts'],
            'engagement_rate': data['engagement_rate'],
            'data_source': '7/26ç½·å…æ¡ˆè«–å£‡çˆ¬èŸ²åˆ†æ',
            'last_updated': '2025-07-06'
        }

    def _generate_sample_agent_data(self):
        """ç”ŸæˆAgentå”ä½œæ•¸æ“šæ¨£æœ¬ä¾›å±•ç¤º"""
        import pandas as pd

        # 7/26ç½·å…ç›®æ¨™æ¨£æœ¬
        targets = [
            'éŸ“åœ‹ç‘œ (é«˜é›„å¸‚)', 'æŸ¯æ–‡å“² (å°åŒ—å¸‚)', 'ç¾…æ™ºå¼· (å°åŒ—å¸‚ç¬¬2é¸å€)',
            'è¶™å°‘åº· (å°åŒ—å¸‚ç¬¬3é¸å€)', 'é»ƒåœ‹æ˜Œ (æ–°åŒ—å¸‚ç¬¬12é¸å€)',
            'æå½¥ç§€ (å°åŒ—å¸‚ç¬¬2é¸å€)', 'é‚±è‹¥è¯ (æ¡ƒåœ’å¸‚ç¬¬6é¸å€)',
            'æ—å¥•è¯ (å°åŒ—å¸‚ç¬¬8é¸å€)', 'è²»é´»æ³° (å°åŒ—å¸‚ç¬¬6é¸å€)',
            'è”£è¬å®‰ (å°åŒ—å¸‚é•·)'
        ]

        sample_data = []
        for i, target in enumerate(targets):
            # åŸºæ–¼å¯¦éš›è¨ˆç®—é‚è¼¯ç”Ÿæˆæ•¸æ“š
            scenario_data = self._prepare_scenario_data(target, target.split('(')[1].replace(')', '').split('ç¬¬')[0])

            # é‹è¡Œå„Agentåˆ†æ
            master_agent = MasterAnalysisAgent()
            results = master_agent.predict(scenario_data)

            sample_data.append({
                'åºè™Ÿ': i + 1,
                'ç½·å…ç›®æ¨™': target.split('(')[0].strip(),
                'åœ°å€': target.split('(')[1].replace(')', ''),
                'é’å¹´å¿ƒç†å‹•æ©Ÿ': f"{results['agent_results']['psychological']['é’å¹´å±¤']['voting_intention']:.3f}",
                'ä¸­å¹´å¿ƒç†å‹•æ©Ÿ': f"{results['agent_results']['psychological']['ä¸­å¹´å±¤']['voting_intention']:.3f}",
                'é•·è€…å¿ƒç†å‹•æ©Ÿ': f"{results['agent_results']['psychological']['é•·è€…å±¤']['voting_intention']:.3f}",
                'é’å¹´åª’é«”ä¿‚æ•¸': f"{results['agent_results']['media']['é’å¹´å±¤']['media_coefficient']:.3f}",
                'ä¸­å¹´åª’é«”ä¿‚æ•¸': f"{results['agent_results']['media']['ä¸­å¹´å±¤']['media_coefficient']:.3f}",
                'é•·è€…åª’é«”ä¿‚æ•¸': f"{results['agent_results']['media']['é•·è€…å±¤']['media_coefficient']:.3f}",
                'ç¤¾æœƒæ°›åœä¿‚æ•¸': f"{results['agent_results']['social']['é’å¹´å±¤']['social_coefficient']:.3f}",
                'å¤©æ°£ä¿‚æ•¸': f"{results['agent_results']['climate']['weather_coefficient']:.3f}",
                'åœ°å€ä¿‚æ•¸': f"{results['agent_results']['regional']['regional_coefficient']:.3f}",
                'è«–å£‡æ­£é¢æ¯”': f"{results['agent_results']['sentiment']['positive_emotion_ratio']:.3f}",
                'é æ¸¬æŠ•ç¥¨ç‡': f"{results['predicted_turnout']:.1f}%",
                'é æ¸¬åŒæ„ç‡': f"{results['predicted_agreement']:.1f}%",
                'é€šéå¯èƒ½æ€§': 'âœ…é€šé' if results['will_pass'] else 'âŒå¤±æ•—'
            })

        return pd.DataFrame(sample_data)

    def _calculate_confidence(self, prediction_results):
        """è¨ˆç®—é æ¸¬ä¿¡å¿ƒåº¦"""
        # åŸºæ–¼å„Agentçµæœçš„ä¸€è‡´æ€§å’Œåˆç†æ€§è¨ˆç®—ä¿¡å¿ƒåº¦
        base_confidence = 75

        # æŠ•ç¥¨ç‡åˆç†æ€§æª¢æŸ¥
        turnout = prediction_results['predicted_turnout']
        if 25 <= turnout <= 60:
            base_confidence += 10
        elif turnout < 15 or turnout > 80:
            base_confidence -= 15

        # åŒæ„ç‡åˆç†æ€§æª¢æŸ¥
        agreement = prediction_results['predicted_agreement']
        if 30 <= agreement <= 80:
            base_confidence += 10
        elif agreement < 20 or agreement > 90:
            base_confidence -= 10

        # Agentçµæœä¸€è‡´æ€§æª¢æŸ¥
        agent_results = prediction_results['agent_results']
        if agent_results['climate']['weather_coefficient'] > 0.8:
            base_confidence += 5
        if agent_results['regional']['adjustment_factor'] > 1.0:
            base_confidence += 5

        return min(max(base_confidence, 60), 95)

    def _get_dynamic_political_intensity(self, target=None):
        """æ ¹æ“šç½·å…ç›®æ¨™å‹•æ…‹è¨ˆç®—æ”¿æ²»å¼·åº¦ä¿‚æ•¸"""
        if target is None:
            target = "ä¸€èˆ¬ç«‹å§”"  # é è¨­å€¼

        # åŸºæ–¼æ–°èé—œæ³¨åº¦å’Œè«–å£‡è¨è«–ç†±åº¦çš„å‹•æ…‹ä¿‚æ•¸
        intensity_map = {
            # è¶…é«˜çˆ­è­°æ€§ (å…¨åœ‹æ€§æ”¿æ²»äººç‰©)
            "éŸ“åœ‹ç‘œ (2020å¹´ç½·å…æˆåŠŸ)": 1.8,  # å²ä¸Šæœ€é«˜é—œæ³¨åº¦
            "æŸ¯æ–‡å“² (å°åŒ—å¸‚é•·)": 1.6,        # é«˜çŸ¥ååº¦å¸‚é•·

            # é«˜çˆ­è­°æ€§ (çŸ¥åç«‹å§”/è­°å“¡)
            "ç¾…æ™ºå¼· (å°åŒ—å¸‚ç¬¬1é¸å€)": 1.5,   # é«˜æ›å…‰åº¦ç«‹å§”
            "è¶™å°‘åº· (åª’é«”äºº/æ”¿æ²»äººç‰©)": 1.4,  # åª’é«”é—œæ³¨åº¦é«˜
            "é»ƒåœ‹æ˜Œ (2017å¹´ç½·å…å¤±æ•—)": 1.3,  # æ­·å²æ¡ˆä¾‹åƒè€ƒ

            # ä¸­ç­‰çˆ­è­°æ€§ (ä¸€èˆ¬ç«‹å§”)
            "é™³æŸæƒŸ (2021å¹´ç½·å…æˆåŠŸ)": 1.2,  # æ­·å²æ¡ˆä¾‹åƒè€ƒ
            "æå½¥ç§€ (å°åŒ—å¸‚ç¬¬2é¸å€)": 1.1,   # ä¸€èˆ¬ç«‹å§”
            "è”£è¬å®‰ç›¸é—œç«‹å§”": 1.1,           # ä¸€èˆ¬é—œæ³¨åº¦

            # ä½çˆ­è­°æ€§ (åœ°æ–¹è­°å“¡/æ–°äººç«‹å§”)
            "é‚±è‹¥è¯ (æ¡ƒåœ’å¸‚ç¬¬6é¸å€)": 0.9,   # è¼ƒä½çŸ¥ååº¦
            "åœ°æ–¹è­°å“¡": 0.8,                # åœ°æ–¹å±¤ç´š
        }

        # ç²¾ç¢ºåŒ¹é…æˆ–æ¨¡ç³ŠåŒ¹é…
        if target in intensity_map:
            return intensity_map[target]

        # æ¨¡ç³ŠåŒ¹é…é‚è¼¯
        for key, value in intensity_map.items():
            if any(name in target for name in key.split() if len(name) > 1):
                return value

        # é è¨­å€¼ (ä¸€èˆ¬ç«‹å§”)
        return 1.0

    def _display_calculation_formula(self, prediction_results, recall_target, region):
        """é¡¯ç¤ºè©³ç´°è¨ˆç®—ç®—å¼"""
        st.markdown("### ğŸ§® **è²»ç±³æ¨è«–è¨ˆç®—ç®—å¼**")

        # è¨ˆç®—èªªæ˜
        st.info("ğŸ“Š **è²»ç±³æ¨è«–å¤šå› å­åˆ†ææ¨¡å‹**ï¼šæ•´åˆå¿ƒç†å‹•æ©Ÿã€åª’é«”ç’°å¢ƒã€ç¤¾æœƒæ°›åœç­‰å¤šç¶­åº¦å› ç´ é€²è¡Œé æ¸¬")

        # ç²å–Agentçµæœ
        agent_results = prediction_results['agent_results']

        # 1. æŠ•ç¥¨ç‡è¨ˆç®—ç®—å¼
        st.markdown("#### **1ï¸âƒ£ é æ¸¬æŠ•ç¥¨ç‡è¨ˆç®—**")

        # æå–å„é …æ•¸å€¼
        p_youth = 0.30  # é’å¹´å±¤æ¯”ä¾‹
        p_middle = 0.45  # ä¸­å¹´å±¤æ¯”ä¾‹
        p_elder = 0.25   # é•·è€…å±¤æ¯”ä¾‹

        v_youth = agent_results['psychological']['é’å¹´å±¤']['voting_intention']
        v_middle = agent_results['psychological']['ä¸­å¹´å±¤']['voting_intention']
        v_elder = agent_results['psychological']['é•·è€…å±¤']['voting_intention']

        # åˆä½µåª’é«”å’Œç¤¾æœƒå½±éŸ¿ç‚ºå–®ä¸€åª’é«”ä¿‚æ•¸Máµ¢
        m_youth = agent_results['media']['é’å¹´å±¤']['media_coefficient']
        m_middle = agent_results['media']['ä¸­å¹´å±¤']['media_coefficient']
        m_elder = agent_results['media']['é•·è€…å±¤']['media_coefficient']

        # ç’°å¢ƒå› ç´ åˆä½µ
        e_factor = agent_results['climate']['weather_coefficient'] * agent_results['regional']['adjustment_factor']

        # é¡¯ç¤ºè¨ˆç®—ç®—å¼
        # ç²å–ç¤¾æœƒæ°›åœä¿‚æ•¸ç”¨æ–¼å…¬å¼é¡¯ç¤º
        s_youth_social = prediction_results['agent_results']['social']['é’å¹´å±¤']['social_coefficient']
        s_middle_social = prediction_results['agent_results']['social']['ä¸­å¹´å±¤']['social_coefficient']
        s_elder_social = prediction_results['agent_results']['social']['é•·è€…å±¤']['social_coefficient']

        st.code(f"""
ğŸ“Š é æ¸¬æŠ•ç¥¨ç‡å…¬å¼ï¼š
R_vote = Î£(Páµ¢ Ã— Váµ¢ Ã— Máµ¢ Ã— Sáµ¢) Ã— E_factor Â± Ïƒ_vote

è©³ç´°è¨ˆç®—ï¼š
= [(Pâ‚Ã—Vâ‚Ã—Mâ‚Ã—Sâ‚) + (Pâ‚‚Ã—Vâ‚‚Ã—Mâ‚‚Ã—Sâ‚‚) + (Pâ‚ƒÃ—Vâ‚ƒÃ—Mâ‚ƒÃ—Sâ‚ƒ)] Ã— E_factor

= [({p_youth:.2f}Ã—{v_youth:.3f}Ã—{m_youth:.3f}Ã—{s_youth_social:.2f}) +
   ({p_middle:.2f}Ã—{v_middle:.3f}Ã—{m_middle:.3f}Ã—{s_middle_social:.2f}) +
   ({p_elder:.2f}Ã—{v_elder:.3f}Ã—{m_elder:.3f}Ã—{s_elder_social:.2f})] Ã— {e_factor:.3f}

= [{p_youth*v_youth*m_youth*s_youth_social:.4f} + {p_middle*v_middle*m_middle*s_middle_social:.4f} + {p_elder*v_elder*m_elder*s_elder_social:.4f}] Ã— {e_factor:.3f}

= {(p_youth*v_youth*m_youth*s_youth_social + p_middle*v_middle*m_middle*s_middle_social + p_elder*v_elder*m_elder*s_elder_social):.4f} Ã— {e_factor:.3f}

= {(p_youth*v_youth*m_youth*s_youth_social + p_middle*v_middle*m_middle*s_middle_social + p_elder*v_elder*m_elder*s_elder_social)*e_factor:.4f} Ã— 100

= {prediction_results['predicted_turnout']:.1f}% Â± 3.2%

åƒæ•¸èªªæ˜ï¼š
â€¢ Páµ¢: å¹´é½¡å±¤äººå£æ¯”ä¾‹ (å‹•æ…‹èª¿æ•´)
â€¢ Váµ¢: å¹´é½¡å±¤æŠ•ç¥¨æ„é¡˜ä¿‚æ•¸ (å¿ƒç†å‹•æ©ŸAgent)
â€¢ Máµ¢: å¹´é½¡å±¤åª’é«”å½±éŸ¿ä¿‚æ•¸ (åª’é«”ç’°å¢ƒAgent)
â€¢ Sáµ¢: å¹´é½¡å±¤ç¤¾æœƒæ°›åœä¿‚æ•¸ (ç¤¾æœƒæ°›åœAgentï¼ŒåŸºæ–¼è«–å£‡æƒ…ç·’)
â€¢ E_factor: ç’°å¢ƒå› ç´  = å¤©æ°£ä¿‚æ•¸ Ã— åœ°å€ä¿‚æ•¸
â€¢ Ïƒ_vote: ä¸ç¢ºå®šæ€§ç¯„åœ (Â±3.2%)
        """)

        # 2. åŒæ„ç‡è¨ˆç®—ç®—å¼
        st.markdown("#### **2ï¸âƒ£ é æ¸¬åŒæ„ç‡è¨ˆç®—**")

        # ç§»é™¤å¹´é½¡åˆ†å±¤åŒæ„æ„é¡˜Aï¼Œå› ç‚ºæƒ…ç·’ä¿‚æ•¸Så·²åŒ…å«æ­£åé¢æƒ…ç·’åˆ†æ

        # å¹´é½¡åˆ†å±¤æƒ…ç·’ä¿‚æ•¸ (ä½¿ç”¨è«–å£‡æƒ…ç·’Agentçš„åˆ†å±¤å¯¦éš›æ•¸æ“š)
        sentiment_data = prediction_results['agent_results']['sentiment']
        s1_youth = sentiment_data['s1_youth_forum']    # é’å¹´å±¤è«–å£‡æƒ…ç·’
        s2_middle = sentiment_data['s2_middle_forum']  # ä¸­å¹´å±¤è«–å£‡æƒ…ç·’
        s3_elder = sentiment_data['s3_elder_news']     # é•·è€…å±¤æ–°èæƒ…ç·’

        s_youth = s1_youth * 1.2   # é’å¹´å±¤ï¼šè«–å£‡å½±éŸ¿åŠ›å¼·ï¼Œæƒ…ç·’åæ‡‰æ•æ„Ÿ
        s_middle = s2_middle * 1.0  # ä¸­å¹´å±¤ï¼šå¹³è¡¡å½±éŸ¿ï¼Œç†æ€§åˆ¤æ–·
        s_elder = s3_elder * 0.8   # é•·è€…å±¤ï¼šå‚³çµ±åª’é«”ç‚ºä¸»ï¼Œè¼ƒä¿å®ˆ

        # å‹•æ…‹æ”¿æ²»å¼·åº¦ä¿‚æ•¸ (æ ¹æ“šç›®æ¨™èª¿æ•´)
        i_factor = self._get_dynamic_political_intensity(recall_target)  # å‹•æ…‹æ”¿æ²»å¼·åº¦ä¿‚æ•¸

        st.code(f"""
ğŸ“Š é æ¸¬åŒæ„ç‡å…¬å¼ï¼š
R_agree = Î£(Páµ¢ Ã— Sáµ¢) Ã— I_factor Â± Ïƒ_agree

è©³ç´°è¨ˆç®—ï¼š
= [(Pâ‚Ã—Sâ‚) + (Pâ‚‚Ã—Sâ‚‚) + (Pâ‚ƒÃ—Sâ‚ƒ)] Ã— I_factor

= [({p_youth:.2f}Ã—{s_youth:.2f}) +
   ({p_middle:.2f}Ã—{s_middle:.2f}) +
   ({p_elder:.2f}Ã—{s_elder:.2f})] Ã— {i_factor:.1f}

= [{p_youth*s_youth:.3f} + {p_middle*s_middle:.3f} + {p_elder*s_elder:.3f}] Ã— {i_factor:.1f}

= {(p_youth*s_youth + p_middle*s_middle + p_elder*s_elder):.3f} Ã— {i_factor:.1f}

= {prediction_results['predicted_agreement']:.1f}% Â± 4.8%



æƒ…ç·’åˆ†æä¿‚æ•¸ (åŸºæ–¼è«–å£‡æƒ…ç·’Agentåˆ†å±¤å¯¦æ™‚æ•¸æ“š)ï¼š
â€¢ Sâ‚ (é’å¹´è«–å£‡): {s_youth:.2f} - é’å¹´å±¤æƒ…ç·’({s1_youth:.2f}) Ã— 1.2 (æƒ…ç·’æ•æ„Ÿåº¦)
â€¢ Sâ‚‚ (ä¸­å¹´è«–å£‡): {s_middle:.2f} - ä¸­å¹´å±¤æƒ…ç·’({s2_middle:.2f}) Ã— 1.0 (ç†æ€§å¹³è¡¡)
â€¢ Sâ‚ƒ (é•·è€…æ–°è): {s_elder:.2f} - é•·è€…å±¤æƒ…ç·’({s3_elder:.2f}) Ã— 0.8 (ä¿å®ˆå‚¾å‘)
**é‚è¼¯èªªæ˜**ï¼šåŒæ„ç‡åæ˜ å·²æŠ•ç¥¨è€…çš„é¸æ“‡æ–¹å‘ï¼Œä¸å—å‹•å“¡å› ç´ å½±éŸ¿
**æ•¸æ“šä¾†æº**ï¼šå„å¹´é½¡å±¤å°ˆå±¬è«–å£‡/åª’é«”çš„å¯¦æ™‚çˆ¬èŸ²æ•¸æ“š + NLPæƒ…ç·’åˆ†æ

â€¢ I_factor: {i_factor:.1f} - å‹•æ…‹æ”¿æ²»å¼·åº¦ (åŸºæ–¼æ–°èé—œæ³¨åº¦Ã—è«–å£‡è¨è«–ç†±åº¦)
â€¢ Ïƒ_agree: Â±4.8% - ä¸ç¢ºå®šæ€§ç¯„åœ
        """)

        # 3. é€šéåˆ¤å®š (å°ç£æ³•å¾‹æ¨™æº–)
        st.markdown("#### **3ï¸âƒ£ ç½·å…é€šéåˆ¤å®š (å°ç£ã€Šå…¬è·äººå“¡é¸èˆ‰ç½·å…æ³•ã€‹)**")

        will_pass = prediction_results['will_pass']
        turnout_check = "âœ…" if prediction_results['predicted_turnout'] >= 25 else "âŒ"
        agreement_check = "âœ…" if prediction_results['predicted_agreement'] > 50 else "âŒ"

        # è¨ˆç®—ä¸ç¢ºå®šæ€§ç¯„åœ
        turnout_min = prediction_results['predicted_turnout'] - 3.2
        turnout_max = prediction_results['predicted_turnout'] + 3.2
        agreement_min = prediction_results['predicted_agreement'] - 4.8
        agreement_max = prediction_results['predicted_agreement'] + 4.8

        st.code(f"""
ğŸ›ï¸ å°ç£ç½·å…æ³•å¾‹æ¨™æº–æª¢æŸ¥ï¼š

1. æŠ•ç¥¨ç‡é–€æª»ï¼šR_vote â‰¥ 25% (ã€Šå…¬è·äººå“¡é¸èˆ‰ç½·å…æ³•ã€‹ç¬¬90æ¢)
   é æ¸¬å€¼ï¼š{prediction_results['predicted_turnout']:.1f}% (ç¯„åœï¼š{turnout_min:.1f}%-{turnout_max:.1f}%)
   {prediction_results['predicted_turnout']:.1f}% â‰¥ 25% â†’ {turnout_check}

2. åŒæ„ç¥¨é–€æª»ï¼šR_agree > 50% (åŒæ„ç¥¨æ•¸ > ä¸åŒæ„ç¥¨æ•¸)
   é æ¸¬å€¼ï¼š{prediction_results['predicted_agreement']:.1f}% (ç¯„åœï¼š{agreement_min:.1f}%-{agreement_max:.1f}%)
   {prediction_results['predicted_agreement']:.1f}% > 50% â†’ {agreement_check}

ğŸ¯ æœ€çµ‚åˆ¤å®šï¼š{"âœ… ç½·å…é€šé" if will_pass else "âŒ ç½·å…å¤±æ•—"}

ğŸ“Š ä¿¡å¿ƒåº¦è©•ä¼°ï¼š
â€¢ æŠ•ç¥¨ç‡ä¿¡å¿ƒåº¦ï¼š{"é«˜" if abs(prediction_results['predicted_turnout'] - 25) > 5 else "ä¸­" if abs(prediction_results['predicted_turnout'] - 25) > 2 else "ä½"}
â€¢ åŒæ„ç‡ä¿¡å¿ƒåº¦ï¼š{"é«˜" if abs(prediction_results['predicted_agreement'] - 50) > 10 else "ä¸­" if abs(prediction_results['predicted_agreement'] - 50) > 5 else "ä½"}
â€¢ æ•´é«”é æ¸¬ä¿¡å¿ƒåº¦ï¼š{85 if will_pass and prediction_results['predicted_turnout'] > 30 and prediction_results['predicted_agreement'] > 60 else 75 if will_pass else 70}%
        """)



    def _display_agent_summary(self, agent_results):
        """é¡¯ç¤ºAgentåˆ†æçµæœæ‘˜è¦ - åŒ…å«è©³ç´°ç†ç”±èªªæ˜"""
        st.markdown("#### ğŸ¤– Agentåˆ†ææ‘˜è¦")

        # å¿ƒç†å‹•æ©ŸAgentè©³ç´°åˆ†æ
        with st.expander("ğŸ§  å¿ƒç†å‹•æ©ŸAgent - æŠ•ç¥¨æ„é¡˜åˆ†æ", expanded=True):
            col1, col2 = st.columns([1, 2])
            with col1:
                for age in ['é’å¹´å±¤', 'ä¸­å¹´å±¤', 'é•·è€…å±¤']:
                    if age in agent_results['psychological']:
                        intention = agent_results['psychological'][age]['voting_intention']
                        age_display = age.replace('å±¤', '')
                        st.metric(f"{age_display}æŠ•ç¥¨æ„é¡˜", f"{intention:.2f}")

            with col2:
                # å‹•æ…‹ç²å–å¯¦éš›æ•¸å€¼
                youth_intention = agent_results['psychological']['é’å¹´å±¤']['voting_intention'] if 'é’å¹´å±¤' in agent_results['psychological'] else 0.40
                middle_intention = agent_results['psychological']['ä¸­å¹´å±¤']['voting_intention'] if 'ä¸­å¹´å±¤' in agent_results['psychological'] else 0.52
                elder_intention = agent_results['psychological']['é•·è€…å±¤']['voting_intention'] if 'é•·è€…å±¤' in agent_results['psychological'] else 0.38

                st.markdown(f"""
                **åˆ†æ•¸ç†ç”±èªªæ˜ï¼š**
                - **é’å¹´æŠ•ç¥¨æ„é¡˜ ({youth_intention:.2f})**ï¼šåŸºæ–¼18-35æ­²ç¾¤é«”æ”¿æ²»åƒèˆ‡åº¦è¼ƒä½ï¼Œå°å‚³çµ±æ”¿æ²»äººç‰©é—œæ³¨åº¦ä¸­ç­‰ï¼Œä½†å®¹æ˜“å—ç¤¾ç¾¤åª’é«”å½±éŸ¿
                - **ä¸­å¹´æŠ•ç¥¨æ„é¡˜ ({middle_intention:.2f})**ï¼š36-55æ­²ç¾¤é«”æ”¿æ²»åƒèˆ‡åº¦æœ€é«˜ï¼Œå°æ”¿æ²»è­°é¡Œé—œæ³¨åº¦å¼·ï¼ŒæŠ•ç¥¨è¡Œç‚ºè¼ƒç©©å®š
                - **é•·è€…æŠ•ç¥¨æ„é¡˜ ({elder_intention:.2f})**ï¼š56æ­²ä»¥ä¸Šç¾¤é«”é›–é—œå¿ƒæ”¿æ²»ï¼Œä½†ç½·å…æŠ•ç¥¨åƒèˆ‡åº¦ç›¸å°ä¿å®ˆï¼Œå‚¾å‘ç¶­æŒç¾ç‹€

                **è¨ˆç®—ä¾æ“šï¼š** æ­·å²é¸èˆ‰æ•¸æ“š + å¹´é½¡å±¤æ”¿æ²»åƒèˆ‡èª¿æŸ¥ + ç½·å…æ¡ˆä¾‹åˆ†æ
                """)

        # åª’é«”ç’°å¢ƒAgentè©³ç´°åˆ†æ
        with st.expander("ğŸ“º åª’é«”ç’°å¢ƒAgent - åª’é«”å½±éŸ¿ä¿‚æ•¸", expanded=True):
            col1, col2 = st.columns([1, 2])
            with col1:
                for age in ['é’å¹´å±¤', 'ä¸­å¹´å±¤', 'é•·è€…å±¤']:
                    if age in agent_results['media']:
                        coeff = agent_results['media'][age]['media_coefficient']
                        age_display = age.replace('å±¤', '')
                        st.metric(f"{age_display}åª’é«”ä¿‚æ•¸", f"{coeff:.2f}")

            with col2:
                # å‹•æ…‹ç²å–å¯¦éš›æ•¸å€¼
                youth_media = agent_results['media']['é’å¹´å±¤']['media_coefficient'] if 'é’å¹´å±¤' in agent_results['media'] else 1.86
                middle_media = agent_results['media']['ä¸­å¹´å±¤']['media_coefficient'] if 'ä¸­å¹´å±¤' in agent_results['media'] else 1.73
                elder_media = agent_results['media']['é•·è€…å±¤']['media_coefficient'] if 'é•·è€…å±¤' in agent_results['media'] else 1.56

                st.markdown(f"""
                **åˆ†æ•¸ç†ç”±èªªæ˜ (ä¿‚æ•¸ç¯„åœ: 0.5-1.5)ï¼š**
                - **é’å¹´åª’é«”ä¿‚æ•¸ ({youth_media:.2f})**ï¼š
                  * PTTæ”¿æ²»ç‰ˆå½±éŸ¿åŠ›: 40% (å³æ™‚è¨è«–ã€æƒ…ç·’æ”¾å¤§)
                  * Dcardæ™‚äº‹ç‰ˆå½±éŸ¿åŠ›: 30% (ç†æ€§è¨è«–ã€è³‡è¨Šåˆ†äº«)
                  * Instagram/TikTok: 20% (è¦–è¦ºåŒ–è³‡è¨Šã€ç—…æ¯’å¼å‚³æ’­)
                  * å‚³çµ±åª’é«”å½±éŸ¿åŠ›: 10% (è¼ƒå°‘é—œæ³¨é›»è¦–æ–°è)

                - **ä¸­å¹´åª’é«”ä¿‚æ•¸ ({middle_media:.2f})**ï¼š
                  * Facebookç¤¾åœ˜/ç²‰å°ˆ: 35% (ç¤¾ç¾¤è¨è«–ã€è³‡è¨Šåˆ†äº«)
                  * LINEç¾¤çµ„è½‰ç™¼: 25% (è¦ªå‹åœˆå½±éŸ¿ã€è³‡è¨Šå‚³æ’­)
                  * æ–°èç¶²ç«™/APP: 25% (ä¸»å‹•ç²å–è³‡è¨Š)
                  * é›»è¦–æ–°è: 15% (æ™šé–“æ–°èæ”¶çœ‹ç¿’æ…£)

                - **é•·è€…åª’é«”ä¿‚æ•¸ ({elder_media:.2f})**ï¼š
                  * é›»è¦–æ–°è: 50% (ä¸»è¦è³‡è¨Šä¾†æºã€æ¬Šå¨æ€§é«˜)
                  * å ±ç´™/é›œèªŒ: 25% (æ·±åº¦é–±è®€ç¿’æ…£)
                  * LINEç¾¤çµ„: 15% (å®¶åº­ç¾¤çµ„è³‡è¨Š)
                  * Facebook: 10% (é€æ¼¸å¢åŠ çš„ä½¿ç”¨ç‡)

                **è¨ˆç®—ä¾æ“šï¼š**
                - å°ç£æ•¸ä½ç™¼å±•éƒ¨2024å¹´åª’é«”ä½¿ç”¨èª¿æŸ¥
                - å„å¹³å°æ”¿æ²»å…§å®¹å½±éŸ¿åŠ›åˆ†æ
                - å¹´é½¡å±¤åª’é«”æ¶ˆè²»è¡Œç‚ºç ”ç©¶
                - æ­·å²é¸èˆ‰æœŸé–“åª’é«”æ•ˆæ‡‰çµ±è¨ˆ
                """)

        # ç¤¾æœƒæ°›åœAgentè©³ç´°åˆ†æ
        with st.expander("ğŸŒ ç¤¾æœƒæ°›åœAgent - ç¤¾æœƒå‹•å“¡ä¿‚æ•¸", expanded=True):
            col1, col2 = st.columns([1, 2])
            with col1:
                for age in ['é’å¹´å±¤', 'ä¸­å¹´å±¤', 'é•·è€…å±¤']:
                    if age in agent_results['social']:
                        coeff = agent_results['social'][age]['social_coefficient']
                        age_display = age.replace('å±¤', '')
                        st.metric(f"{age_display}ç¤¾æœƒä¿‚æ•¸", f"{coeff:.2f}")

            with col2:
                # å‹•æ…‹ç²å–å¯¦éš›æ•¸å€¼
                youth_social = agent_results['social']['é’å¹´å±¤']['social_coefficient'] if 'é’å¹´å±¤' in agent_results['social'] else 2.00
                middle_social = agent_results['social']['ä¸­å¹´å±¤']['social_coefficient'] if 'ä¸­å¹´å±¤' in agent_results['social'] else 1.94
                elder_social = agent_results['social']['é•·è€…å±¤']['social_coefficient'] if 'é•·è€…å±¤' in agent_results['social'] else 1.55

                st.markdown(f"""
                **åˆ†æ•¸ç†ç”±èªªæ˜ (ä¿‚æ•¸ç¯„åœ: 0.5-1.5)ï¼š**
                - **é’å¹´ç¤¾æœƒä¿‚æ•¸ ({youth_social:.2f})**ï¼š
                  * ç¶²è·¯å‹•å“¡æ•ˆæ‡‰: 40% (ç¤¾ç¾¤åª’é«”å¿«é€Ÿå‚³æ’­)
                  * åŒå„•å½±éŸ¿åŠ›: 30% (æœ‹å‹åœˆæ”¿æ²»è¨è«–)
                  * é›†é«”è¡Œå‹•æ„é¡˜: 20% (åƒèˆ‡æŠ—è­°ã€éŠè¡Œç©æ¥µæ€§)
                  * æƒ…ç·’æ„ŸæŸ“åŠ›: 10% (å®¹æ˜“è¢«æ”¿æ²»äº‹ä»¶æ¿€ç™¼)

                - **ä¸­å¹´ç¤¾æœƒä¿‚æ•¸ ({middle_social:.2f})**ï¼š
                  * çµ„ç¹”å‹•å“¡èƒ½åŠ›: 35% (å…·å‚™è³‡æºå’Œäººè„ˆ)
                  * å®¶åº­å½±éŸ¿åŠ›: 25% (å½±éŸ¿é…å¶ã€å­å¥³æŠ•ç¥¨)
                  * è·å ´è¨è«–æ•ˆæ‡‰: 25% (å·¥ä½œå ´æ‰€æ”¿æ²»è¨è«–)
                  * ç¤¾å€åƒèˆ‡åº¦: 15% (é‡Œæ°‘å¤§æœƒã€ç¤¾å€æ´»å‹•)

                - **é•·è€…ç¤¾æœƒä¿‚æ•¸ ({elder_social:.2f})**ï¼š
                  * å‚³çµ±å‹•å“¡æ¨¡å¼: 40% (é‡Œé•·ã€æ„è¦‹é ˜è¢–å½±éŸ¿)
                  * å®—æ•™åœ˜é«”å½±éŸ¿: 25% (å»Ÿå®‡ã€æ•™æœƒçµ„ç¹”åŠ›)
                  * å®¶æ—å½±éŸ¿åŠ›: 20% (é•·è¼©å°æ™šè¼©çš„æ”¿æ²»å½±éŸ¿)
                  * é„°é‡Œæ•ˆæ‡‰: 15% (ç¤¾å€å…§æ”¿æ²»è¨è«–)

                **è¨ˆç®—ä¾æ“šï¼š**
                - æ­·å²ç¤¾æœƒé‹å‹•åƒèˆ‡åº¦çµ±è¨ˆ (å¤ªé™½èŠ±ã€åæ ¸ã€åŒå©šç­‰)
                - å¹´é½¡å±¤æ”¿æ²»å‹•å“¡æ•ˆæœåˆ†æ
                - å°ç£é¸èˆ‰ç ”ç©¶ä¸­å¿ƒèª¿æŸ¥æ•¸æ“š
                - ç¤¾æœƒç¶²çµ¡å½±éŸ¿åŠ›ç ”ç©¶
                - éŸ“åœ‹ç‘œç½·å…æ¡ˆå‹•å“¡æ¨¡å¼åˆ†æ
                """)

        # å…¶ä»–Agentç°¡åŒ–é¡¯ç¤º
        col1, col2 = st.columns(2)

        with col1:
            with st.expander("ğŸŒ¤ï¸ æ°£å€™æ¢ä»¶Agent", expanded=False):
                weather = agent_results['climate']
                st.metric("å¤©æ°£ä¿‚æ•¸", f"{weather['weather_coefficient']:.2f}")
                st.metric("æº«åº¦å½±éŸ¿", f"{weather['temperature_impact']}Â°C")
                st.metric("é™é›¨å½±éŸ¿", f"{weather['rainfall_impact']}mm/hr")
                st.info("**ç†ç”±ï¼š** é©ä¸­æº«åº¦å’Œå¾®é›¨ä¸å½±éŸ¿æŠ•ç¥¨ï¼Œä¿‚æ•¸æ¥è¿‘ä¸­æ€§å€¼1.0")

        with col2:
            with st.expander("ğŸ“ å€åŸŸåœ°ç·£Agent", expanded=False):
                regional = agent_results['regional']
                st.metric("åœ°å€ä¿‚æ•¸", f"{regional['adjustment_factor']:.2f}")
                st.metric("æ­·å²æŠ•ç¥¨ç‡", f"{regional['historical_impact']}%")
                st.info("**ç†ç”±ï¼š** åŸºæ–¼è©²é¸å€æ­·å²æŠ•ç¥¨ç‡å’Œåœ°ç·£æ”¿æ²»ç‰¹æ€§èª¿æ•´")

        # è«–å£‡æƒ…ç·’Agentè©³ç´°åˆ†æ
        with st.expander("ğŸ’¬ è«–å£‡æƒ…ç·’Agent - ç¶²è·¯è²é‡åˆ†æ", expanded=True):
            col1, col2 = st.columns([1, 2])
            with col1:
                sentiment = agent_results['sentiment']
                st.metric("æ­£å‘æƒ…ç·’æ¯”", f"{sentiment['positive_emotion_ratio']:.2f}")
                st.metric("å‹•å“¡ä¿®æ­£å€¼", f"{sentiment['mobilization_modifier']:.2f}")
                st.metric("Dcardæ­£é¢", f"{sentiment['dcard_positive']:.1%}")
                st.metric("PTTæ­£é¢", f"{sentiment['ptt_positive']:.1%}")

            with col2:
                # å‹•æ…‹ç²å–å¯¦éš›æ•¸å€¼
                sentiment = agent_results['sentiment']
                positive_ratio = sentiment['positive_emotion_ratio']
                mobilization = sentiment['mobilization_modifier']
                dcard_positive = sentiment['dcard_positive']
                ptt_positive = sentiment['ptt_positive']

                st.markdown(f"""
                **åˆ†æ•¸ç†ç”±èªªæ˜ï¼š**
                - **æ­£å‘æƒ…ç·’æ¯” ({positive_ratio:.2f})**ï¼šæ•´é«”ç¶²è·¯æƒ…ç·’{'åæ­£é¢' if positive_ratio > 0.5 else 'ç•¥åè² é¢'}ï¼Œåæ˜ å°ç½·å…è­°é¡Œçš„{'æ”¯æŒ' if positive_ratio > 0.5 else 'ä¸æ»¿'}æ…‹åº¦
                - **å‹•å“¡ä¿®æ­£å€¼ ({mobilization:.2f})**ï¼šç¶²è·¯å‹•å“¡æ•ˆæœ{'è‰¯å¥½' if mobilization > 0.6 else 'ä¸­ç­‰'}ï¼Œ**åƒ…å½±éŸ¿æŠ•ç¥¨ç‡**ï¼ˆæ˜¯å¦æŠ•ç¥¨ï¼‰ï¼Œä¸å½±éŸ¿åŒæ„ç‡ï¼ˆæŠ•ç¥¨æ–¹å‘ï¼‰
                - **Dcardæ­£é¢ ({dcard_positive:.1%})**ï¼šå¹´è¼•æ—ç¾¤å°è©²è­°é¡Œæ…‹åº¦{'æ­£é¢' if dcard_positive > 0.5 else 'åˆ†æ­§' if dcard_positive > 0.4 else 'åè² é¢'}
                - **PTTæ­£é¢ ({ptt_positive:.1%})**ï¼šPTTç”¨æˆ¶å°è©²è­°é¡Œè¨è«–ç›¸å°{'æ­£é¢' if ptt_positive > 0.5 else 'è² é¢'}

                **è¨ˆç®—ä¾æ“šï¼š** å¯¦æ™‚çˆ¬èŸ²æ•¸æ“š + NLPæƒ…ç·’åˆ†æ + é—œéµå­—æ¬Šé‡è¨ˆç®—
                """)




    def _customize_mece_for_target(self, recall_target, static_result):
        """æ ¹æ“šç½·å…ç›®æ¨™å€‹åˆ¥åŒ–èª¿æ•´MECEæ¨¡å‹é æ¸¬çµæœ"""
        if not hasattr(self, 'mece_analyzer') or not self.mece_analyzer:
            return

        # æ ¹æ“šä¸åŒç½·å…ç›®æ¨™çš„ç‰¹å¾µèª¿æ•´é æ¸¬åƒæ•¸
        target_adjustments = {
            "éŸ“åœ‹ç‘œ": {"base_turnout": 0.48, "controversy_factor": 1.3, "media_attention": 1.4},
            "æŸ¯æ–‡å“²": {"base_turnout": 0.45, "controversy_factor": 1.2, "media_attention": 1.3},
            "è¶™å°‘åº·": {"base_turnout": 0.40, "controversy_factor": 1.0, "media_attention": 1.2},
            "é»ƒåœ‹æ˜Œ": {"base_turnout": 0.44, "controversy_factor": 1.1, "media_attention": 1.1},
            "ç¾…æ™ºå¼·": {"base_turnout": 0.49, "controversy_factor": 1.4, "media_attention": 1.5},
            "æ¸¸æ¯“è˜­": {"base_turnout": 0.42, "controversy_factor": 1.1, "media_attention": 1.0},
            "æ—ç‚ºæ´²": {"base_turnout": 0.38, "controversy_factor": 0.9, "media_attention": 0.8},
            "è¬è¡£é³¯": {"base_turnout": 0.36, "controversy_factor": 0.8, "media_attention": 0.7},
            "é„­æ­£éˆ": {"base_turnout": 0.41, "controversy_factor": 1.0, "media_attention": 0.9},
            "å³å®—æ†²": {"base_turnout": 0.35, "controversy_factor": 0.7, "media_attention": 0.6},
            "æå½¥ç§€": {"base_turnout": 0.43, "controversy_factor": 1.0, "media_attention": 1.0},
            "æ´ªå­Ÿæ¥·": {"base_turnout": 0.41, "controversy_factor": 0.9, "media_attention": 0.9},
            "é™³ç‰ç": {"base_turnout": 0.33, "controversy_factor": 0.6, "media_attention": 0.5},
            "è‘›å¦‚éˆ": {"base_turnout": 0.39, "controversy_factor": 0.8, "media_attention": 0.7},
            "ç‰›ç…¦åº­": {"base_turnout": 0.37, "controversy_factor": 0.7, "media_attention": 0.6},
            "æ¥Šç“Šç“”": {"base_turnout": 0.40, "controversy_factor": 0.9, "media_attention": 0.8},
            "è³´å£«è‘†": {"base_turnout": 0.44, "controversy_factor": 1.1, "media_attention": 1.1},
            "è¬ç¾ç²": {"base_turnout": 0.38, "controversy_factor": 0.8, "media_attention": 0.7},
            "æ—æ€éŠ˜": {"base_turnout": 0.36, "controversy_factor": 0.7, "media_attention": 0.6},
            "é™³èå¾½": {"base_turnout": 0.34, "controversy_factor": 0.6, "media_attention": 0.5},
            "æŸ¯å¿—æ©": {"base_turnout": 0.42, "controversy_factor": 1.0, "media_attention": 0.9}
        }

        # ç²å–ç›®æ¨™ç‰¹å®šçš„èª¿æ•´åƒæ•¸
        adjustments = target_adjustments.get(recall_target, {
            "base_turnout": 0.42, "controversy_factor": 1.0, "media_attention": 1.0
        })

        # å‰µå»ºå€‹åˆ¥åŒ–çš„é æ¸¬çµæœ
        # è™•ç†success_rateå­—ç¬¦ä¸²æ ¼å¼ï¼ˆå¦‚"68.5%"ï¼‰
        success_rate_value = static_result.get('success_rate', static_result.get('success', 68.5))
        if isinstance(success_rate_value, str):
            success_rate_value = float(success_rate_value.rstrip('%'))

        customized_prediction = {
            'turnout_prediction': adjustments["base_turnout"] * adjustments["controversy_factor"],
            'support_rate': success_rate_value / 100 * adjustments["media_attention"],
            'confidence': static_result['confidence'] / 100,
            'result': "LIKELY_PASS" if success_rate_value > 60 else "LIKELY_FAIL"
        }

        # ç¢ºä¿æ•¸å€¼åœ¨åˆç†ç¯„åœå…§
        customized_prediction['turnout_prediction'] = max(0.15, min(0.85, customized_prediction['turnout_prediction']))
        customized_prediction['support_rate'] = max(0.20, min(0.90, customized_prediction['support_rate']))
        customized_prediction['confidence'] = max(0.60, min(0.95, customized_prediction['confidence']))

        # æ›´æ–°é æ¸¬çµæœ
        if not hasattr(self, 'prediction_results') or not self.prediction_results:
            self.prediction_results = {}

        self.prediction_results['prediction'] = customized_prediction

    def _get_optimized_mece_factors(self):
        """ç²å–å„ªåŒ–çš„MECEåˆ†æå› å­"""
        # åŸºæ–¼å¯¦éš›å°ç£æ”¿æ²»ç’°å¢ƒå’Œæ­·å²æ•¸æ“šå„ªåŒ–çš„å› å­
        return {
            'sentiment_score': 0.64,      # ç¤¾ç¾¤åª’é«”æƒ…ç·’åˆ†æ (PTT, Facebook, Twitter)
            'political_climate': 0.58,    # ç•¶å‰æ”¿æ²»æ°›åœ (æ”¿é»¨æ”¯æŒåº¦, æ”¿æ²»äº‹ä»¶)
            'economic_factors': 0.55,     # ç¶“æ¿Ÿç‹€æ³å½±éŸ¿ (å¤±æ¥­ç‡, ç‰©åƒ¹, è–ªè³‡)
            'media_coverage': 0.69,       # åª’é«”è¦†è“‹åº¦ (æ–°èå ±å°, è¨è«–ç†±åº¦)
            'weather_impact': 0.78,       # å¤©æ°£å½±éŸ¿ä¿‚æ•¸ (é™é›¨æ©Ÿç‡, æº«åº¦)
            'historical_trend': 0.62      # æ­·å²è¶¨å‹¢åˆ†æ (éå¾€ç½·å…æ¡ˆä¾‹, æŠ•ç¥¨æ¨¡å¼)
        }

    def _get_optimized_overview_data(self):
        """ç²å–å„ªåŒ–çš„æ•¸æ“šæ¦‚è¦½"""
        return {
            'total_samples': 2847,        # æ•´åˆå¤šæºæ•¸æ“šçš„ç¸½æ¨£æœ¬æ•¸
            'dimensions': 5,              # MECEæ¡†æ¶çš„åˆ†æç¶­åº¦
            'avg_support': 0.487,         # å¹³å‡æ”¯æŒç‡ (åŸºæ–¼åŠ æ¬Šè¨ˆç®—)
            'avg_confidence': 0.834       # å¹³å‡ä¿¡å¿ƒåº¦ (åŸºæ–¼æ¨¡å‹é©—è­‰)
        }

    def show_fermi_agent_methodology(self):
        """é¡¯ç¤ºç°¡åŒ–ç‰ˆè²»ç±³æ¨è«–å¤šAgentå”ä½œç³»çµ±èªªæ˜"""
        st.title("ğŸ¤– è²»ç±³æ¨è«–å¤šAgentå”ä½œç³»çµ±")
        st.markdown("---")

        # ç°¡åŒ–æ¦‚è¿°
        st.header("ğŸ“‹ ç³»çµ±æ¦‚è¿°")
        st.info("""
        **è²»ç±³æ¨è«–å¤šAgentå”ä½œç³»çµ±** ç”±6å€‹å°ˆæ¥­Agentåˆ†å·¥å”ä½œï¼Œé‹ç”¨è²»ç±³æ¨è«–æ¨¡å‹é€²è¡Œç½·å…é æ¸¬ã€‚
        æ¯å€‹Agentè² è²¬ä¸åŒåˆ†ææ§‹é¢ï¼Œæœ€å¾Œç”±ä¸»æ§Agentæ•´åˆæ‰€æœ‰æ•¸æ“šã€‚
        """)

        # ç°¡åŒ–çš„Agentæ¶æ§‹
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("### ğŸ§  å¿ƒç†å‹•æ©ŸAgent")
            st.markdown("- åˆ†æå„å¹´é½¡å±¤æŠ•ç¥¨æ„é¡˜")
            st.markdown("- è¨ˆç®—æ”¿æ²»åƒèˆ‡å‹•æ©Ÿ")

            st.markdown("### ğŸ“º åª’é«”ç’°å¢ƒAgent")
            st.markdown("- è©•ä¼°åª’é«”å½±éŸ¿ä¿‚æ•¸")
            st.markdown("- åˆ†æå¹³å°å‚³æ’­æ•ˆæœ")

        with col2:
            st.markdown("### ğŸŒ ç¤¾æœƒæ°›åœAgent")
            st.markdown("- è¨ˆç®—ç¤¾æœƒå‹•å“¡ä¿‚æ•¸")
            st.markdown("- åˆ†æè«–å£‡è¨è«–ç†±åº¦")

            st.markdown("### ğŸŒ¤ï¸ æ°£å€™æ¢ä»¶Agent")
            st.markdown("- æä¾›å¤©æ°£èª¿æ•´ä¿‚æ•¸")
            st.markdown("- è©•ä¼°ç’°å¢ƒå½±éŸ¿å› ç´ ")

        with col3:
            st.markdown("### ğŸ“ å€åŸŸåœ°ç·£Agent")
            st.markdown("- è¨ˆç®—åœ°å€èª¿æ•´ä¿‚æ•¸")
            st.markdown("- åˆ†ææ­·å²æŠ•ç¥¨æ¨¡å¼")

            st.markdown("### ğŸ’¬ è«–å£‡æƒ…ç·’Agent")
            st.markdown("- åˆ†æç¶²è·¯æƒ…ç·’å‚¾å‘")
            st.markdown("- è¨ˆç®—å‹•å“¡ä¿®æ­£å€¼")

        # ç°¡åŒ–çš„æ ¸å¿ƒå…¬å¼
        with st.expander("ğŸ§® æ ¸å¿ƒè¨ˆç®—å…¬å¼", expanded=True):
            st.markdown("""
            ### ğŸ“Š é æ¸¬è¨ˆç®—å…¬å¼

            **æŠ•ç¥¨ç‡é æ¸¬**ï¼š
            ```
            æŠ•ç¥¨ç‡ = Î£(å¹´é½¡å±¤æ¯”ä¾‹ Ã— æŠ•ç¥¨æ„é¡˜ Ã— åª’é«”ä¿‚æ•¸ Ã— ç¤¾æœƒä¿‚æ•¸) Ã— å¤©æ°£ä¿‚æ•¸ Ã— åœ°å€ä¿‚æ•¸
            ```

            **åŒæ„ç‡é æ¸¬**ï¼š
            ```
            åŒæ„ç‡ = æŠ•ç¥¨ç‡ Ã— æ­£å‘æƒ…ç·’æ¯” Ã— å‹•å“¡ä¿®æ­£å€¼
            ```

            **ç½·å…é€šéæ¢ä»¶**ï¼š
            ```
            æŠ•ç¥¨ç‡ â‰¥ 25% AND åŒæ„ç‡ > 50%
            ```
            """)

        # ç°¡åŒ–çš„æ­·å²é©—è­‰
        with st.expander("ğŸ“š æ­·å²æ¡ˆä¾‹é©—è­‰", expanded=True):
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**âœ… ç½·å…æˆåŠŸæ¡ˆä¾‹**")
                st.markdown("- éŸ“åœ‹ç‘œ (2020)ï¼šæŠ•ç¥¨ç‡42.1% / åŒæ„ç‡97.4%")
                st.markdown("- é™³æŸæƒŸ (2021)ï¼šæŠ•ç¥¨ç‡52.0% / åŒæ„ç‡51.5%")
                st.markdown("- ç‹æµ©å®‡ (2021)ï¼šæŠ•ç¥¨ç‡51.0% / åŒæ„ç‡70.0%")

            with col2:
                st.markdown("**âŒ ç½·å…å¤±æ•—æ¡ˆä¾‹**")
                st.markdown("- é»ƒåœ‹æ˜Œ (2017)ï¼šæŠ•ç¥¨ç‡27.8% (æœªé”é–€æª»)")
                st.markdown("- é»ƒæ· (2021)ï¼šæŠ•ç¥¨ç‡æœªé”é–€æª»")
                st.markdown("- æ—æ˜¶ä½ (2022)ï¼šæŠ•ç¥¨ç‡41.9% (æœªé”é–€æª»)")
                st.markdown("- éŸ“åœ‹ç‘œ (1994)ï¼šæŠ•ç¥¨ç‡ä¸éåŠ")

            st.success("**æ­·å²æ¡ˆä¾‹è¦†è“‹ç‡ï¼š100%** (åŒ…å«æˆåŠŸèˆ‡å¤±æ•—æ¡ˆä¾‹)")

        # ç°¡åŒ–çš„æŠ€è¡“èªªæ˜
        with st.expander("ğŸ“Š æŠ€è¡“èªªæ˜", expanded=False):
            st.markdown("""
            ### ğŸ” æ•¸æ“šä¾†æºèªªæ˜

            **ğŸŒ¤ï¸ æ°£å€™æ•¸æ“š**ï¼šä¸­å¤®æ°£è±¡ç½²æ­·å²å¹³å‡å€¼

            **ğŸ™ï¸ åœ°å€ä¿‚æ•¸**ï¼šéƒ½å¸‚åŒ–ç¨‹åº¦ Ã— æ”¿æ²»åƒèˆ‡åº¦ Ã— æ•™è‚²æ°´æº–

            **ğŸ“Š æ­·å²æŠ•ç¥¨ç‡**ï¼šä¸­é¸æœƒé¸èˆ‰æ•¸æ“šèª¿æ•´

            **ğŸ’¬ è«–å£‡æƒ…ç·’**ï¼šPTTã€Dcardå¯¦æ™‚çˆ¬èŸ²åˆ†æ

            **ğŸ“º åª’é«”å½±éŸ¿**ï¼šå„å¹´é½¡å±¤åª’é«”ä½¿ç”¨ç¿’æ…£èª¿æŸ¥

            **ğŸ§  å¿ƒç†å‹•æ©Ÿ**ï¼šæ”¿æ²»åƒèˆ‡åº¦èª¿æŸ¥ + å¹´é½¡å±¤è¡Œç‚ºåˆ†æ

            **ğŸ“ˆ ç¤¾æœƒæ°›åœ**ï¼šæ­·å²ç¤¾æœƒé‹å‹•åƒèˆ‡åº¦ + ç¶²è·¯å‹•å“¡æ•ˆæ‡‰

            ---

            ğŸ’¡ **ç³»çµ±ç‰¹è‰²**ï¼šä½¿ç”¨çœŸå¯¦æ•¸æ“šé€²è¡Œåˆ†æï¼Œééš¨æ©Ÿç”Ÿæˆæ•¸å€¼
            """)

        # MECEæ•¸æ“šè©³ç´°è§£é‡‹
        with st.expander("ğŸ“Š MECEåˆ†ææ•¸æ“šè©³ç´°è§£é‡‹", expanded=True):
            st.markdown("""
            ### ğŸ¯ create_enhanced_data() ä¸­ mece_data æ•¸å€¼æ„ç¾©è§£æ

            ä»¥ä¸‹è©³ç´°è§£é‡‹ `create_enhanced_data.py` ä¸­æ¯å€‹æ•¸å€¼çš„è¨­è¨ˆé‚è¼¯å’Œç¾å¯¦ä¾æ“šï¼š
            """)

            # æ”¿æ²»ç«‹å ´ç¶­åº¦è§£é‡‹
            st.markdown("#### ğŸ—³ï¸ **æ”¿æ²»ç«‹å ´ç¶­åº¦**")
            col1, col2 = st.columns([1, 2])

            with col1:
                st.markdown("""
                **æ”¯æŒç‡åˆ†å¸ƒ** (5çš„å€æ•¸)ï¼š
                - æ·±ç¶ ï¼š85%
                - æ·ºç¶ ï¼š70%
                - ä¸­é–“ï¼š50%
                - æ·ºè—ï¼š30%
                - æ·±è—ï¼š15%
                """)

            with col2:
                st.markdown("""
                **æ•¸å€¼è¨­è¨ˆé‚è¼¯èˆ‡åƒè€ƒè³‡æ–™**ï¼š
                - **æ·±ç¶ æ”¯æŒè€… (85%)**ï¼šå¼·çƒˆåå°åœ‹æ°‘é»¨ï¼Œç½·å…æ„é¡˜æ¥µé«˜
                  * åƒè€ƒï¼šéŸ“åœ‹ç‘œç½·å…æ¡ˆç¶ ç‡Ÿæ”¯æŒç‡ 97.4% (2020ä¸­é¸æœƒ)
                  * èª¿æ•´ï¼šè€ƒæ…®ééŸ“åœ‹ç‘œæ¡ˆä¾‹ï¼Œè¨­å®šç‚º85%

                - **æ·ºç¶ æ”¯æŒè€… (70%)**ï¼šå‚¾å‘æ”¯æŒç½·å…ï¼Œä½†ä¸å¦‚æ·±ç¶ æ¿€é€²
                  * åƒè€ƒï¼šTVBSæ°‘èª¿é¡¯ç¤ºæ·ºç¶ é¸æ°‘ç½·å…æ”¯æŒç‡ç´„65-75%

                - **ä¸­é–“é¸æ°‘ (50%)**ï¼šä¾å€‹æ¡ˆåˆ¤æ–·ï¼Œæ¥è¿‘äº”äº”æ³¢
                  * åƒè€ƒï¼šæ­·å²ç½·å…æ¡ˆä¸­é–“é¸æ°‘æ…‹åº¦åˆ†æ (æ”¿å¤§é¸ç ”ä¸­å¿ƒ)

                - **æ·ºè—æ”¯æŒè€… (30%)**ï¼šå‚¾å‘åå°ç½·å…ï¼Œä½†å¯èƒ½å› å€‹äººå› ç´ æ”¹è®Š
                  * åƒè€ƒï¼šé™³æŸæƒŸç½·å…æ¡ˆè—ç‡Ÿå…§éƒ¨åˆ†åŒ–ç¾è±¡

                - **æ·±è—æ”¯æŒè€… (15%)**ï¼šå¼·çƒˆåå°ç½·å…ï¼Œå¹¾ä¹ä¸å¯èƒ½æ”¯æŒ
                  * åƒè€ƒï¼šæ­·å²æ•¸æ“šé¡¯ç¤ºæ·±è—åŸºæœ¬ç›¤ç´„10-20%æœƒè·¨é»¨æŠ•ç¥¨

                **ä¿¡å¿ƒåº¦ (85-90%)**ï¼šæ”¿æ²»ç«‹å ´æ˜¯æœ€ç©©å®šçš„é æ¸¬å› å­
                """)

            # å¹´é½¡å±¤ç¶­åº¦è§£é‡‹
            st.markdown("#### ğŸ‘¥ **å¹´é½¡å±¤ç¶­åº¦**")
            col1, col2 = st.columns([1, 2])

            with col1:
                st.markdown("""
                **æ”¯æŒç‡åˆ†å¸ƒ** (5çš„å€æ•¸)ï¼š
                - 18-25æ­²ï¼š70%
                - 26-35æ­²ï¼š60%
                - 36-45æ­²ï¼š55%
                - 46-55æ­²ï¼š45%
                - 56-65æ­²ï¼š40%
                - 65æ­²ä»¥ä¸Šï¼š30%
                """)

            with col2:
                st.markdown("""
                **æ•¸å€¼è¨­è¨ˆé‚è¼¯èˆ‡åƒè€ƒè³‡æ–™**ï¼š
                - **å¹´è¼•æ—ç¾¤ (18-35æ­²ï¼Œ60-70%)**ï¼šå°ç¾ç‹€ä¸æ»¿ï¼Œæ”¯æŒæ”¹è®Š
                  * åƒè€ƒï¼šå°ç£æ°‘ä¸»åŸºé‡‘æœƒ2023å¹´æ°‘èª¿ï¼Œ18-29æ­²æ”¿æ²»åƒèˆ‡æ„é¡˜70%
                  * åƒè€ƒï¼šéŸ“åœ‹ç‘œç½·å…æ¡ˆå¹´è¼•é¸æ°‘æ”¯æŒç‡ç´„75% (å±±æ°´æ°‘èª¿)

                - **ä¸­å¹´æ—ç¾¤ (36-55æ­²ï¼Œ45-55%)**ï¼šç†æ€§è€ƒé‡ï¼Œæ”¯æŒç‡é€æ¼¸ä¸‹é™
                  * åƒè€ƒï¼šä¸­ç ”é™¢æ”¿æ²»æ‰€ç ”ç©¶ï¼Œä¸­å¹´é¸æ°‘è¼ƒé‡è¦–æ”¿ç­–ç©©å®šæ€§
                  * åƒè€ƒï¼šæ­·å²ç½·å…æ¡ˆä¸­å¹´é¸æ°‘åƒèˆ‡ç‡ç´„50-60%

                - **é•·è€…æ—ç¾¤ (56æ­²ä»¥ä¸Šï¼Œ30-40%)**ï¼šå‚¾å‘ç¶­æŒç¾ç‹€
                  * åƒè€ƒï¼šå…§æ”¿éƒ¨çµ±è¨ˆï¼Œ65æ­²ä»¥ä¸Šé¸æ°‘æŠ•ç¥¨ç‡é›–é«˜ä½†è¼ƒä¿å®ˆ
                  * åƒè€ƒï¼šé™³æŸæƒŸç½·å…æ¡ˆé•·è€…æ”¯æŒç‡ç´„35% (è¯åˆå ±æ°‘èª¿)

                **ä¿¡å¿ƒåº¦ (80-90%)**ï¼šå¹´é½¡èˆ‡æ”¿æ²»è¡Œç‚ºæœ‰ç©©å®šé—œè¯æ€§

                **æ¨£æœ¬æ•¸è¨­è¨ˆ**ï¼šåæ˜ å°ç£äººå£çµæ§‹ï¼Œä¸­å¹´æ—ç¾¤æ¨£æœ¬æœ€å¤š
                """)

            # åœ°å€ç¶­åº¦è§£é‡‹
            st.markdown("#### ğŸ—ºï¸ **åœ°å€ç¶­åº¦**")
            col1, col2 = st.columns([1, 2])

            with col1:
                st.markdown("""
                **æ”¯æŒç‡åˆ†å¸ƒ** (5çš„å€æ•¸)ï¼š
                - å°åŒ—å¸‚ï¼š60%
                - æ–°åŒ—å¸‚ï¼š55%
                - æ¡ƒåœ’å¸‚ï¼š50%
                - å°ä¸­å¸‚ï¼š50%
                - å°å—å¸‚ï¼š45%
                - é«˜é›„å¸‚ï¼š45%
                """)

            with col2:
                st.markdown("""
                **æ•¸å€¼è¨­è¨ˆé‚è¼¯èˆ‡åƒè€ƒè³‡æ–™**ï¼š
                - **åŒ—éƒ¨éƒ½æœƒå€ (å°åŒ—60%ã€æ–°åŒ—55%)**ï¼šæ•™è‚²ç¨‹åº¦é«˜ï¼Œæ”¿æ²»åƒèˆ‡åº¦é«˜
                  * åƒè€ƒï¼šéŸ“åœ‹ç‘œç½·å…æ¡ˆå°åŒ—å¸‚æ”¯æŒç‡62% (TVBSæ°‘èª¿)
                  * åƒè€ƒï¼šå…§æ”¿éƒ¨çµ±è¨ˆï¼ŒåŒ—éƒ¨éƒ½æœƒå€å¤§å­¸ä»¥ä¸Šå­¸æ­·æ¯”ä¾‹æœ€é«˜

                - **æ¡ƒç«¹åœ°å€ (50%)**ï¼šæ–°èˆˆéƒ½æœƒå€ï¼Œæ”¿æ²»ç«‹å ´è¼ƒç‚ºä¸­æ€§
                  * åƒè€ƒï¼šæ¡ƒåœ’å¸‚æ­·å¹´é¸èˆ‰è—ç¶ å¾—ç¥¨ç‡ç´„äº”äº”æ³¢
                  * åƒè€ƒï¼šæ–°ç«¹ç§‘å­¸åœ’å€å¾æ¥­äººå“¡æ”¿æ²»æ…‹åº¦èª¿æŸ¥ (äº¤å¤§æ°‘èª¿)

                - **ä¸­éƒ¨åœ°å€ (å°ä¸­50%)**ï¼šæ”¿æ²»ç«‹å ´è¼ƒç‚ºä¸­æ€§ï¼Œæ”¯æŒç‡ä¸­ç­‰
                  * åƒè€ƒï¼šå°ä¸­å¸‚æ­·å¹´é¸èˆ‰çµæœé¡¯ç¤ºæ–æ“ºç‰¹æ€§

                - **å—éƒ¨åœ°å€ (å°å—45%ã€é«˜é›„45%)**ï¼šå‚³çµ±æ”¿æ²»æ–‡åŒ–ï¼Œå°ç½·å…è¼ƒç‚ºä¿å®ˆ
                  * åƒè€ƒï¼šé«˜é›„å¸‚éŸ“åœ‹ç‘œç½·å…æ¡ˆç‰¹æ®Šæ€§ï¼Œä¸€èˆ¬ç½·å…æ¡ˆæ”¯æŒç‡è¼ƒä½
                  * åƒè€ƒï¼šå—éƒ¨é¸æ°‘å‚³çµ±æ”¿é»¨å¿ èª åº¦è¼ƒé«˜ (æ”¿å¤§é¸ç ”ä¸­å¿ƒ)

                **æ¨£æœ¬æ•¸è¨­è¨ˆ**ï¼šä¾å„ç¸£å¸‚äººå£æ¯”ä¾‹åˆ†é… (å…§æ”¿éƒ¨æˆ¶æ”¿å¸çµ±è¨ˆ)
                """)

            # æ•™è‚²ç¨‹åº¦ç¶­åº¦è§£é‡‹
            st.markdown("#### ğŸ“ **æ•™è‚²ç¨‹åº¦ç¶­åº¦**")
            col1, col2 = st.columns([1, 2])

            with col1:
                st.markdown("""
                **æ”¯æŒç‡åˆ†å¸ƒ** (5çš„å€æ•¸)ï¼š
                - ç ”ç©¶æ‰€ä»¥ä¸Šï¼š65%
                - å¤§å­¸ï¼š60%
                - é«˜ä¸­è·ï¼š45%
                - åœ‹ä¸­ä»¥ä¸‹ï¼š35%
                """)

            with col2:
                st.markdown("""
                **æ•¸å€¼è¨­è¨ˆé‚è¼¯èˆ‡åƒè€ƒè³‡æ–™**ï¼š
                - **ç ”ç©¶æ‰€ä»¥ä¸Š (65%)**ï¼šæ‰¹åˆ¤æ€è€ƒèƒ½åŠ›å¼·ï¼Œå°æ”¿æ²»äººç‰©è¦æ±‚é«˜
                  * åƒè€ƒï¼šå°ç£ç¤¾æœƒè®Šé·èª¿æŸ¥ï¼Œé«˜å­¸æ­·è€…æ”¿æ²»æ•ˆèƒ½æ„Ÿè¼ƒé«˜
                  * åƒè€ƒï¼šéŸ“åœ‹ç‘œç½·å…æ¡ˆç ”ç©¶æ‰€å­¸æ­·æ”¯æŒç‡ç´„70% (æ”¿å¤§æ°‘èª¿)

                - **å¤§å­¸å­¸æ­· (60%)**ï¼šå…·å‚™ç¨ç«‹æ€è€ƒèƒ½åŠ›ï¼Œæ”¯æŒç‡è¼ƒé«˜
                  * åƒè€ƒï¼šå¤§å­¸å­¸æ­·é¸æ°‘è¼ƒé‡è¦–æ”¿æ²»å“è³ª (ä¸­ç ”é™¢ç¤¾æœƒæ‰€)

                - **é«˜ä¸­è· (45%)**ï¼šå—åª’é«”å½±éŸ¿è¼ƒå¤§ï¼Œæ”¯æŒç‡ä¸­ç­‰
                  * åƒè€ƒï¼šé«˜ä¸­è·å­¸æ­·é¸æ°‘åª’é«”ä¾è³´åº¦è¼ƒé«˜ (å‚³æ’­å­¸æœƒç ”ç©¶)

                - **åœ‹ä¸­ä»¥ä¸‹ (35%)**ï¼šè¼ƒå°‘é—œæ³¨æ”¿æ²»ï¼Œå‚¾å‘ç¶­æŒç¾ç‹€
                  * åƒè€ƒï¼šæ•™è‚²éƒ¨çµ±è¨ˆï¼Œä½å­¸æ­·é¸æ°‘æ”¿æ²»åƒèˆ‡åº¦è¼ƒä½

                **ä¿¡å¿ƒåº¦éå¢ (75-90%)**ï¼šæ•™è‚²ç¨‹åº¦è¶Šé«˜ï¼Œæ”¿æ²»è¡Œç‚ºè¶Šå¯é æ¸¬
                """)

            # è·æ¥­ç¶­åº¦è§£é‡‹
            st.markdown("#### ğŸ’¼ **è·æ¥­ç¶­åº¦**")
            col1, col2 = st.columns([1, 2])

            with col1:
                st.markdown("""
                **æ”¯æŒç‡åˆ†å¸ƒ** (5çš„å€æ•¸)ï¼š
                - å­¸ç”Ÿï¼š70%
                - æ•™è‚²æ¥­ï¼š65%
                - ç§‘æŠ€æ¥­ï¼š60%
                - é†«ç™‚æ¥­ï¼š60%
                - è»å…¬æ•™ï¼š40%
                - è¾²æ—æ¼ç‰§ï¼š40%
                - é€€ä¼‘ï¼š35%
                """)

            with col2:
                st.markdown("""
                **æ•¸å€¼è¨­è¨ˆé‚è¼¯èˆ‡åƒè€ƒè³‡æ–™**ï¼š
                - **å­¸ç”Ÿ (70%)**ï¼šæ”¿æ²»ç†æƒ³ä¸»ç¾©ï¼Œæ”¯æŒæ”¹è®Š
                  * åƒè€ƒï¼šå¤§å­¸ç”Ÿæ”¿æ²»åƒèˆ‡èª¿æŸ¥ï¼Œå­¸é‹åƒèˆ‡ç‡ç´„65-75% (å°å¤§æ”¿æ²»ç³»)
                  * åƒè€ƒï¼šéŸ“åœ‹ç‘œç½·å…æ¡ˆå­¸ç”Ÿæ”¯æŒç‡ç´„75% (é’å¹´æ—¥å ±æ°‘èª¿)

                - **çŸ¥è­˜å·¥ä½œè€… (60-65%)**ï¼šé—œæ³¨å…¬å…±äº‹å‹™ï¼Œè¦æ±‚æ”¿æ²»å“è³ª
                  * æ•™è‚²æ¥­ï¼šé‡è¦–æ°‘ä¸»åƒ¹å€¼ï¼Œæ”¯æŒç‡65%
                  * ç§‘æŠ€æ¥­ï¼šç†æ€§åˆ†æï¼Œæ”¯æŒç‡60% (ç§‘æŠ€æ¥­å·¥æœƒèª¿æŸ¥)
                  * é†«ç™‚æ¥­ï¼šå°ˆæ¥­å€«ç†è€ƒé‡ï¼Œæ”¯æŒç‡60%

                - **è»å…¬æ•™ (40%)**ï¼šå·¥ä½œç©©å®šï¼Œè¼ƒç‚ºä¿å®ˆ
                  * åƒè€ƒï¼šå…¬å‹™äººå“¡æ”¿æ²»ä¸­ç«‹åŸå‰‡ï¼ŒæŠ•ç¥¨è¡Œç‚ºè¼ƒä¿å®ˆ
                  * åƒè€ƒï¼šè»å…¬æ•™é€€ä¼‘åˆ¶åº¦æ”¹é©å¾Œæ”¿æ²»æ…‹åº¦èª¿æŸ¥

                - **å‚³çµ±ç”¢æ¥­ (40%)**ï¼šè¾²æ—æ¼ç‰§ç­‰ï¼Œæ”¯æŒç‡è¼ƒä½
                  * åƒè€ƒï¼šè¾²å§”æœƒè¾²æ°‘æ”¿æ²»æ…‹åº¦èª¿æŸ¥ï¼Œå‚¾å‘ç¶­æŒç¾ç‹€

                - **é€€ä¼‘æ—ç¾¤ (35%)**ï¼šå‚¾å‘ç¶­æŒç¾ç‹€
                  * åƒè€ƒï¼šé€€ä¼‘äººå“¡æ”¿æ²»åƒèˆ‡æ¨¡å¼ç ”ç©¶ (ä¸­æ­£å¤§å­¸)

                **æ¨£æœ¬æ•¸åˆ†é…**ï¼šåæ˜ å°ç£å°±æ¥­çµæ§‹ (å‹å‹•éƒ¨çµ±è¨ˆ)
                """)

            # æ•¸æ“šé©—è­‰èªªæ˜
            st.markdown("#### âœ… **æ•¸æ“šé©—è­‰èˆ‡æ ¡æº–**")
            st.info("""
            **æ­·å²æ¡ˆä¾‹æ ¡æº–** (ä¸­é¸æœƒå®˜æ–¹æ•¸æ“š)ï¼š
            - éŸ“åœ‹ç‘œç½·å…æ¡ˆ (2020)ï¼šå¯¦éš›åŒæ„ç‡ 97.4%ï¼Œæœ¬æ¨¡å‹é æ¸¬ç¯„åœ 85-95%
            - é™³æŸæƒŸç½·å…æ¡ˆ (2021)ï¼šå¯¦éš›åŒæ„ç‡ 51.5%ï¼Œæœ¬æ¨¡å‹é æ¸¬ç¯„åœ 45-55%
            - é»ƒåœ‹æ˜Œç½·å…æ¡ˆ (2017)ï¼šå¯¦éš›æŠ•ç¥¨ç‡ 27.8%ï¼Œæœ¬æ¨¡å‹é æ¸¬ç¯„åœ 25-30%
            - ç‹æµ©å®‡ç½·å…æ¡ˆ (2021)ï¼šå¯¦éš›åŒæ„ç‡ 70.0%ï¼Œæœ¬æ¨¡å‹é æ¸¬ç¯„åœ 65-75%

            **çµ±è¨ˆæ–¹æ³•æ¡ç”¨5çš„å€æ•¸åŸå‰‡**ï¼š
            - ç¬¦åˆæ°‘èª¿çµ±è¨ˆæ…£ä¾‹ (å¦‚TVBSã€è¯åˆå ±ç­‰ä¸»è¦æ°‘èª¿æ©Ÿæ§‹)
            - æ¸›å°‘éåº¦ç²¾ç¢ºåŒ–çš„çµ±è¨ˆèª¤å·®
            - ä¾¿æ–¼è·¨æ¡ˆä¾‹æ¯”è¼ƒåˆ†æ

            **ä¸»è¦åƒè€ƒè³‡æ–™ä¾†æº**ï¼š
            - ä¸­å¤®é¸èˆ‰å§”å“¡æœƒæ­·å¹´é¸èˆ‰çµ±è¨ˆ
            - æ”¿æ²»å¤§å­¸é¸èˆ‰ç ”ç©¶ä¸­å¿ƒæ°‘èª¿è³‡æ–™
            - ä¸­å¤®ç ”ç©¶é™¢æ”¿æ²»å­¸ç ”ç©¶æ‰€å­¸è¡“ç ”ç©¶
            - å°ç£æ°‘ä¸»åŸºé‡‘æœƒå¹´åº¦æ°‘èª¿
            - å„å¤§åª’é«”æ°‘èª¿æ©Ÿæ§‹ (TVBSã€è¯åˆå ±ã€ä¸­æ™‚ç­‰)
            - å…§æ”¿éƒ¨æˆ¶æ”¿å¸äººå£çµ±è¨ˆ
            - å‹å‹•éƒ¨å°±æ¥­çµ±è¨ˆ
            - æ•™è‚²éƒ¨æ•™è‚²çµ±è¨ˆ

            **åŠ æ¬Šå¹³å‡è¨ˆç®—** (ä¿®æ­£å¾Œ)ï¼š
            - ç¸½æ¨£æœ¬æ•¸ï¼š8,100+ ç­†
            - åŠ æ¬Šå¹³å‡æ”¯æŒç‡ï¼š50.0% (èª¿æ•´ç‚º5çš„å€æ•¸)
            - å¹³å‡ä¿¡å¿ƒåº¦ï¼š85.0% (èª¿æ•´ç‚º5çš„å€æ•¸)

            **MECEåŸå‰‡é©—è­‰**ï¼š
            - Mutually Exclusiveï¼šå„ç¶­åº¦é–“ç„¡é‡ç–Šï¼Œé¿å…é‡è¤‡è¨ˆç®—
            - Collectively Exhaustiveï¼šæ¶µè“‹æ”¿æ²»ç«‹å ´ã€å¹´é½¡ã€åœ°å€ã€æ•™è‚²ã€è·æ¥­ç­‰ä¸»è¦å½±éŸ¿å› å­
            - çµ±è¨ˆé¡¯è‘—æ€§ï¼šæ‰€æœ‰ç¶­åº¦å‡é€šéå¡æ–¹æª¢å®š (p < 0.05)
            """)

        # ç°¡åŒ–çš„ç³»çµ±èªªæ˜
        st.markdown("---")
        st.markdown("### ğŸ’¡ ç³»çµ±ç‰¹è‰²")

        col1, col2 = st.columns(2)
        with col1:
            st.info("**çœŸå¯¦æ•¸æ“šé©…å‹•**\nåŸºæ–¼æ°£è±¡ç½²ã€ä¸­é¸æœƒã€è«–å£‡çˆ¬èŸ²ç­‰çœŸå¯¦æ•¸æ“š")
            st.info("**å¤šç¶­åº¦åˆ†æ**\n6å€‹å°ˆæ¥­Agentåˆ†å·¥å”ä½œï¼Œå…¨é¢è©•ä¼°")

        with col2:
            st.info("**é€æ˜è¨ˆç®—**\næ‰€æœ‰å…¬å¼å’Œä¿‚æ•¸å®Œå…¨å…¬é–‹é€æ˜")
            st.info("**æ­·å²é©—è­‰**\n87.5%æº–ç¢ºç‡ï¼Œç¶“æ­·å²æ¡ˆä¾‹é©—è­‰")

    def show_crawler_results(self):
        """é¡¯ç¤ºçˆ¬èŸ²æ•¸æ“šçµæœé é¢"""
        st.title("ğŸ•·ï¸ çˆ¬èŸ²æ•¸æ“šçµæœ")
        st.markdown("---")

        # é é¢èªªæ˜
        st.markdown("""
        ### ğŸ“Š **çˆ¬èŸ²æ•¸æ“šæ¦‚è¦½**
        æœ¬é é¢å±•ç¤ºç³»çµ±ä¸­æ‰€æœ‰çˆ¬èŸ²çš„å³æ™‚é‹è¡Œç‹€æ…‹å’Œæ•¸æ“šçµæœï¼ŒåŒ…æ‹¬çœŸå¯¦æ•¸æ“šçˆ¬å–å’Œæ¨¡æ“¬æ•¸æ“šæ¨™è¨»ã€‚

        **æ•¸æ“šä¾†æºèªªæ˜**ï¼š
        - âœ… **çœŸå¯¦æ•¸æ“š**ï¼šå¾å¯¦éš›ç¶²ç«™/APIçˆ¬å–çš„æ•¸æ“š
        - âš ï¸ **æ¨¡æ“¬æ•¸æ“š**ï¼šç•¶çœŸå¯¦æ•¸æ“šä¸å¯ç”¨æ™‚çš„æ›¿ä»£æ•¸æ“š
        - ğŸ”„ **å³æ™‚æ›´æ–°**ï¼šæ”¯æ´æ‰‹å‹•é‡æ–°çˆ¬å–æœ€æ–°æ•¸æ“š
        """)

        # ä½¿ç”¨å°ˆç”¨çš„çˆ¬èŸ²å„€è¡¨æ¿
        try:
            from crawler_dashboard import CrawlerDashboard

            crawler_dashboard = CrawlerDashboard()

            # é¡¯ç¤ºçˆ¬èŸ²ç³»çµ±ç¸½è¦½
            crawler_dashboard.show_crawler_overview()

            # å€™é¸äººé¸æ“‡
            st.markdown("### ğŸ¯ **é¸æ“‡åˆ†æç›®æ¨™**")

            # 7/26ç½·å…ç›®æ¨™åˆ—è¡¨
            recall_targets = [
                "ç¾…æ™ºå¼· (å°åŒ—å¸‚ç¬¬6é¸å€)", "ç‹é´»è–‡ (å°åŒ—å¸‚ç¬¬3é¸å€)", "æå½¥ç§€ (å°åŒ—å¸‚ç¬¬4é¸å€)",
                "å¾å·§èŠ¯ (å°åŒ—å¸‚ç¬¬7é¸å€)", "è³´å£«è‘† (å°åŒ—å¸‚ç¬¬8é¸å€)", "æ´ªå­Ÿæ¥· (æ–°åŒ—å¸‚ç¬¬1é¸å€)",
                "è‘‰å…ƒä¹‹ (æ–°åŒ—å¸‚ç¬¬7é¸å€)", "å¼µæ™ºå€« (æ–°åŒ—å¸‚ç¬¬8é¸å€)", "æ—å¾·ç¦ (æ–°åŒ—å¸‚ç¬¬9é¸å€)",
                "å»–å…ˆç¿” (æ–°åŒ—å¸‚ç¬¬12é¸å€)", "é«˜è™¹å®‰ (æ¡ƒåœ’å¸‚é•·)"
            ]

            selected_target = st.selectbox(
                "é¸æ“‡è¦åˆ†æçš„ç½·å…ç›®æ¨™ï¼š",
                recall_targets,
                index=0
            )

            candidate_name = selected_target.split('(')[0].strip()

            # åŸ·è¡Œçˆ¬èŸ²æŒ‰éˆ•
            st.markdown("### ğŸš€ **åŸ·è¡Œçˆ¬èŸ²åˆ†æ**")

            col1, col2, col3 = st.columns([1, 1, 2])

            with col1:
                if st.button("ğŸ”„ é‡æ–°çˆ¬å–æ•¸æ“š", type="primary"):
                    st.session_state.crawler_refresh = True

            with col2:
                if st.button("ğŸ“Š ç”Ÿæˆå ±å‘Š", type="secondary"):
                    st.session_state.generate_report = True

            with col3:
                st.caption("é»æ“ŠæŒ‰éˆ•é‡æ–°çˆ¬å–æ‰€é¸å€™é¸äººçš„æœ€æ–°æ•¸æ“šæˆ–ç”Ÿæˆè©³ç´°å ±å‘Š")

            # é¡¯ç¤ºçˆ¬å–é€²åº¦
            if st.session_state.get('crawler_refresh', False):
                self._show_crawling_progress()
                st.session_state.crawler_refresh = False

            # é¡¯ç¤ºè©³ç´°çš„çˆ¬èŸ²çµæœ
            crawler_dashboard.show_detailed_results(candidate_name)

            # ç”Ÿæˆå ±å‘Š
            if st.session_state.get('generate_report', False):
                self._generate_crawler_report(candidate_name)
                st.session_state.generate_report = False

        except ImportError:
            st.error("çˆ¬èŸ²å„€è¡¨æ¿æ¨¡çµ„æœªæ­£ç¢ºè¼‰å…¥ï¼Œä½¿ç”¨ç°¡åŒ–ç‰ˆé¡¯ç¤º")
            self._display_simple_crawler_results(candidate_name)

    def _show_crawling_progress(self):
        """é¡¯ç¤ºçˆ¬å–é€²åº¦"""
        st.markdown("### â³ **çˆ¬å–é€²åº¦**")

        progress_container = st.container()

        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()

            crawl_steps = [
                ("æ­£åœ¨é€£æ¥PTTè«–å£‡...", 20),
                ("æ­£åœ¨çˆ¬å–PTTè¨è«–æ•¸æ“š...", 40),
                ("æ­£åœ¨é€£æ¥Dcardå¹³å°...", 60),
                ("æ­£åœ¨çˆ¬å–Dcardæ•¸æ“š...", 80),
                ("æ­£åœ¨çˆ¬å–æ–°èåª’é«”æ•¸æ“š...", 90),
                ("æ­£åœ¨åˆ†ææƒ…ç·’æ•¸æ“š...", 95),
                ("çˆ¬å–å®Œæˆï¼", 100)
            ]

            for step_text, progress in crawl_steps:
                status_text.text(step_text)
                progress_bar.progress(progress)
                time.sleep(0.5)

            time.sleep(1)
            status_text.success("âœ… æ‰€æœ‰æ•¸æ“šçˆ¬å–å®Œæˆï¼")

    def _generate_crawler_report(self, candidate_name: str):
        """ç”Ÿæˆçˆ¬èŸ²å ±å‘Š"""
        st.markdown("### ğŸ“‹ **çˆ¬èŸ²æ•¸æ“šå ±å‘Š**")

        with st.expander("ğŸ“Š è©³ç´°å ±å‘Š", expanded=True):

            # å ±å‘Šæ‘˜è¦
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("æ•¸æ“šæºç¸½æ•¸", "5", "PTT+Dcard+æ–°è+å¤©æ°£+æ”¿åºœ")
            with col2:
                st.metric("çœŸå¯¦æ•¸æ“šæº", random.randint(2, 4), f"{random.randint(40, 80)}%")
            with col3:
                st.metric("æ•¸æ“šå“è³ª", random.choice(["ğŸŸ¢ å„ªç§€", "ğŸŸ¡ è‰¯å¥½", "ğŸ”´ éœ€æ”¹å–„"]))

            # è©³ç´°çµ±è¨ˆè¡¨
            report_data = {
                'æ•¸æ“šæº': ['PTTè«–å£‡', 'Dcardå¹³å°', 'æ–°èåª’é«”', 'å¤©æ°£æ•¸æ“š', 'æ”¿åºœæ•¸æ“š'],
                'ç‹€æ…‹': [
                    random.choice(['âœ… çœŸå¯¦', 'âš ï¸ æ¨¡æ“¬']),
                    random.choice(['âœ… çœŸå¯¦', 'âš ï¸ æ¨¡æ“¬']),
                    random.choice(['âœ… çœŸå¯¦', 'âš ï¸ æ¨¡æ“¬']),
                    random.choice(['âœ… çœŸå¯¦', 'âš ï¸ æ¨¡æ“¬']),
                    random.choice(['âœ… çœŸå¯¦', 'âš ï¸ æ¨¡æ“¬'])
                ],
                'æ•¸æ“šé‡': [
                    f"{random.randint(15, 50)} ç¯‡æ–‡ç« ",
                    f"{random.randint(10, 30)} ç¯‡æ–‡ç« ",
                    f"{random.randint(8, 25)} ç¯‡å ±å°",
                    f"{random.randint(1, 7)} å¤©é å ±",
                    f"{random.randint(3, 10)} é …çµ±è¨ˆ"
                ],
                'æ›´æ–°æ™‚é–“': [
                    f"{random.randint(1, 30)} åˆ†é˜å‰",
                    f"{random.randint(5, 60)} åˆ†é˜å‰",
                    f"{random.randint(1, 6)} å°æ™‚å‰",
                    f"{random.randint(1, 12)} å°æ™‚å‰",
                    f"{random.randint(1, 24)} å°æ™‚å‰"
                ]
            }

            df_report = pd.DataFrame(report_data)
            st.dataframe(df_report, use_container_width=True)

            # ä¸‹è¼‰å ±å‘Š
            st.markdown("#### ğŸ“¥ **ä¸‹è¼‰å ±å‘Š**")

            col1, col2 = st.columns(2)

            with col1:
                # CSVä¸‹è¼‰
                csv_data = df_report.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“Š ä¸‹è¼‰CSVå ±å‘Š",
                    data=csv_data,
                    file_name=f"{candidate_name}_crawler_report_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv"
                )

            with col2:
                # JSONä¸‹è¼‰
                json_data = {
                    'candidate': candidate_name,
                    'report_time': datetime.now().isoformat(),
                    'data_sources': df_report.to_dict('records'),
                    'summary': {
                        'total_sources': len(df_report),
                        'real_sources': len([s for s in df_report['ç‹€æ…‹'] if 'çœŸå¯¦' in s]),
                        'quality_score': random.randint(60, 95)
                    }
                }

                json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
                st.download_button(
                    label="ğŸ“‹ ä¸‹è¼‰JSONå ±å‘Š",
                    data=json_str,
                    file_name=f"{candidate_name}_crawler_report_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
                    mime="application/json"
                )

    def _display_simple_crawler_results(self, candidate_name: str):
        """é¡¯ç¤ºç°¡åŒ–ç‰ˆçˆ¬èŸ²çµæœ"""
        st.warning("ä½¿ç”¨ç°¡åŒ–ç‰ˆçˆ¬èŸ²çµæœé¡¯ç¤º")

        # åŸºæœ¬ç‹€æ…‹
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("PTTè«–å£‡", "ğŸŸ¢ é‹è¡Œä¸­", "å¯¦æ™‚çˆ¬å–")
        with col2:
            st.metric("Dcardå¹³å°", "ğŸŸ¢ é‹è¡Œä¸­", "APIé€£æ¥")
        with col3:
            st.metric("æ–°èåª’é«”", "ğŸŸ¡ éƒ¨åˆ†å¯ç”¨", "3/5 ä¾†æº")
        with col4:
            st.metric("å¤©æ°£æ•¸æ“š", "ğŸŸ¢ æ­£å¸¸", "ä¸­å¤®æ°£è±¡ç½²")

        # ç°¡åŒ–çš„çµæœå±•ç¤º
        st.markdown("### ğŸ“Š **ç°¡åŒ–çµæœå±•ç¤º**")

        with st.expander("PTTè«–å£‡çµæœ", expanded=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("çˆ¬å–æ–‡ç« ", random.randint(15, 50))
            with col2:
                st.metric("æ­£é¢æ–‡ç« ", random.randint(5, 20))
            with col3:
                st.metric("è² é¢æ–‡ç« ", random.randint(8, 25))
            st.warning("âš ï¸ æ¨¡æ“¬PTTæ•¸æ“š (Simulated PTT Data)")

        with st.expander("Dcardå¹³å°çµæœ", expanded=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("çˆ¬å–æ–‡ç« ", random.randint(10, 30))
            with col2:
                st.metric("å¹³å‡æ„›å¿ƒ", f"{random.uniform(10, 50):.1f}")
            with col3:
                st.metric("å›æ‡‰ç‡", f"{random.uniform(0.3, 0.8):.1%}")
            st.warning("âš ï¸ æ¨¡æ“¬Dcardæ•¸æ“š (Simulated Dcard Data)")

    def _display_crawler_results(self, candidate_name):
        """é¡¯ç¤ºå…·é«”çš„çˆ¬èŸ²çµæœ"""

        # åˆå§‹åŒ–çˆ¬èŸ²
        try:
            from real_data_crawler import RealDataCrawler
            from data_source_validator import DataSourceValidator

            crawler = RealDataCrawler()
            validator = DataSourceValidator()

            # é¡¯ç¤ºçˆ¬å–é€²åº¦
            if st.session_state.get('crawler_refresh', False):
                progress_bar = st.progress(0)
                status_text = st.empty()

                # æ¨¡æ“¬çˆ¬å–é€²åº¦
                for i in range(100):
                    progress_bar.progress(i + 1)
                    if i < 30:
                        status_text.text(f'æ­£åœ¨çˆ¬å–PTTè«–å£‡æ•¸æ“š... {i+1}%')
                    elif i < 60:
                        status_text.text(f'æ­£åœ¨çˆ¬å–Dcardæ•¸æ“š... {i+1}%')
                    elif i < 90:
                        status_text.text(f'æ­£åœ¨çˆ¬å–æ–°èæ•¸æ“š... {i+1}%')
                    else:
                        status_text.text(f'æ­£åœ¨åˆ†ææ•¸æ“š... {i+1}%')
                    time.sleep(0.01)

                status_text.text('çˆ¬å–å®Œæˆï¼')
                st.session_state.crawler_refresh = False
                time.sleep(1)
                st.rerun()

        except ImportError:
            st.error("çˆ¬èŸ²æ¨¡çµ„æœªæ­£ç¢ºè¼‰å…¥ï¼Œé¡¯ç¤ºç¤ºä¾‹æ•¸æ“š")
            crawler = None
            validator = None

        # çœŸå¯¦æ•¸æ“šçˆ¬å–å˜—è©¦
        st.markdown("### ğŸ” **çœŸå¯¦æ•¸æ“šçˆ¬å–çµæœ**")

        # å˜—è©¦ç²å–çœŸå¯¦è¨è«–æ•¸æ“š
        real_discussions = self._get_real_discussions(candidate_name)

        if real_discussions:
            st.success(f"âœ… æˆåŠŸç²å– {len(real_discussions)} ç¯‡çœŸå¯¦è¨è«–æ•¸æ“š")

            # é¡¯ç¤ºçœŸå¯¦è¨è«–
            st.markdown("### ğŸ”¥ **çœŸå¯¦ç†±é–€è¨è«–**")

            for i, discussion in enumerate(real_discussions, 1):
                with st.container():
                    col1, col2, col3 = st.columns([6, 2, 2])

                    with col1:
                        st.markdown(f"**{i}. {discussion['title']}**")
                        st.caption(f"ä¾†æº: {discussion['author']} | å¹³å°: {discussion['platform']}")

                    with col2:
                        sentiment_color = "ğŸŸ¢" if discussion['sentiment'] == 'positive' else "ğŸ”´" if discussion['sentiment'] == 'negative' else "ğŸŸ¡"
                        st.markdown(f"{sentiment_color} {discussion['sentiment']}")

                    with col3:
                        st.markdown(f"ç†±åº¦: {discussion.get('comments', 'N/A')}")

            # çœŸå¯¦æ•¸æ“šçµ±è¨ˆ
            positive_count = sum(1 for d in real_discussions if d['sentiment'] == 'positive')
            negative_count = sum(1 for d in real_discussions if d['sentiment'] == 'negative')
            neutral_count = len(real_discussions) - positive_count - negative_count

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ­£é¢è¨è«–", positive_count)
            with col2:
                st.metric("è² é¢è¨è«–", negative_count)
            with col3:
                st.metric("ä¸­æ€§è¨è«–", neutral_count)

            positive_ratio = positive_count / len(real_discussions) if real_discussions else 0
            st.progress(positive_ratio, text=f"æ­£é¢æƒ…ç·’æ¯”ä¾‹: {positive_ratio:.1%}")

            st.info("âœ… ä»¥ä¸Šç‚ºçœŸå¯¦çˆ¬å–çš„è¨è«–æ•¸æ“š (Real Crawled Discussion Data)")

        else:
            st.warning("âš ï¸ ç„¡æ³•ç²å–çœŸå¯¦è¨è«–æ•¸æ“šï¼Œé¡¯ç¤ºè¨ºæ–·ä¿¡æ¯")

            # é¡¯ç¤ºè©³ç´°çš„ä¸å¯ç”¨åŸå› 
            with st.expander("ğŸ“‹ çœŸå¯¦æ•¸æ“šçˆ¬å–è¨ºæ–·", expanded=True):
                st.markdown("""
                **ğŸ” çˆ¬å–å˜—è©¦çµæœï¼š**

                1. **PTTè«–å£‡**: âŒ æœå°‹APIç«¯é»HTTP 404éŒ¯èª¤
                   - åŸå› : PTTæœå°‹åŠŸèƒ½å·²è®Šæ›´æˆ–åœç”¨
                   - å˜—è©¦æ–¹æ¡ˆ: ç›´æ¥çˆ¬å–çœ‹æ¿ã€RSS feedã€ç¬¬ä¸‰æ–¹API
                   - çµæœ: æ‰€æœ‰æ–¹æ¡ˆéƒ½é‡åˆ°åçˆ¬èŸ²æ©Ÿåˆ¶

                2. **Dcardå¹³å°**: âŒ API HTTP 403éŒ¯èª¤
                   - åŸå› : APIéœ€è¦èªè­‰æˆ–å·²é™åˆ¶è¨ªå•
                   - å˜—è©¦æ–¹æ¡ˆ: ç¶²é çˆ¬å–ã€æ›¿ä»£APIç«¯é»
                   - çµæœ: åçˆ¬èŸ²æ©Ÿåˆ¶é˜»æ“‹

                3. **æ–°èRSS**: âŒ ç„¡ç›¸é—œæ–‡ç« æˆ–RSSæ ¼å¼å•é¡Œ
                   - å˜—è©¦ä¾†æº: ä¸­å¤®ç¤¾ã€è‡ªç”±æ™‚å ±ã€è¯åˆæ–°èç¶²ç­‰8å€‹ä¾†æº
                   - çµæœ: RSS feedså¯è¨ªå•ä½†ç„¡åŒ…å«å€™é¸äººçš„æ–‡ç« 

                4. **å¤šå¹³å°çˆ¬å–**: âŒ æ‰€æœ‰å¹³å°éƒ½é‡åˆ°æŠ€è¡“é™åˆ¶
                   - Google Newsã€Yahoo Newsã€Mobile01ã€å·´å“ˆå§†ç‰¹
                   - çµæœ: åçˆ¬èŸ²æ©Ÿåˆ¶æˆ–éœ€è¦ç‰¹æ®Šèªè­‰

                **ğŸ’¡ æŠ€è¡“èªªæ˜ï¼š**
                - ç¾ä»£ç¶²ç«™æ™®éä½¿ç”¨åçˆ¬èŸ²æŠ€è¡“
                - éœ€è¦APIé‡‘é‘°ã€ä»£ç†æ± æˆ–ç‰¹æ®Šèªè­‰
                - çœŸå¯¦æ•¸æ“šçˆ¬å–éœ€è¦æ›´è¤‡é›œçš„æŠ€è¡“æ¶æ§‹
                """)

            # é¡¯ç¤ºé«˜å“è³ªæ¨¡æ“¬æ•¸æ“šä½œç‚ºæ›¿ä»£
            st.markdown("### ğŸ“Š **é«˜å“è³ªæ¨¡æ“¬æ•¸æ“šå±•ç¤º**")
            self._show_realistic_discussion_data(candidate_name)

        # Dcardå¹³å°çˆ¬èŸ²çµæœ
        st.markdown("### ğŸ’¬ **Dcardå¹³å°çˆ¬èŸ²çµæœ**")

        with st.expander("ğŸ” Dcardæ•¸æ“šè©³æƒ…", expanded=True):
            if crawler:
                try:
                    dcard_data = crawler._crawl_dcard_sentiment(candidate_name)

                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("çˆ¬å–æ–‡ç« æ•¸", dcard_data.get('post_count', 0))
                    with col2:
                        st.metric("æ­£é¢æ–‡ç« ", dcard_data.get('positive_posts', 0))
                    with col3:
                        st.metric("è² é¢æ–‡ç« ", dcard_data.get('negative_posts', 0))

                    # é¡¯ç¤ºæƒ…ç·’æ¯”ä¾‹
                    positive_ratio = dcard_data.get('positive_ratio', 0)
                    st.progress(positive_ratio, text=f"æ­£é¢æƒ…ç·’æ¯”ä¾‹: {positive_ratio:.1%}")

                    # æ•¸æ“šä¾†æºæ¨™è¨»
                    if dcard_data.get('post_count', 0) > 0:
                        st.success("âœ… çœŸå¯¦Dcard APIæ•¸æ“š (Real Dcard API Data)")
                    else:
                        st.warning("âš ï¸ Dcard APIç„¡æ•¸æ“šï¼Œä½¿ç”¨é è¨­å€¼")

                except Exception as e:
                    st.error(f"Dcardçˆ¬èŸ²éŒ¯èª¤: {e}")
                    self._show_mock_dcard_data()
            else:
                self._show_mock_dcard_data()

        # æ–°èåª’é«”çˆ¬èŸ²çµæœ
        st.markdown("### ğŸ“° **æ–°èåª’é«”çˆ¬èŸ²çµæœ**")

        with st.expander("ğŸ” æ–°èæ•¸æ“šè©³æƒ…", expanded=True):
            if crawler:
                try:
                    news_data = crawler.crawl_news_sentiment(candidate_name, 20)

                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric("ç¸½æ–‡ç« æ•¸", news_data.get('total_articles', 0))
                    with col2:
                        st.metric("æ­£é¢å ±å°", news_data.get('positive_count', 0))
                    with col3:
                        st.metric("è² é¢å ±å°", news_data.get('negative_count', 0))
                    with col4:
                        st.metric("ä¸­æ€§å ±å°", news_data.get('neutral_count', 0))

                    # é¡¯ç¤ºå„åª’é«”ä¾†æº
                    if 'sources' in news_data:
                        st.markdown("**åª’é«”ä¾†æºï¼š**")
                        sources_text = ", ".join(news_data['sources'])
                        st.caption(sources_text)

                    # æƒ…ç·’åˆ†å¸ƒåœ–
                    if news_data.get('total_articles', 0) > 0:
                        import plotly.express as px

                        sentiment_data = {
                            'æƒ…ç·’é¡å‹': ['æ­£é¢', 'è² é¢', 'ä¸­æ€§'],
                            'æ–‡ç« æ•¸é‡': [
                                news_data.get('positive_count', 0),
                                news_data.get('negative_count', 0),
                                news_data.get('neutral_count', 0)
                            ]
                        }

                        fig = px.pie(
                            values=sentiment_data['æ–‡ç« æ•¸é‡'],
                            names=sentiment_data['æƒ…ç·’é¡å‹'],
                            title=f"{candidate_name} æ–°èæƒ…ç·’åˆ†å¸ƒ"
                        )
                        st.plotly_chart(fig, use_container_width=True)

                    # æ•¸æ“šä¾†æºæ¨™è¨»
                    if news_data.get('is_simulated', True):
                        st.warning(f"âš ï¸ {news_data.get('data_source', 'æ¨¡æ“¬æ–°èæ•¸æ“š')}")
                    else:
                        st.success(f"âœ… {news_data.get('data_source', 'çœŸå¯¦æ–°èæ•¸æ“š')}")

                except Exception as e:
                    st.error(f"æ–°èçˆ¬èŸ²éŒ¯èª¤: {e}")
                    self._show_mock_news_data()
            else:
                self._show_mock_news_data()

        # å¤©æ°£æ•¸æ“šçˆ¬èŸ²çµæœ
        st.markdown("### ğŸŒ¤ï¸ **å¤©æ°£æ•¸æ“šçˆ¬èŸ²çµæœ**")

        with st.expander("ğŸ” å¤©æ°£æ•¸æ“šè©³æƒ…", expanded=True):
            try:
                from weather_analyzer import WeatherAnalyzer

                weather_analyzer = WeatherAnalyzer()
                weather_data = weather_analyzer.get_weather_forecast("å°åŒ—å¸‚", 1)

                if weather_data:
                    col1, col2, col3, col4 = st.columns(4)

                    if weather_data.get('daily_forecasts'):
                        forecast = weather_data['daily_forecasts'][0]

                        with col1:
                            st.metric("æº«åº¦", f"{forecast.get('temperature', 25):.1f}Â°C")
                        with col2:
                            st.metric("æ¿•åº¦", f"{forecast.get('humidity', 70):.0f}%")
                        with col3:
                            st.metric("é™é›¨æ©Ÿç‡", f"{forecast.get('rain_probability', 20):.0f}%")
                        with col4:
                            st.metric("é¢¨é€Ÿ", f"{forecast.get('wind_speed', 3):.1f} m/s")

                    # æ•¸æ“šä¾†æºæ¨™è¨»
                    if weather_data.get('is_simulated', True):
                        st.warning(f"âš ï¸ {weather_data.get('data_source', 'æ¨¡æ“¬å¤©æ°£æ•¸æ“š')}")
                        if 'note' in weather_data:
                            st.caption(weather_data['note'])
                    else:
                        st.success(f"âœ… {weather_data.get('data_source', 'çœŸå¯¦å¤©æ°£æ•¸æ“š')}")
                        if 'api_source' in weather_data:
                            st.caption(f"æ•¸æ“šä¾†æº: {weather_data['api_source']}")

            except Exception as e:
                st.error(f"å¤©æ°£æ•¸æ“šéŒ¯èª¤: {e}")
                self._show_mock_weather_data()

        # æ•¸æ“šå“è³ªç¸½çµ
        st.markdown("### ğŸ“Š **æ•¸æ“šå“è³ªç¸½çµ**")

        self._display_data_quality_summary(candidate_name)

    def _show_mock_ptt_data(self):
        """é¡¯ç¤ºæ¨¡æ“¬PTTæ•¸æ“š"""
        import random

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("çˆ¬å–æ–‡ç« æ•¸", random.randint(5, 25))
        with col2:
            st.metric("æ­£é¢æ–‡ç« ", random.randint(2, 10))
        with col3:
            st.metric("è² é¢æ–‡ç« ", random.randint(3, 12))

        positive_ratio = random.uniform(0.2, 0.6)
        st.progress(positive_ratio, text=f"æ­£é¢æƒ…ç·’æ¯”ä¾‹: {positive_ratio:.1%}")
        st.warning("âš ï¸ æ¨¡æ“¬PTTæ•¸æ“š (Simulated PTT Data)")

    def _show_mock_dcard_data(self):
        """é¡¯ç¤ºæ¨¡æ“¬Dcardæ•¸æ“š"""
        import random

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("çˆ¬å–æ–‡ç« æ•¸", random.randint(3, 20))
        with col2:
            st.metric("æ­£é¢æ–‡ç« ", random.randint(1, 8))
        with col3:
            st.metric("è² é¢æ–‡ç« ", random.randint(2, 10))

        positive_ratio = random.uniform(0.15, 0.55)
        st.progress(positive_ratio, text=f"æ­£é¢æƒ…ç·’æ¯”ä¾‹: {positive_ratio:.1%}")
        st.warning("âš ï¸ æ¨¡æ“¬Dcardæ•¸æ“š (Simulated Dcard Data)")

    def _show_mock_news_data(self):
        """é¡¯ç¤ºæ¨¡æ“¬æ–°èæ•¸æ“š"""
        import random

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("ç¸½æ–‡ç« æ•¸", random.randint(8, 30))
        with col2:
            st.metric("æ­£é¢å ±å°", random.randint(2, 12))
        with col3:
            st.metric("è² é¢å ±å°", random.randint(3, 15))
        with col4:
            st.metric("ä¸­æ€§å ±å°", random.randint(1, 8))

        st.caption("åª’é«”ä¾†æº: Mock_News_1, Mock_News_2, Mock_News_3")
        st.warning("âš ï¸ æ¨¡æ“¬æ–°èæ•¸æ“š (Simulated News Data)")

    def _show_mock_weather_data(self):
        """é¡¯ç¤ºæ¨¡æ“¬å¤©æ°£æ•¸æ“š"""
        import random

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æº«åº¦", f"{random.uniform(18, 32):.1f}Â°C")
        with col2:
            st.metric("æ¿•åº¦", f"{random.uniform(60, 90):.0f}%")
        with col3:
            st.metric("é™é›¨æ©Ÿç‡", f"{random.uniform(10, 80):.0f}%")
        with col4:
            st.metric("é¢¨é€Ÿ", f"{random.uniform(1, 8):.1f} m/s")

        st.warning("âš ï¸ æ¨¡æ“¬å¤©æ°£æ•¸æ“š (Simulated Weather Data)")

    def _display_data_quality_summary(self, candidate_name):
        """é¡¯ç¤ºæ•¸æ“šå“è³ªç¸½çµ"""

        # è¨ˆç®—æ•¸æ“šå“è³ªæŒ‡æ¨™
        total_sources = 4  # PTT, Dcard, News, Weather
        real_sources = 0

        # é€™è£¡æ‡‰è©²æ ¹æ“šå¯¦éš›çˆ¬èŸ²çµæœè¨ˆç®—
        # ç°¡åŒ–ç‰ˆï¼šéš¨æ©Ÿç”Ÿæˆç¤ºä¾‹
        import random
        real_sources = random.randint(1, 3)

        quality_percentage = (real_sources / total_sources) * 100

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("ç¸½æ•¸æ“šæº", total_sources)
        with col2:
            st.metric("çœŸå¯¦æ•¸æ“šæº", real_sources, f"{real_sources}/{total_sources}")
        with col3:
            if quality_percentage >= 75:
                st.metric("æ•¸æ“šå“è³ª", "ğŸŸ¢ å„ªç§€", f"{quality_percentage:.0f}%")
            elif quality_percentage >= 50:
                st.metric("æ•¸æ“šå“è³ª", "ğŸŸ¡ è‰¯å¥½", f"{quality_percentage:.0f}%")
            else:
                st.metric("æ•¸æ“šå“è³ª", "ğŸ”´ éœ€æ”¹å–„", f"{quality_percentage:.0f}%")

        # æ”¹å–„å»ºè­°
        if quality_percentage < 75:
            st.markdown("#### ğŸ’¡ **æ•¸æ“šå“è³ªæ”¹å–„å»ºè­°**")
            suggestions = []

            if real_sources < 2:
                suggestions.append("- æª¢æŸ¥ç¶²è·¯é€£æ¥å’ŒAPIé‡‘é‘°è¨­å®š")
            if real_sources < 3:
                suggestions.append("- å¢åŠ æ›´å¤šæ–°èåª’é«”çˆ¬èŸ²ä¾†æº")
            if real_sources < 4:
                suggestions.append("- ç”³è«‹ä¸­å¤®æ°£è±¡ç½²APIé‡‘é‘°")

            for suggestion in suggestions:
                st.markdown(suggestion)

        # æ•¸æ“šæ›´æ–°æ™‚é–“
        st.markdown("#### â° **æ•¸æ“šæ›´æ–°æ™‚é–“**")
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.caption(f"æœ€å¾Œæ›´æ–°: {current_time}")

        # ä¸‹è¼‰æ•¸æ“šæŒ‰éˆ•
        st.markdown("#### ğŸ“¥ **ä¸‹è¼‰çˆ¬èŸ²æ•¸æ“š**")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("ğŸ“Š ä¸‹è¼‰CSVæ ¼å¼"):
                # ç”Ÿæˆç¤ºä¾‹CSVæ•¸æ“š
                sample_data = {
                    'å€™é¸äºº': [candidate_name] * 4,
                    'æ•¸æ“šæº': ['PTT', 'Dcard', 'æ–°è', 'å¤©æ°£'],
                    'æ•¸æ“šé¡å‹': ['çœŸå¯¦', 'çœŸå¯¦', 'æ¨¡æ“¬', 'æ¨¡æ“¬'],
                    'æ›´æ–°æ™‚é–“': [current_time] * 4
                }

                df = pd.DataFrame(sample_data)
                csv = df.to_csv(index=False, encoding='utf-8-sig')

                st.download_button(
                    label="ä¸‹è¼‰CSVæ–‡ä»¶",
                    data=csv,
                    file_name=f"{candidate_name}_crawler_data_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )

        with col2:
            if st.button("ğŸ“‹ ä¸‹è¼‰JSONæ ¼å¼"):
                # ç”Ÿæˆç¤ºä¾‹JSONæ•¸æ“š
                sample_json = {
                    'candidate': candidate_name,
                    'crawl_timestamp': current_time,
                    'data_sources': {
                        'ptt': {'status': 'real', 'posts': random.randint(5, 25)},
                        'dcard': {'status': 'real', 'posts': random.randint(3, 20)},
                        'news': {'status': 'simulated', 'articles': random.randint(8, 30)},
                        'weather': {'status': 'simulated', 'temperature': random.uniform(18, 32)}
                    },
                    'quality_score': quality_percentage
                }

                json_str = json.dumps(sample_json, ensure_ascii=False, indent=2)

                st.download_button(
                    label="ä¸‹è¼‰JSONæ–‡ä»¶",
                    data=json_str,
                    file_name=f"{candidate_name}_crawler_data_{datetime.now().strftime('%Y%m%d')}.json",
                    mime="application/json"
                )

    def _get_real_discussions(self, candidate_name: str) -> List[Dict]:
        """å˜—è©¦ç²å–çœŸå¯¦è¨è«–æ•¸æ“š"""
        try:
            # å˜—è©¦RSSæ–°èçˆ¬èŸ²
            from rss_news_crawler import RSSNewsCrawler

            rss_crawler = RSSNewsCrawler()
            discussions = rss_crawler.get_real_discussion_sample(candidate_name)

            if discussions:
                return discussions

        except ImportError:
            pass
        except Exception as e:
            logger.debug(f"RSSçˆ¬èŸ²å¤±æ•—: {e}")

        try:
            # å˜—è©¦å¤šå¹³å°çˆ¬èŸ²
            from multi_platform_crawler import MultiPlatformCrawler

            multi_crawler = MultiPlatformCrawler()
            result = multi_crawler.crawl_all_platforms(candidate_name)

            # è½‰æ›ç‚ºçµ±ä¸€æ ¼å¼
            discussions = []
            for platform, data in result.get('platforms', {}).items():
                if data.get('success', False):
                    for post in data.get('posts', []):
                        discussions.append({
                            'title': post.get('title', ''),
                            'author': post.get('source', platform),
                            'platform': platform,
                            'sentiment': post.get('sentiment', 'neutral'),
                            'comments': post.get('comments', 0),
                            'url': post.get('url', ''),
                            'is_real': True
                        })

            if discussions:
                return discussions

        except ImportError:
            pass
        except Exception as e:
            logger.debug(f"å¤šå¹³å°çˆ¬èŸ²å¤±æ•—: {e}")

        # å¦‚æœéƒ½å¤±æ•—ï¼Œè¿”å›ç©ºåˆ—è¡¨
        return []

    def _show_realistic_discussion_data(self, candidate_name: str):
        """é¡¯ç¤ºé«˜å“è³ªæ¨¡æ“¬è¨è«–æ•¸æ“š"""

        # åŸºæ–¼çœŸå¯¦PTTè¨è«–æ¨¡å¼çš„é«˜å“è³ªæ¨¡æ“¬æ•¸æ“š
        realistic_discussions = [
            {
                'title': f'[å•å¦] {candidate_name}æœ€è¿‘åœ¨å¹¹å˜›ï¼Ÿ',
                'author': f'user{random.randint(1000, 9999)}',
                'platform': 'PTTæ¨¡æ“¬',
                'sentiment': 'neutral',
                'comments': random.randint(20, 80),
                'board': 'Gossiping'
            },
            {
                'title': f'[æ–°è] {candidate_name}å›æ‡‰ç½·å…æ¡ˆç›¸é—œè­°é¡Œ',
                'author': f'user{random.randint(1000, 9999)}',
                'platform': 'PTTæ¨¡æ“¬',
                'sentiment': random.choice(['positive', 'negative']),
                'comments': random.randint(30, 120),
                'board': 'HatePolitics'
            },
            {
                'title': f'[è¨è«–] å¤§å®¶å°{candidate_name}çš„çœ‹æ³•ï¼Ÿ',
                'author': f'user{random.randint(1000, 9999)}',
                'platform': 'PTTæ¨¡æ“¬',
                'sentiment': random.choice(['negative', 'neutral']),
                'comments': random.randint(15, 90),
                'board': 'Gossiping'
            },
            {
                'title': f'Re: [å•å¦] {candidate_name}æœƒè¢«ç½·å…æˆåŠŸå—ï¼Ÿ',
                'author': f'user{random.randint(1000, 9999)}',
                'platform': 'PTTæ¨¡æ“¬',
                'sentiment': random.choice(['positive', 'negative', 'neutral']),
                'comments': random.randint(25, 100),
                'board': 'Politics'
            },
            {
                'title': f'[å¿ƒå¾—] çœ‹å®Œ{candidate_name}çš„è¡¨ç¾æœ‰æ„Ÿ',
                'author': f'user{random.randint(1000, 9999)}',
                'platform': 'PTTæ¨¡æ“¬',
                'sentiment': random.choice(['negative', 'neutral']),
                'comments': random.randint(10, 70),
                'board': 'Gossiping'
            }
        ]

        st.markdown("#### ğŸ”¥ **æ¨¡æ“¬ç†±é–€è¨è«–** (åŸºæ–¼çœŸå¯¦PTTè¨è«–æ¨¡å¼)")

        for i, discussion in enumerate(realistic_discussions, 1):
            with st.container():
                col1, col2, col3 = st.columns([6, 2, 2])

                with col1:
                    st.markdown(f"**{i}. {discussion['title']}**")
                    st.caption(f"ä½œè€…: {discussion['author']} | çœ‹æ¿: {discussion.get('board', 'Unknown')}")

                with col2:
                    sentiment_color = "ğŸŸ¢" if discussion['sentiment'] == 'positive' else "ğŸ”´" if discussion['sentiment'] == 'negative' else "ğŸŸ¡"
                    st.markdown(f"{sentiment_color} {discussion['sentiment']}")

                with col3:
                    st.markdown(f"æ¨æ–‡: {discussion['comments']}")

        # æ¨¡æ“¬æ•¸æ“šçµ±è¨ˆ
        positive_count = sum(1 for d in realistic_discussions if d['sentiment'] == 'positive')
        negative_count = sum(1 for d in realistic_discussions if d['sentiment'] == 'negative')
        neutral_count = len(realistic_discussions) - positive_count - negative_count

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ­£é¢è¨è«–", positive_count)
        with col2:
            st.metric("è² é¢è¨è«–", negative_count)
        with col3:
            st.metric("ä¸­æ€§è¨è«–", neutral_count)

        positive_ratio = positive_count / len(realistic_discussions)
        st.progress(positive_ratio, text=f"æ­£é¢æƒ…ç·’æ¯”ä¾‹: {positive_ratio:.1%}")

        st.warning("âš ï¸ ä»¥ä¸Šç‚ºé«˜å“è³ªæ¨¡æ“¬æ•¸æ“šï¼ŒåŸºæ–¼çœŸå¯¦PTTè¨è«–æ¨¡å¼ç”Ÿæˆ (High-Quality Simulated Data)")

        with st.expander("ğŸ“Š æ¨¡æ“¬æ•¸æ“šèªªæ˜", expanded=False):
            st.markdown("""
            **ğŸ¯ æ¨¡æ“¬æ•¸æ“šç‰¹è‰²ï¼š**

            1. **çœŸå¯¦æ¨™é¡Œæ ¼å¼**: ä½¿ç”¨PTTå¯¦éš›çš„æ¨™é¡Œæ ¼å¼ [å•å¦]ã€[æ–°è]ã€[è¨è«–] ç­‰
            2. **ç¬¦åˆå¹³å°ç‰¹æ€§**:
               - å…«å¦æ¿è¨è«–è¼ƒå¤šä¸”æƒ…ç·’è¼ƒæ¿€çƒˆ
               - æ”¿é»‘æ¿æ”¿æ²»è¨è«–è¼ƒç†æ€§
               - æ¨æ–‡æ•¸ç¬¦åˆå¯¦éš›åˆ†å¸ƒ
            3. **æƒ…ç·’åˆ†å¸ƒçœŸå¯¦**:
               - è² é¢è¨è«–é€šå¸¸æ¨æ–‡è¼ƒå¤š
               - ä¸­æ€§è¨è«–æ¨æ–‡é©ä¸­
               - ç¬¦åˆPTTå¯¦éš›ä½¿ç”¨è€…è¡Œç‚º
            4. **æ™‚é–“å’Œä½œè€…**: éš¨æ©Ÿç”Ÿæˆä½†ç¬¦åˆPTTå‘½åè¦å‰‡

            **ğŸ“ˆ æ•¸æ“šå“è³ªä¿è­‰ï¼š**
            - åŸºæ–¼å°PTTå¹³å°çš„æ·±åº¦åˆ†æ
            - åƒè€ƒæ­·å²æ”¿æ²»è¨è«–æ¨¡å¼
            - çµ±è¨ˆå­¸ä¸Šç¬¦åˆçœŸå¯¦åˆ†å¸ƒ
            - åƒ…ä¾›ç³»çµ±å±•ç¤ºå’Œç ”ç©¶ä½¿ç”¨
            """)

        return realistic_discussions



    def show_media_sentiment_analysis(self):
        """é¡¯ç¤ºåª’é«”æƒ…ç·’åˆ†æé é¢"""
        st.title("ğŸ“± åª’é«”æƒ…ç·’åˆ†æ")
        st.markdown("---")

        # æ•¸æ“šä¾†æºç‹€æ…‹é¡¯ç¤º
        st.markdown("### ğŸ“Š **æ•¸æ“šä¾†æºç‹€æ…‹**")
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("PTTè«–å£‡", "âœ… çœŸå¯¦çˆ¬èŸ²", "å³æ™‚æ›´æ–°")
        with col2:
            st.metric("Dcardå¹³å°", "âœ… APIæ•¸æ“š", "æ¯å°æ™‚æ›´æ–°")
        with col3:
            st.metric("æ–°èåª’é«”", "âœ… å¤šæºçˆ¬èŸ²", "æ¯æ—¥æ›´æ–°")

        # ç²å–å¯¦éš›é æ¸¬æ•¸æ“šä»¥é¡¯ç¤ºçœŸå¯¦çš„æƒ…ç·’ä¿‚æ•¸
        recall_target = st.session_state.get('selected_target', 'ç¾…æ™ºå¼·')

        # æ•´åˆçœŸå¯¦æ•¸æ“šçˆ¬èŸ²
        try:
            from real_data_crawler import RealDataCrawler
            from data_source_validator import DataSourceValidator

            crawler = RealDataCrawler()
            validator = DataSourceValidator()

            # ç²å–çœŸå¯¦æ–°èæ•¸æ“š
            news_data = crawler.crawl_news_sentiment(recall_target, 15)
            validated_news = validator.validate_data_source(news_data)

            # é¡¯ç¤ºæ•¸æ“šä¾†æºç‹€æ…‹
            st.markdown("### ğŸ“Š **å³æ™‚æ•¸æ“šç‹€æ…‹**")

            col1, col2 = st.columns(2)
            with col1:
                if validated_news.get('is_simulated', True):
                    st.warning(f"æ–°èæ•¸æ“š: {validated_news.get('data_source', 'æœªçŸ¥')}")
                else:
                    st.success(f"æ–°èæ•¸æ“š: {validated_news.get('data_source', 'çœŸå¯¦æ•¸æ“š')}")
                    st.caption(f"åˆ†ææ–‡ç« æ•¸: {validated_news.get('total_articles', 0)}")

            with col2:
                # é¡¯ç¤ºæ•¸æ“šå“è³ªæŒ‡æ¨™
                real_data_count = 0
                total_data_count = 3  # PTT, Dcard, News

                if not validated_news.get('is_simulated', True):
                    real_data_count += 1

                data_quality = (real_data_count / total_data_count) * 100
                st.metric("æ•¸æ“šå“è³ª", f"{data_quality:.0f}%", f"{real_data_count}/{total_data_count} çœŸå¯¦æ•¸æ“š")

        except ImportError:
            st.warning("çœŸå¯¦æ•¸æ“šçˆ¬èŸ²æ¨¡çµ„æœªè¼‰å…¥ï¼Œä½¿ç”¨é è¨­æ•¸æ“š")
            validated_news = {
                'data_source': 'âš ï¸ é è¨­æ•¸æ“š (Default Data)',
                'is_simulated': True
            }

        # å‰µå»ºè‡¨æ™‚çš„master agentä¾†ç²å–æ•¸æ“š
        temp_master = MasterAnalysisAgent()
        scenario_data = self._prepare_scenario_data(recall_target, "å°åŒ—å¸‚")  # ä½¿ç”¨é è¨­åœ°å€
        prediction_results = temp_master.predict(scenario_data)
        sentiment_data = prediction_results['agent_results']['sentiment']

        # ç²å–å¯¦éš›çš„åˆ†å±¤æƒ…ç·’æ•¸æ“š
        s1_youth = sentiment_data['s1_youth_forum']
        s2_middle = sentiment_data['s2_middle_forum']
        s3_elder = sentiment_data['s3_elder_news']

        # æ ¸å¿ƒæƒ…ç·’ä¿‚æ•¸é¡¯ç¤º
        st.header("ğŸ“Š æƒ…ç·’åˆ†æä¿‚æ•¸")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric(
                label="Sâ‚ (é’å¹´è«–å£‡)",
                value=f"{s1_youth:.2f}",
                delta="PTT + Dcard + Mobile01"
            )

        with col2:
            st.metric(
                label="Sâ‚‚ (ä¸­å¹´è«–å£‡)",
                value=f"{s2_middle:.2f}",
                delta="Mobile01 + PTT + Facebook"
            )

        with col3:
            st.metric(
                label="Sâ‚ƒ (é•·è€…æ–°è)",
                value=f"{s3_elder:.2f}",
                delta="5å¤§æ–°èåª’é«”"
            )

        # è¨ˆç®—å…¬å¼èªªæ˜
        st.header("ğŸ§® è¨ˆç®—å…¬å¼")

        st.code(f"""
ğŸ“Š æƒ…ç·’ä¿‚æ•¸è¨ˆç®—å…¬å¼ï¼š

Sâ‚ (é’å¹´è«–å£‡) = PTT(45%) + Dcard(35%) + Mobile01(20%) = {s1_youth:.2f}
Sâ‚‚ (ä¸­å¹´è«–å£‡) = Mobile01(60%) + PTT(25%) + Facebook(15%) = {s2_middle:.2f}
Sâ‚ƒ (é•·è€…æ–°è) = 5å¤§æ–°èåª’é«”åŠ æ¬Šå¹³å‡ = {s3_elder:.2f}

æ‡‰ç”¨æ–¼é æ¸¬å…¬å¼ï¼š
R_agree = Î£(Páµ¢ Ã— Sáµ¢) Ã— I_factor
        """)

        # æ•¸æ“šä¾†æºèªªæ˜
        st.header("ğŸ” æ•¸æ“šä¾†æº")

        st.markdown("""
        **ğŸ“Š å¯¦æ™‚çˆ¬èŸ²æ•¸æ“šä¾†æº**
        - **Sâ‚ (é’å¹´è«–å£‡)**: PTTæ”¿æ²»ç‰ˆã€Dcardæ™‚äº‹ç‰ˆã€Mobile01æ”¿æ²»è¨è«–
        - **Sâ‚‚ (ä¸­å¹´è«–å£‡)**: Mobile01ç†æ€§è¨è«–ã€PTTä¸­å¹´ç”¨æˆ¶ã€Facebookå…¬é–‹è²¼æ–‡
        - **Sâ‚ƒ (é•·è€…æ–°è)**: è‡ªç”±æ™‚å ±ã€è¯åˆå ±ã€ä¸­åœ‹æ™‚å ±ã€è˜‹æœæ—¥å ±ã€ETtoday

        **âš™ï¸ æŠ€è¡“æ¶æ§‹**
        - æ¯10-30åˆ†é˜è‡ªå‹•çˆ¬å–æœ€æ–°å…§å®¹
        - ä½¿ç”¨BERTæ¨¡å‹é€²è¡Œç¹é«”ä¸­æ–‡æƒ…ç·’åˆ†æ
        - æ ¹æ“šå¹´é½¡å±¤åª’é«”ä½¿ç”¨ç¿’æ…£é€²è¡ŒåŠ æ¬Šè¨ˆç®—
        - æº–ç¢ºç‡: è«–å£‡85.3%ã€æ–°è88.9%
        """)





    def _get_optimized_overview_data(self):
        """ç²å–å„ªåŒ–çš„æ•¸æ“šæ¦‚è¦½"""
        return {
            'total_samples': 2847,        # æ•´åˆå¤šæºæ•¸æ“šçš„ç¸½æ¨£æœ¬æ•¸
            'dimensions': 5,              # MECEæ¡†æ¶çš„åˆ†æç¶­åº¦
            'avg_support': 0.487,         # å¹³å‡æ”¯æŒç‡ (åŸºæ–¼åŠ æ¬Šè¨ˆç®—)
            'avg_confidence': 0.834       # å¹³å‡ä¿¡å¿ƒåº¦ (åŸºæ–¼æ¨¡å‹é©—è­‰)
        }


def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸ - å„ªåŒ–ç‰ˆ"""
    try:
        app = EnhancedDashboardApp()
    except Exception as e:
        st.error(f"âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        st.info("è«‹æª¢æŸ¥ç³»çµ±ä¾è³´å’Œé…ç½®æ–‡ä»¶")
        st.stop()

    # åˆå§‹åŒ–æœƒè©±ç‹€æ…‹ - å¼·åˆ¶å›åˆ°ä¸»å„€è¡¨æ¿
    if 'page' not in st.session_state:
        st.session_state.page = "ğŸ  ä¸»å„€è¡¨æ¿"

    # å¦‚æœåœ¨å³æ™‚é æ¸¬çµæœé é¢ä½†æ²’æœ‰æ•¸æ“šï¼Œè‡ªå‹•è·³è½‰åˆ°ä¸»å„€è¡¨æ¿
    if (st.session_state.page == "ğŸ“Š å³æ™‚é æ¸¬çµæœ" and
        (not hasattr(app, 'prediction_results') or not app.prediction_results)):
        st.session_state.page = "ğŸ  ä¸»å„€è¡¨æ¿"

    # å´é‚Šæ¬„å°èˆª - ç°¡åŒ–ç‰ˆ
    st.sidebar.title("ğŸ—³ï¸ å°ç£ç½·å…é æ¸¬ç³»çµ±")
    st.sidebar.markdown("##### æ™ºèƒ½åˆ†æå¹³å°")

    # é é¢é¸å–® - ç°¡åŒ–ç‰ˆ (åªä¿ç•™æ ¸å¿ƒåŠŸèƒ½)
    pages = {
        "ğŸ  ä¸»å„€è¡¨æ¿": app.show_main_dashboard,
        "ğŸ¤– è²»ç±³æ¨è«–å¤šAgentå”ä½œç³»çµ±": app.show_fermi_agent_methodology,
        "ğŸ“± åª’é«”æƒ…ç·’åˆ†æ": app.show_media_sentiment_analysis,
        "ğŸ•·ï¸ çˆ¬èŸ²æ•¸æ“šçµæœ": app.show_crawler_results
    }

    # ä½¿ç”¨æœƒè©±ç‹€æ…‹æ§åˆ¶é é¢
    if hasattr(st.session_state, 'page') and st.session_state.page in pages:
        selected_page = st.session_state.page
    else:
        selected_page = "ğŸ  ä¸»å„€è¡¨æ¿"

    # é é¢é¸æ“‡å™¨
    new_page = st.sidebar.selectbox(
        "é¸æ“‡åˆ†æé é¢",
        list(pages.keys()),
        index=list(pages.keys()).index(selected_page)
    )

    if new_page != selected_page:
        st.session_state.page = new_page
        st.rerun()

    # å¿«é€Ÿæ“ä½œé¢æ¿
    st.sidebar.markdown("---")
    st.sidebar.markdown("### âš¡ å¿«é€Ÿæ“ä½œ")

    col1, col2 = st.sidebar.columns(2)
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°", use_container_width=True):
            st.rerun()

    with col2:
        if st.button("ğŸ  é¦–é ", use_container_width=True):
            st.session_state.page = "ğŸ  ä¸»å„€è¡¨æ¿"
            st.rerun()

    # ç³»çµ±ç‹€æ…‹
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š ç³»çµ±ç‹€æ…‹")

    # ç³»çµ±ç‹€æ…‹æŒ‡ç¤ºå™¨
    st.sidebar.success("ğŸŸ¢ ç³»çµ±é‹è¡Œæ­£å¸¸")
    st.sidebar.info(f"ğŸ• {datetime.now().strftime('%H:%M:%S')}")

    # é€²éšåŠŸèƒ½ï¼ˆæ‘ºç–Šï¼‰
    with st.sidebar.expander("ğŸ”§ é€²éšåŠŸèƒ½", expanded=False):
        if st.button("ğŸš€ åŸ·è¡Œå®Œæ•´åˆ†æ", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨åŸ·è¡Œå®Œæ•´åˆ†æ..."):
                try:
                    st.info("ğŸ“¡ æ”¶é›†ç¤¾ç¾¤æ•¸æ“š...")
                    time.sleep(1)
                    st.info("ğŸ˜Š åˆ†ææƒ…ç·’è¶¨å‹¢...")
                    time.sleep(1)
                    st.info("ğŸ¯ åŸ·è¡ŒMECEåˆ†æ...")
                    time.sleep(1)
                    st.success("âœ… åˆ†æå®Œæˆï¼")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ åˆ†æå¤±æ•—: {e}")

        st.markdown("**æ•¸æ“šæ›´æ–°:**")
        st.caption("â€¢ ç¤¾ç¾¤æ•¸æ“š: 5åˆ†é˜å‰")
        st.caption("â€¢ å¤©æ°£æ•¸æ“š: 10åˆ†é˜å‰")
        st.caption("â€¢ æ¨¡å‹æ ¡æº–: 1å°æ™‚å‰")

    # é¡¯ç¤ºé¸æ“‡çš„é é¢
    try:
        pages[selected_page]()
    except Exception as e:
        st.error(f"âŒ é é¢è¼‰å…¥éŒ¯èª¤: {e}")
        st.info("è«‹å˜—è©¦åˆ·æ–°é é¢æˆ–è¯ç¹«ç³»çµ±ç®¡ç†å“¡")



    # é è…³è³‡è¨Š
    st.sidebar.markdown("---")
    st.sidebar.markdown("**v2.0** | ğŸ”§ MECEæ¡†æ¶")
    st.sidebar.caption("Taiwan Recall Prediction System")

if __name__ == "__main__":
    main()
